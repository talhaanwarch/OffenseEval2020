{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep model.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "FwKb7_NBWjAv"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/talhaanwarch/OffenseEval2020/blob/master/English/Deep_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twoQx3_KWgi3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# d=[]\n",
        "# while(1):\n",
        "#   d.append('1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uqG7k8lK3xz",
        "colab_type": "code",
        "outputId": "cfaef12e-67c9-44a3-9e34-1a8ef3707a68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "source": [
        "!pip install focal-loss\n",
        "!pip install keras-tcn==2.8.3"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting focal-loss\n",
            "  Downloading https://files.pythonhosted.org/packages/66/ed/17450291228192ad8595de4514c8ec28a587697b03c707d12d4af5b7f331/focal_loss-0.0.2-py3-none-any.whl\n",
            "Installing collected packages: focal-loss\n",
            "Successfully installed focal-loss-0.0.2\n",
            "Collecting keras-tcn==2.8.3\n",
            "  Downloading https://files.pythonhosted.org/packages/d4/c4/438c86b27ab11a79cc659d8d6878682c4eb80caa0c0b3d620740cef762f5/keras_tcn-2.8.3-py3-none-any.whl\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-tcn==2.8.3) (2.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-tcn==2.8.3) (1.17.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-tcn==2.8.3) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-tcn==2.8.3) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-tcn==2.8.3) (1.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-tcn==2.8.3) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-tcn==2.8.3) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras->keras-tcn==2.8.3) (1.0.8)\n",
            "Installing collected packages: keras-tcn\n",
            "Successfully installed keras-tcn-2.8.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPexfZvANVks",
        "colab_type": "code",
        "outputId": "28859437-f65e-45a2-955a-c4000f892de7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6Q3msMuLDpE",
        "colab_type": "text"
      },
      "source": [
        "# Import lib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpTHlh_QLDL7",
        "colab_type": "code",
        "outputId": "836f8dde-776e-4560-a43c-cf1e476f7554",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 96
        }
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Embedding,CuDNNGRU,CuDNNLSTM,Dense,Dropout,Bidirectional,BatchNormalization,GlobalMaxPooling1D,Flatten, GlobalAveragePooling1D, MaxPooling1D,SpatialDropout1D,Input,Activation,concatenate,Conv1D\n",
        "from keras.optimizers import RMSprop,Adam,Adadelta\n",
        "from keras.initializers import Constant\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import classification_report,f1_score\n",
        "import keras\n",
        "import collections\n",
        "import numpy as np\n",
        "from focal_loss import BinaryFocalLoss\n",
        "import tensorflow as tf\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Udk8qWz-K4cx",
        "colab_type": "text"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52k7345EK6kb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#cd /content/drive/My Drive/dataset/OffenseEval2020/data/English/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnI2RvjGK_Vw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lx-1BQaY6rkq",
        "colab_type": "code",
        "outputId": "23fb7e25-d73f-4c23-8fce-9b831da686e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "train=pd.read_csv( '/content/drive/My Drive/dataset/OffenseEval2020/data/English/task_a_distant.tsv',sep=\"\\t\")\n",
        "train.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>average</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1159533701283352576</td>\n",
              "      <td>First time I heard his name in camp, he seems ...</td>\n",
              "      <td>0.195773</td>\n",
              "      <td>0.187379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1159533703522992128</td>\n",
              "      <td>When I go to drink with Tsubaki he would alway...</td>\n",
              "      <td>0.262401</td>\n",
              "      <td>0.145998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1159533703758061570</td>\n",
              "      <td>@USER His ass need to stay up 😂😂</td>\n",
              "      <td>0.833391</td>\n",
              "      <td>0.140628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1159533703904800769</td>\n",
              "      <td>most important tweet of the day : Fuck Donald ...</td>\n",
              "      <td>0.565238</td>\n",
              "      <td>0.187498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1159533705125343232</td>\n",
              "      <td>You wanna leave? then feel free cus I promise ...</td>\n",
              "      <td>0.664921</td>\n",
              "      <td>0.097098</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    id  ...       std\n",
              "0  1159533701283352576  ...  0.187379\n",
              "1  1159533703522992128  ...  0.145998\n",
              "2  1159533703758061570  ...  0.140628\n",
              "3  1159533703904800769  ...  0.187498\n",
              "4  1159533705125343232  ...  0.097098\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsyaJHD98Fdn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train=train['average'].values\n",
        "\n",
        "y_train[y_train>0.5]=1\n",
        "y_train[y_train<0.5]=0\n",
        "y_train=y_train.astype('int')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIoM04y68Pwd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpKtr-fN64Tw",
        "colab_type": "code",
        "outputId": "4953d577-5b1e-446f-c911-b8dcca688d4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "test=pd.read_csv( '/content/drive/My Drive/dataset/OffenseEval2020/data/English/test_a_tweets.tsv',sep=\"\\t\")\n",
        "test.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A0</td>\n",
              "      <td>¿Who the fuck is Yoru?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A1</td>\n",
              "      <td>@USER @USER He's an evil law breaker that shou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A2</td>\n",
              "      <td>Now hiring for 49 #Labor job opportunities in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A3</td>\n",
              "      <td>#NerkondaPaarvai' - As Of Now, There Is NO Ear...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A4</td>\n",
              "      <td>@USER Hahahaha I wish...but a week is good, I’...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                              tweet\n",
              "0  A0                             ¿Who the fuck is Yoru?\n",
              "1  A1  @USER @USER He's an evil law breaker that shou...\n",
              "2  A2  Now hiring for 49 #Labor job opportunities in ...\n",
              "3  A3  #NerkondaPaarvai' - As Of Now, There Is NO Ear...\n",
              "4  A4  @USER Hahahaha I wish...but a week is good, I’..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMbpcevIl7g9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lemmatizer = WordNetLemmatizer()\n",
        "# w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
        "# stop = stopwords.words('english')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YY8MVlxhggiD",
        "colab_type": "code",
        "outputId": "099650fa-d353-4b3a-f0e8-c4f758b88024",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "\n",
        "train['text']=train['text'].str.replace('\\d+', '')\n",
        "train['text']=train['text'].str.replace('@USER', \"\") \n",
        "train['text']=train['text'].str.replace('URL', '')\n",
        "train[\"text\"]= train[\"text\"].str.lower()\n",
        "train[\"text\"] = train[\"text\"].str.replace('[^\\w\\s]','')\n",
        "#train[\"text\"] = train[\"text\"].apply(lambda x : [lemmatizer.lemmatize(y) for y in w_tokenizer.tokenize(x)])\n",
        "#train[\"text\"] = train[\"text\"].apply(lambda x: [item for item in x if item not in stop])\n",
        "#train[\"text\"] = train[\"text\"].apply(lambda x : \" \".join(x))\n",
        "train.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>average</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1159533701283352576</td>\n",
              "      <td>first time i heard his name in camp he seems t...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.187379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1159533703522992128</td>\n",
              "      <td>when i go to drink with tsubaki he would alway...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.145998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1159533703758061570</td>\n",
              "      <td>his ass need to stay up</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.140628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1159533703904800769</td>\n",
              "      <td>most important tweet of the day  fuck donald t...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.187498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1159533705125343232</td>\n",
              "      <td>you wanna leave then feel free cus i promise i...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.097098</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    id  ...       std\n",
              "0  1159533701283352576  ...  0.187379\n",
              "1  1159533703522992128  ...  0.145998\n",
              "2  1159533703758061570  ...  0.140628\n",
              "3  1159533703904800769  ...  0.187498\n",
              "4  1159533705125343232  ...  0.097098\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4a563504-c9cb-44fa-9794-f5abcaf76c61",
        "id": "CsyCZVe-IdY7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "\n",
        "test['tweet']=test['tweet'].str.replace('\\d+', '')\n",
        "test['tweet']=test['tweet'].str.replace('@USER', \"\") \n",
        "test['tweet']=test['tweet'].str.replace('URL', '')\n",
        "test[\"tweet\"]= test[\"tweet\"].str.lower()\n",
        "test[\"tweet\"] = test[\"tweet\"].str.replace('[^\\w\\s]','')\n",
        "#test[\"tweet\"] = test[\"tweet\"].apply(lambda x : [lemmatizer.lemmatize(y) for y in w_tokenizer.tokenize(x)])\n",
        "#test[\"tweet\"] = test[\"tweet\"].apply(lambda x: [item for item in x if item not in stop])\n",
        "#test[\"tweet\"] = test[\"tweet\"].apply(lambda x : \" \".join(x))\n",
        "test.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A0</td>\n",
              "      <td>who the fuck is yoru</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A1</td>\n",
              "      <td>hes an evil law breaker that should be in pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A2</td>\n",
              "      <td>now hiring for  labor job opportunities in min...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A3</td>\n",
              "      <td>nerkondapaarvai  as of now there is no early m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A4</td>\n",
              "      <td>hahahaha i wishbut a week is good im extremel...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                              tweet\n",
              "0  A0                               who the fuck is yoru\n",
              "1  A1    hes an evil law breaker that should be in pr...\n",
              "2  A2  now hiring for  labor job opportunities in min...\n",
              "3  A3  nerkondapaarvai  as of now there is no early m...\n",
              "4  A4   hahahaha i wishbut a week is good im extremel..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "75QSgBlzIdY_"
      },
      "source": [
        "#Label Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CAxHNiNJIdZA",
        "colab": {}
      },
      "source": [
        "labels=y_train.copy()\n",
        "train=train['text']\n",
        "test=test['tweet']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCtBGu-B_kgZ",
        "colab_type": "code",
        "outputId": "9d96981f-d32f-4acf-dad5-9c6c96142921",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    first time i heard his name in camp he seems t...\n",
              "1    when i go to drink with tsubaki he would alway...\n",
              "2                             his ass need to stay up \n",
              "3    most important tweet of the day  fuck donald t...\n",
              "4    you wanna leave then feel free cus i promise i...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8D3p5u3JIdZH",
        "colab": {}
      },
      "source": [
        "# le=LabelEncoder()\n",
        "# labels=le.fit_transform(labels)\n",
        "# print(len(labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zAdyISaxIdZK"
      },
      "source": [
        "# Common Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijjhkumKaDw7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_size=0.2\n",
        "batch_size=1024\n",
        "opt=Adam()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-IToeBciV1m",
        "colab_type": "text"
      },
      "source": [
        "## Cylic learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIYW6ZAniXzU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://www.kaggle.com/hireme/fun-api-keras-f1-metric-cyclical-learning-rate/code\n",
        "from keras.callbacks import Callback\n",
        "class CyclicLR(Callback):\n",
        "    \"\"\"This callback implements a cyclical learning rate policy (CLR).\n",
        "    The method cycles the learning rate between two boundaries with\n",
        "    some constant frequency, as detailed in this paper (https://arxiv.org/abs/1506.01186).\n",
        "    The amplitude of the cycle can be scaled on a per-iteration or \n",
        "    per-cycle basis.\n",
        "    This class has three built-in policies, as put forth in the paper.\n",
        "    \"triangular\":\n",
        "        A basic triangular cycle w/ no amplitude scaling.\n",
        "    \"triangular2\":\n",
        "        A basic triangular cycle that scales initial amplitude by half each cycle.\n",
        "    \"exp_range\":\n",
        "        A cycle that scales initial amplitude by gamma**(cycle iterations) at each \n",
        "        cycle iteration.\n",
        "    For more detail, please see paper.\n",
        "    \n",
        "    # Example\n",
        "        ```python\n",
        "            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
        "                                step_size=2000., mode='triangular')\n",
        "            model.fit(X_train, Y_train, callbacks=[clr])\n",
        "        ```\n",
        "    \n",
        "    Class also supports custom scaling functions:\n",
        "        ```python\n",
        "            clr_fn = lambda x: 0.5*(1+np.sin(x*np.pi/2.))\n",
        "            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
        "                                step_size=2000., scale_fn=clr_fn,\n",
        "                                scale_mode='cycle')\n",
        "            model.fit(X_train, Y_train, callbacks=[clr])\n",
        "        ```    \n",
        "    # Arguments\n",
        "        base_lr: initial learning rate which is the\n",
        "            lower boundary in the cycle.\n",
        "        max_lr: upper boundary in the cycle. Functionally,\n",
        "            it defines the cycle amplitude (max_lr - base_lr).\n",
        "            The lr at any cycle is the sum of base_lr\n",
        "            and some scaling of the amplitude; therefore \n",
        "            max_lr may not actually be reached depending on\n",
        "            scaling function.\n",
        "        step_size: number of training iterations per\n",
        "            half cycle. Authors suggest setting step_size\n",
        "            2-8 x training iterations in epoch.\n",
        "        mode: one of {triangular, triangular2, exp_range}.\n",
        "            Default 'triangular'.\n",
        "            Values correspond to policies detailed above.\n",
        "            If scale_fn is not None, this argument is ignored.\n",
        "        gamma: constant in 'exp_range' scaling function:\n",
        "            gamma**(cycle iterations)\n",
        "        scale_fn: Custom scaling policy defined by a single\n",
        "            argument lambda function, where \n",
        "            0 <= scale_fn(x) <= 1 for all x >= 0.\n",
        "            mode paramater is ignored \n",
        "        scale_mode: {'cycle', 'iterations'}.\n",
        "            Defines whether scale_fn is evaluated on \n",
        "            cycle number or cycle iterations (training\n",
        "            iterations since start of cycle). Default is 'cycle'.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=2000., mode='triangular',\n",
        "                 gamma=1., scale_fn=None, scale_mode='cycle'):\n",
        "        super(CyclicLR, self).__init__()\n",
        "\n",
        "        self.base_lr = base_lr\n",
        "        self.max_lr = max_lr\n",
        "        self.step_size = step_size\n",
        "        self.mode = mode\n",
        "        self.gamma = gamma\n",
        "        if scale_fn == None:\n",
        "            if self.mode == 'triangular':\n",
        "                self.scale_fn = lambda x: 1.\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'triangular2':\n",
        "                self.scale_fn = lambda x: 1/(2.**(x-1))\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'exp_range':\n",
        "                self.scale_fn = lambda x: gamma**(x)\n",
        "                self.scale_mode = 'iterations'\n",
        "        else:\n",
        "            self.scale_fn = scale_fn\n",
        "            self.scale_mode = scale_mode\n",
        "        self.clr_iterations = 0.\n",
        "        self.trn_iterations = 0.\n",
        "        self.history = {}\n",
        "\n",
        "        self._reset()\n",
        "\n",
        "    def _reset(self, new_base_lr=None, new_max_lr=None,\n",
        "               new_step_size=None):\n",
        "        \"\"\"Resets cycle iterations.\n",
        "        Optional boundary/step size adjustment.\n",
        "        \"\"\"\n",
        "        if new_base_lr != None:\n",
        "            self.base_lr = new_base_lr\n",
        "        if new_max_lr != None:\n",
        "            self.max_lr = new_max_lr\n",
        "        if new_step_size != None:\n",
        "            self.step_size = new_step_size\n",
        "        self.clr_iterations = 0.\n",
        "        \n",
        "    def clr(self):\n",
        "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
        "        x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
        "        if self.scale_mode == 'cycle':\n",
        "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(cycle)\n",
        "        else:\n",
        "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(self.clr_iterations)\n",
        "        \n",
        "    def on_train_begin(self, logs={}):\n",
        "        logs = logs or {}\n",
        "\n",
        "        if self.clr_iterations == 0:\n",
        "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
        "        else:\n",
        "            K.set_value(self.model.optimizer.lr, self.clr())        \n",
        "            \n",
        "    def on_batch_end(self, epoch, logs=None):\n",
        "        \n",
        "        logs = logs or {}\n",
        "        self.trn_iterations += 1\n",
        "        self.clr_iterations += 1\n",
        "\n",
        "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
        "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
        "\n",
        "        for k, v in logs.items():\n",
        "            self.history.setdefault(k, []).append(v)\n",
        "        \n",
        "        K.set_value(self.model.optimizer.lr, self.clr())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIcxIjeYjHyo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clr = CyclicLR(base_lr=0.001, max_lr=0.005,\n",
        "                        step_size=4., mode='exp_range',\n",
        "                        gamma=0.99994)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAv_EEaQLXtY",
        "colab_type": "text"
      },
      "source": [
        "# Tokenize data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QomCkNlRLHPG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "max_words = 5000 #frequency of words to be kept\n",
        "max_len = 150\n",
        "\n",
        "tokenize = Tokenizer(num_words=max_words)\n",
        "tokenize.fit_on_texts(train)\n",
        "sequences = tokenize.texts_to_sequences(train)\n",
        "word_index = tokenize.word_index\n",
        "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len,padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og1W2rCOLs4w",
        "colab_type": "code",
        "outputId": "e102ca7a-f674-4571-b2f6-158d2d7df83f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "len(sequences_matrix),len(labels)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9075418, 9075418)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4kzu1RxLyGk",
        "colab_type": "code",
        "outputId": "6373a344-8859-4c78-db64-3f43bdc73355",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "num_words = min(max_words, len(word_index)) + 1\n",
        "print(num_words)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4i7WSY3lMmdp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_sequences = tokenize.texts_to_sequences(test)\n",
        "X_test_sequences = sequence.pad_sequences(test_sequences,maxlen=max_len,padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRZxav1WNle-",
        "colab_type": "code",
        "outputId": "75353913-d1c0-4f01-cfd4-fcd2adebc85a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "len(X_test_sequences)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3887"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpzUIu4iL0PO",
        "colab_type": "text"
      },
      "source": [
        "# Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UASiPIPlnZKP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_path1 = \"/content/drive/My Drive/dataset/OLID/wiki-news-300d-1M.vec\"\n",
        "embedding_path2 = \"/content/drive/My Drive/dataset/OLID/glove/glove.840B.300d.txt\"\n",
        "embed_size = 300"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nSWnsAQzI3fS",
        "colab": {}
      },
      "source": [
        "def get_coefs(word,*arr):\n",
        "    return word, np.asarray(arr, dtype='float32')\n",
        "\n",
        "def build_matrix(embedding_path, word_index):\n",
        "    embedding_index = dict(get_coefs(*o.strip().split(\" \")) for o in open(embedding_path))\n",
        "\n",
        "    nb_words = min(max_words, len(word_index))\n",
        "    embedding_matrix = np.zeros((nb_words + 1, embed_size))\n",
        "    for word, i in word_index.items():\n",
        "        if i >= max_words:\n",
        "            continue\n",
        "        embedding_vector = embedding_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "    return embedding_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WHijQT3BI3fX",
        "colab": {}
      },
      "source": [
        "fasttext=build_matrix(embedding_path1, word_index)\n",
        "glove_emb=build_matrix(embedding_path2, word_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWgNaYzPnf2C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "8566f4c7-bbdd-4c9a-f4ce-3a43b30ebaf4"
      },
      "source": [
        "embeddings=np.mean((fasttext,glove_emb),axis=0)\n",
        "embeddings.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5001, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaShFhtgJ_Ef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6sOo5OtMQnL",
        "colab_type": "text"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G71gBUQ0MNDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_val,y_train,y_val=train_test_split(sequences_matrix,labels,test_size=test_size,stratify=labels,shuffle=True,random_state=2020)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jv2yPgQWL9de",
        "colab_type": "text"
      },
      "source": [
        "##GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXvqlGD0L-sx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_gru():\n",
        "  inp = Input(shape=(max_len,))\n",
        "  x = Embedding(num_words,embed_size,embeddings_initializer=Constant(embeddings),input_length=max_len,trainable=False)(inp)\n",
        "  x = SpatialDropout1D(0.1)(x)\n",
        "  x = Bidirectional(CuDNNLSTM(50, return_sequences=True))(x)\n",
        "  x, x_h, x_c = Bidirectional(CuDNNGRU(50, return_sequences=True, return_state = True))(x)\n",
        "  avg_pool = GlobalAveragePooling1D()(x)\n",
        "  max_pool = GlobalMaxPooling1D()(x)\n",
        "  conc = concatenate([avg_pool, x_h, max_pool])\n",
        "  outp = Dense(1, activation=\"sigmoid\")(conc)    \n",
        "  model = Model(inputs=inp, outputs=outp)\n",
        "  model.compile(loss=BinaryFocalLoss(gamma=2), optimizer=opt, metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7t_Ph6qafOQK",
        "colab_type": "text"
      },
      "source": [
        "## GRU attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyKea_xMkrmP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://github.com/zake7749/DeepToxic\n",
        "from keras.layers import Layer,Lambda\n",
        "from keras import initializers\n",
        "from keras.engine import InputSpec, Layer\n",
        "from keras import backend as K\n",
        "\n",
        "class AttentionWeightedAverage(Layer):\n",
        "    \"\"\"\n",
        "    Computes a weighted average of the different channels across timesteps.\n",
        "    Uses 1 parameter pr. channel to compute the attention value for a single timestep.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, return_attention=False, **kwargs):\n",
        "        self.init = initializers.get('uniform')\n",
        "        self.supports_masking = True\n",
        "        self.return_attention = return_attention\n",
        "        super(AttentionWeightedAverage, self).__init__(** kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.input_spec = [InputSpec(ndim=3)]\n",
        "        assert len(input_shape) == 3\n",
        "\n",
        "        self.W = self.add_weight(shape=(input_shape[2], 1),\n",
        "                                 name='{}_W'.format(self.name),\n",
        "                                 initializer=self.init)\n",
        "        self.trainable_weights = [self.W]\n",
        "        super(AttentionWeightedAverage, self).build(input_shape)\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        # computes a probability distribution over the timesteps\n",
        "        # uses 'max trick' for numerical stability\n",
        "        # reshape is done to avoid issue with Tensorflow\n",
        "        # and 1-dimensional weights\n",
        "        logits = K.dot(x, self.W)\n",
        "        x_shape = K.shape(x)\n",
        "        logits = K.reshape(logits, (x_shape[0], x_shape[1]))\n",
        "        ai = K.exp(logits - K.max(logits, axis=-1, keepdims=True))\n",
        "\n",
        "        # masked timesteps have zero weight\n",
        "        if mask is not None:\n",
        "            mask = K.cast(mask, K.floatx())\n",
        "            ai = ai * mask\n",
        "        att_weights = ai / (K.sum(ai, axis=1, keepdims=True) + K.epsilon())\n",
        "        weighted_input = x * K.expand_dims(att_weights)\n",
        "        result = K.sum(weighted_input, axis=1)\n",
        "        if self.return_attention:\n",
        "            return [result, att_weights]\n",
        "        return result\n",
        "\n",
        "    def get_output_shape_for(self, input_shape):\n",
        "        return self.compute_output_shape(input_shape)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        output_len = input_shape[2]\n",
        "        if self.return_attention:\n",
        "            return [(input_shape[0], output_len), (input_shape[0], input_shape[1])]\n",
        "        return (input_shape[0], output_len)\n",
        "\n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        if isinstance(input_mask, list):\n",
        "            return [None] * len(input_mask)\n",
        "        else:\n",
        "            return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hovBxS5jfRbn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_gru_attn():\n",
        "  inp = Input(shape=(max_len,))\n",
        "  x = Embedding(num_words,embed_size,embeddings_initializer=Constant(embeddings),input_length=max_len,trainable=False)(inp)\n",
        "  x = SpatialDropout1D(0.1)(x)\n",
        "  x = Bidirectional(CuDNNLSTM(50, return_sequences=True))(x)\n",
        "  x = Bidirectional(CuDNNGRU(50, return_sequences=True))(x)\n",
        "  avg_pool = GlobalAveragePooling1D()(x)\n",
        "  max_pool = GlobalMaxPooling1D()(x)\n",
        "  last = Lambda(lambda t: t[:, -1])(x)\n",
        "  attn = AttentionWeightedAverage()(x)\n",
        "  conc = concatenate([avg_pool,  max_pool,last,attn])\n",
        "  outp = Dense(1, activation=\"sigmoid\")(conc)    \n",
        "  model = Model(inputs=inp, outputs=outp)\n",
        "  model.compile(loss=BinaryFocalLoss(gamma=2), optimizer=opt, metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I34DRPLqTVru",
        "colab_type": "text"
      },
      "source": [
        "##TCN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-euqTedTWjY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tcn import TCN\n",
        "\n",
        "def wave_net_activation(x):\n",
        "    # type: (Layer) -> Layer\n",
        "    \"\"\"This method defines the activation used for WaveNet\n",
        "    described in https://deepmind.com/blog/wavenet-generative-model-raw-audio/\n",
        "    Args:\n",
        "        x: The layer we want to apply the activation to\n",
        "    Returns:\n",
        "        A new layer with the wavenet activation applied\n",
        "    \"\"\"\n",
        "    tanh_out = Activation('tanh')(x)\n",
        "    sigm_out = Activation('sigmoid')(x)\n",
        "    return keras.layers.multiply([tanh_out, sigm_out])\n",
        "\n",
        "def model_tcn(embedding_matrix):\n",
        "    \n",
        "    inp = Input(shape=(max_len,))\n",
        "    x = Embedding(num_words,embed_size,embeddings_initializer=Constant(embeddings),input_length=max_len,trainable=False)(inp)\n",
        "    x = SpatialDropout1D(0.1)(x)\n",
        "    x = TCN(128,dilations = [1, 2, 4], return_sequences=True ,name = 'tnc1')(x)\n",
        "    x = wave_net_activation(x)\n",
        "    x = TCN(64,dilations = [1, 2, 4], return_sequences=True, name = 'tnc2')(x)\n",
        "    x = wave_net_activation(x)\n",
        "    #x = TCN(32,dilations = [1, 2, 4], return_sequences=True, activation = 'wavenet',name = 'tnc3')(x)\n",
        "    avg_pool = GlobalAveragePooling1D()(x)\n",
        "    max_pool = GlobalMaxPooling1D()(x)\n",
        "    \n",
        "    conc = concatenate([avg_pool, max_pool])\n",
        "    conc = Dense(64, activation=\"relu\")(conc)\n",
        "    conc = Dense(32, activation=\"relu\")(conc)\n",
        "\n",
        "    conc = Dropout(0.1)(conc)\n",
        "    outp = Dense(1, activation=\"sigmoid\")(conc)    \n",
        "    model = Model(inputs=inp, outputs=outp)\n",
        "    model.compile(loss=BinaryFocalLoss(gamma=2), optimizer=opt, metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wLyuzTtMErl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "class_weights = class_weight.compute_class_weight('balanced',np.unique(labels),labels)\n",
        "class_weights=dict(enumerate(class_weights))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNc6xxspBcTG",
        "colab_type": "text"
      },
      "source": [
        "##KIM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAgtTt9IBfMQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_filters=128\n",
        "def model_kim():\n",
        "  inp = Input(shape=(max_len,))\n",
        "  emb = Embedding(num_words,embed_size,embeddings_initializer=Constant(embeddings),input_length=max_len,trainable=False)(inp)\n",
        "  # Specify each convolution layer and their kernel siz i.e. n-grams \n",
        "  conv1_1 = Conv1D(filters=conv_filters, kernel_size=3)(emb)\n",
        "  btch1_1 = BatchNormalization()(conv1_1)\n",
        "  drp1_1  = Dropout(0.2)(btch1_1)\n",
        "  actv1_1 = Activation('relu')(drp1_1)\n",
        "  glmp1_1 = GlobalMaxPooling1D()(actv1_1)\n",
        "\n",
        "  conv1_2 = Conv1D(filters=conv_filters, kernel_size=4)(emb)\n",
        "  btch1_2 = BatchNormalization()(conv1_2)\n",
        "  drp1_2  = Dropout(0.2)(btch1_2)\n",
        "  actv1_2 = Activation('relu')(drp1_2)\n",
        "  glmp1_2 = GlobalMaxPooling1D()(actv1_2)\n",
        "\n",
        "  conv1_3 = Conv1D(filters=conv_filters, kernel_size=5)(emb)\n",
        "  btch1_3 = BatchNormalization()(conv1_3)\n",
        "  drp1_3  = Dropout(0.2)(btch1_3)\n",
        "  actv1_3 = Activation('relu')(drp1_3)\n",
        "  glmp1_3 = GlobalMaxPooling1D()(actv1_3)\n",
        "\n",
        "  conv1_4 = Conv1D(filters=conv_filters, kernel_size=6)(emb)\n",
        "  btch1_4 = BatchNormalization()(conv1_4)\n",
        "  drp1_4  = Dropout(0.2)(btch1_4)\n",
        "  actv1_4 = Activation('relu')(drp1_4)\n",
        "  glmp1_4 = GlobalMaxPooling1D()(actv1_4)\n",
        "\n",
        "  # Gather all convolution layers\n",
        "  cnct = concatenate([glmp1_1, glmp1_2, glmp1_3, glmp1_4], axis=1)\n",
        "  drp1 = Dropout(0.2)(cnct)\n",
        "\n",
        "  dns1  = Dense(32, activation='relu')(drp1)\n",
        "  btch1 = BatchNormalization()(dns1)\n",
        "  drp2  = Dropout(0.2)(btch1)\n",
        "\n",
        "  out = Dense(1, activation='sigmoid')(drp2)   \n",
        "  model = Model(inputs=inp, outputs=out)\n",
        "  model.compile(loss=BinaryFocalLoss(gamma=2), optimizer=opt, metrics=['accuracy'])\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9WsLKCXzYy9b"
      },
      "source": [
        "# Train model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUygUis5N2yN",
        "colab_type": "text"
      },
      "source": [
        "##GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyLDrkoXMGoi",
        "colab_type": "code",
        "outputId": "a15ce85f-5fbc-4465-c472-e7eaf8155992",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        }
      },
      "source": [
        "gru_model=model_gru()\n",
        "gru_model.fit(x_train,y_train,batch_size=batch_size,epochs=10,verbose=2,class_weight=class_weights,validation_data=(x_val,y_val),callbacks= [clr,])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7260334 samples, validate on 1815084 samples\n",
            "Epoch 1/10\n",
            " - 2323s - loss: 0.0311 - acc: 0.9611 - val_loss: 0.0283 - val_acc: 0.9653\n",
            "Epoch 2/10\n",
            " - 2312s - loss: 0.0281 - acc: 0.9653 - val_loss: 0.0277 - val_acc: 0.9657\n",
            "Epoch 3/10\n",
            " - 2318s - loss: 0.0272 - acc: 0.9666 - val_loss: 0.0270 - val_acc: 0.9668\n",
            "Epoch 4/10\n",
            " - 2314s - loss: 0.0266 - acc: 0.9673 - val_loss: 0.0268 - val_acc: 0.9673\n",
            "Epoch 5/10\n",
            " - 2315s - loss: 0.0262 - acc: 0.9678 - val_loss: 0.0269 - val_acc: 0.9670\n",
            "Epoch 6/10\n",
            " - 2315s - loss: 0.0259 - acc: 0.9682 - val_loss: 0.0269 - val_acc: 0.9671\n",
            "Epoch 7/10\n",
            " - 2314s - loss: 0.0257 - acc: 0.9684 - val_loss: 0.0268 - val_acc: 0.9673\n",
            "Epoch 8/10\n",
            " - 2312s - loss: 0.0255 - acc: 0.9686 - val_loss: 0.0267 - val_acc: 0.9674\n",
            "Epoch 9/10\n",
            " - 2317s - loss: 0.0253 - acc: 0.9688 - val_loss: 0.0268 - val_acc: 0.9674\n",
            "Epoch 10/10\n",
            " - 2313s - loss: 0.0252 - acc: 0.9689 - val_loss: 0.0268 - val_acc: 0.9674\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc51a8ef2e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6h6n7szWzPA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "8e08f518-f3c2-4e22-dd6d-5362801d6d70"
      },
      "source": [
        "model.save_weights(\"/content/drive/My Drive/dataset/OffenseEval2020/data/English/gru_model.h5\")\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-1447950e2b06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/dataset/OffenseEval2020/data/English/gru_model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaW-Uq0Kldp4",
        "colab_type": "text"
      },
      "source": [
        "## GRU attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjPFYBWZlf23",
        "colab_type": "code",
        "outputId": "08225fc2-dad0-491d-b42d-aa43faa3d34f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "attn_gru_model=model_gru_attn()\n",
        "attn_gru_model.fit(x_train,y_train,batch_size=batch_size,epochs=10,verbose=2,class_weight=class_weights,validation_data=(x_val,y_val),callbacks= [clr,])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2516 samples, validate on 444 samples\n",
            "Epoch 1/10\n",
            " - 4s - loss: 0.0996 - acc: 0.8748 - val_loss: 0.0765 - val_acc: 0.8986\n",
            "Epoch 2/10\n",
            " - 3s - loss: 0.0804 - acc: 0.9066 - val_loss: 0.0741 - val_acc: 0.9144\n",
            "Epoch 3/10\n",
            " - 3s - loss: 0.0693 - acc: 0.9205 - val_loss: 0.0750 - val_acc: 0.9122\n",
            "Epoch 4/10\n",
            " - 3s - loss: 0.0602 - acc: 0.9281 - val_loss: 0.0777 - val_acc: 0.9122\n",
            "Epoch 5/10\n",
            " - 3s - loss: 0.0522 - acc: 0.9352 - val_loss: 0.0864 - val_acc: 0.9099\n",
            "Epoch 6/10\n",
            " - 3s - loss: 0.0419 - acc: 0.9471 - val_loss: 0.1056 - val_acc: 0.8446\n",
            "Epoch 7/10\n",
            " - 3s - loss: 0.0339 - acc: 0.9575 - val_loss: 0.1092 - val_acc: 0.9009\n",
            "Epoch 8/10\n",
            " - 3s - loss: 0.0235 - acc: 0.9730 - val_loss: 0.1251 - val_acc: 0.9009\n",
            "Epoch 9/10\n",
            " - 3s - loss: 0.0179 - acc: 0.9813 - val_loss: 0.1492 - val_acc: 0.8874\n",
            "Epoch 10/10\n",
            " - 3s - loss: 0.0162 - acc: 0.9781 - val_loss: 0.1385 - val_acc: 0.8986\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa82c7ab6d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlFNurr4T1rh",
        "colab_type": "text"
      },
      "source": [
        "##TCN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKtfxHFBT2wB",
        "colab_type": "code",
        "outputId": "0e593b4f-fae0-4fec-abe2-22f9bee7fefb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "tcn_model=model_tcn(embeddings)\n",
        "tcn_model.fit(x_train,y_train,batch_size=batch_size,epochs=10,verbose=2,class_weight=class_weights,validation_data=(x_val,y_val),callbacks= [clr,])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2516 samples, validate on 444 samples\n",
            "Epoch 1/10\n",
            " - 4s - loss: 0.1361 - acc: 0.8581 - val_loss: 0.1046 - val_acc: 0.8694\n",
            "Epoch 2/10\n",
            " - 1s - loss: 0.1106 - acc: 0.8704 - val_loss: 0.1030 - val_acc: 0.8694\n",
            "Epoch 3/10\n",
            " - 1s - loss: 0.1089 - acc: 0.8704 - val_loss: 0.1029 - val_acc: 0.8694\n",
            "Epoch 4/10\n",
            " - 1s - loss: 0.1105 - acc: 0.8704 - val_loss: 0.1029 - val_acc: 0.8694\n",
            "Epoch 5/10\n",
            " - 1s - loss: 0.1074 - acc: 0.8704 - val_loss: 0.1031 - val_acc: 0.8694\n",
            "Epoch 6/10\n",
            " - 1s - loss: 0.1090 - acc: 0.8704 - val_loss: 0.1043 - val_acc: 0.8694\n",
            "Epoch 7/10\n",
            " - 1s - loss: 0.1073 - acc: 0.8704 - val_loss: 0.1032 - val_acc: 0.8694\n",
            "Epoch 8/10\n",
            " - 1s - loss: 0.1099 - acc: 0.8704 - val_loss: 0.1029 - val_acc: 0.8694\n",
            "Epoch 9/10\n",
            " - 1s - loss: 0.1089 - acc: 0.8704 - val_loss: 0.1038 - val_acc: 0.8694\n",
            "Epoch 10/10\n",
            " - 1s - loss: 0.1066 - acc: 0.8704 - val_loss: 0.1031 - val_acc: 0.8694\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa82c0cdba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tr_J6FWTCYXB",
        "colab_type": "text"
      },
      "source": [
        "##KIM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgmUF8liCa4M",
        "colab_type": "code",
        "outputId": "5703b418-a12f-404e-bbfa-cb0e5b5c0be6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "kim_model=model_kim()\n",
        "kim_model.fit(x_train,y_train,batch_size=batch_size,epochs=10,verbose=2,class_weight=class_weights,validation_data=(x_val,y_val),callbacks= [clr,])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2516 samples, validate on 444 samples\n",
            "Epoch 1/10\n",
            " - 3s - loss: 0.1258 - acc: 0.8450 - val_loss: 0.1210 - val_acc: 0.8491\n",
            "Epoch 2/10\n",
            " - 1s - loss: 0.1050 - acc: 0.8653 - val_loss: 0.1041 - val_acc: 0.8694\n",
            "Epoch 3/10\n",
            " - 1s - loss: 0.0971 - acc: 0.8696 - val_loss: 0.1098 - val_acc: 0.8694\n",
            "Epoch 4/10\n",
            " - 1s - loss: 0.0801 - acc: 0.8859 - val_loss: 0.1134 - val_acc: 0.8694\n",
            "Epoch 5/10\n",
            " - 1s - loss: 0.0762 - acc: 0.8986 - val_loss: 0.1004 - val_acc: 0.8761\n",
            "Epoch 6/10\n",
            " - 1s - loss: 0.0627 - acc: 0.9141 - val_loss: 0.1112 - val_acc: 0.8761\n",
            "Epoch 7/10\n",
            " - 1s - loss: 0.0514 - acc: 0.9277 - val_loss: 0.0882 - val_acc: 0.8919\n",
            "Epoch 8/10\n",
            " - 1s - loss: 0.0497 - acc: 0.9348 - val_loss: 0.1003 - val_acc: 0.8941\n",
            "Epoch 9/10\n",
            " - 1s - loss: 0.0419 - acc: 0.9444 - val_loss: 0.1082 - val_acc: 0.8874\n",
            "Epoch 10/10\n",
            " - 1s - loss: 0.0363 - acc: 0.9535 - val_loss: 0.1015 - val_acc: 0.8874\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa816f6ecf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRW2JWbBMfkb",
        "colab_type": "text"
      },
      "source": [
        "# Validate Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7BVpvPJOH5x",
        "colab_type": "text"
      },
      "source": [
        "##GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gd85B8kuMWU1",
        "colab_type": "code",
        "outputId": "8655cc0b-2243-489d-fffd-6c868e8e0737",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "source": [
        "y_pred = gru_model.predict(x_val, batch_size=batch_size, verbose=1)\n",
        "y_pred = (y_pred > 0.5)\n",
        "print(classification_report(y_val, y_pred))\n",
        "gru_f1=f1_score(y_val, y_pred,average='macro')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1815084/1815084 [==============================] - 192s 106us/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98   1525730\n",
            "           1       0.93      0.86      0.89    289354\n",
            "\n",
            "    accuracy                           0.97   1815084\n",
            "   macro avg       0.95      0.93      0.94   1815084\n",
            "weighted avg       0.97      0.97      0.97   1815084\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snrLZrtdxheq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "0e935914-6085-408f-e1b7-40b929d519f9"
      },
      "source": [
        "y_test_gru = gru_model.predict(X_test_sequences, batch_size=batch_size, verbose=1).ravel()\n",
        "np.save('/content/drive/My Drive/dataset/OffenseEval2020/data/English/prediction_files/y_test_gru.npy',y_test_gru)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3887/3887 [==============================] - 1s 141us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQQUnhy-ljKa",
        "colab_type": "text"
      },
      "source": [
        "## GRU attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJvhOCgEllGM",
        "colab_type": "code",
        "outputId": "c5631623-a0a9-4b0c-a9a4-cb495092e8c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "y_pred = attn_gru_model.predict(x_val, batch_size=batch_size, verbose=1)\n",
        "y_pred = (y_pred > 0.5)\n",
        "print(classification_report(y_val, y_pred))\n",
        "gru_atten_f1=f1_score(y_val, y_pred,average='macro')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "444/444 [==============================] - 1s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.96      0.94       386\n",
            "           1       0.66      0.47      0.55        58\n",
            "\n",
            "    accuracy                           0.90       444\n",
            "   macro avg       0.79      0.71      0.74       444\n",
            "weighted avg       0.89      0.90      0.89       444\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PmqHy-HWeuQ",
        "colab_type": "text"
      },
      "source": [
        "##TCN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8SxnEBRWf-R",
        "colab_type": "code",
        "outputId": "8720d56b-78d0-448a-e7c4-a95b276dd719",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "y_pred = tcn_model.predict(x_val, batch_size=batch_size, verbose=1)\n",
        "y_pred = (y_pred > 0.5)\n",
        "print(classification_report(y_val, y_pred))\n",
        "tcn_f1=f1_score(y_val, y_pred,average='macro')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "444/444 [==============================] - 1s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       386\n",
            "           1       0.00      0.00      0.00        58\n",
            "\n",
            "    accuracy                           0.87       444\n",
            "   macro avg       0.43      0.50      0.47       444\n",
            "weighted avg       0.76      0.87      0.81       444\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ix_QKjbbC7ub",
        "colab_type": "text"
      },
      "source": [
        "##KIM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0McQOe5pC8oQ",
        "colab_type": "code",
        "outputId": "7a50431a-a044-4db5-f318-cf817c759813",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "y_pred = kim_model.predict(x_val, batch_size=batch_size, verbose=1)\n",
        "y_pred = (y_pred > 0.5)\n",
        "print(classification_report(y_val, y_pred))\n",
        "kim_f1=f1_score(y_val, y_pred,average='macro')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "444/444 [==============================] - 1s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.97      0.94       386\n",
            "           1       0.64      0.31      0.42        58\n",
            "\n",
            "    accuracy                           0.89       444\n",
            "   macro avg       0.77      0.64      0.68       444\n",
            "weighted avg       0.87      0.89      0.87       444\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFxd_0Jbg95C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XP-W9arzp3H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXd8VkdPhAq2",
        "colab_type": "text"
      },
      "source": [
        "# Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBp341Qog_uv",
        "colab_type": "code",
        "outputId": "e3093208-a7f4-4ea7-8817-021a5ed99837",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "print('f1 score of count vec' ,cv_f1)\n",
        "print('f1 score of word tfidf' ,tfw_f1)\n",
        "print('f1 score of char tfidf' ,tfc_f1)\n",
        "\n",
        "print('f1 score of RNN' ,gru_f1)\n",
        "print('f1 score of gated attention', gru_atten_f1)\n",
        "print('f1 score of tcn',tcn_f1)\n",
        "print('f1 score of vdcnn', vdcnn_f1)\n",
        "print('f1 score of kim',kim_f1)\n",
        "print('f1 score of char cnn',char_f1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1 score of count vec 0.7583593283334439\n",
            "f1 score of word tfidf 0.5159276071917062\n",
            "f1 score of char tfidf 0.5318284777005389\n",
            "f1 score of RNN 0.7309257312472945\n",
            "f1 score of gated attention 0.744210162461113\n",
            "f1 score of tcn 0.4650602409638554\n",
            "f1 score of vdcnn 0.4650602409638554\n",
            "f1 score of kim 0.678130255755959\n",
            "f1 score of char cnn 0.4650602409638554\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DW1OugTMEpZg",
        "colab_type": "text"
      },
      "source": [
        "# Ensemble"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6VT0aVcUIhm",
        "colab_type": "text"
      },
      "source": [
        "we will choose only those, having f1 greater than 0.7. Once they are selected, we will decode labels, and keep label according to mod"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0lFlc4nY70O",
        "colab_type": "code",
        "outputId": "6643b06b-4d5e-4709-c96c-54425c6f126f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "y_test_cv = cv_classifier.predict_proba(X_test_cv)[:,1]\n",
        "# y_test_tfw = tfw_classifier.predict_proba(test_word_features)[:,1]\n",
        "# y_test_tfc = tfc_classifier.predict_proba(test_char_features)[:,1]\n",
        "\n",
        "y_test_gru = gru_model.predict(X_test_sequences, batch_size=batch_size, verbose=1).ravel()\n",
        "y_test_gru_atten = attn_gru_model.predict(X_test_sequences, batch_size=batch_size, verbose=1).ravel()\n",
        "# y_test_tcn = tcn_model.predict(X_test_sequences, batch_size=batch_size, verbose=1).ravel()\n",
        "# y_test_vdcnn = vdcnn_model.predict(X_test_sequences, batch_size=batch_size, verbose=1).ravel()\n",
        "y_test_kim = kim_model.predict(X_test_sequences, batch_size=batch_size, verbose=1).ravel()\n",
        "# y_test_char = char_model.predict(X_test_sequences, batch_size=batch_size, verbose=1).ravel()\n",
        "# # # "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "329/329 [==============================] - 0s 449us/step\n",
            "329/329 [==============================] - 0s 423us/step\n",
            "329/329 [==============================] - 0s 152us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wmQlS5LkZLi",
        "colab_type": "code",
        "outputId": "722fe77e-57dd-4fd5-c956-a32a6241c22c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "f=np.array([0.75,0.73,0.74,0.67])\n",
        "f/np.sum(f)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.25951557, 0.25259516, 0.25605536, 0.23183391])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkCLYtxOcXCA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#i am bit changing the distribution in order to give more weightage to ml than dl\n",
        "y_test=0.3*y_test_cv+0.25*y_test_gru+0.25*y_test_gru_atten+0.2*y_test_kim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9Pu0LvuZIf8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode(y_test):\n",
        "  y_test[y_test>0.5]=1\n",
        "  y_test[y_test<0.5]=0\n",
        "  y_test=y_test.astype('int16').ravel()\n",
        "\n",
        "  y_test=le.inverse_transform(y_test)\n",
        "  y_test=pd.DataFrame(y_test,columns=['label'])\n",
        "  y_test=pd.concat([ids, y_test['label']], axis=1)\n",
        "  return y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PgV77IYZRGP",
        "colab_type": "code",
        "outputId": "257c23a7-d167-4cca-c729-1d6a0214a8a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "y_test=decode(y_test)\n",
        "y_test.head()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1382</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1384</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>547</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1269</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1695</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id label\n",
              "0  1382   NOT\n",
              "1  1384   NOT\n",
              "2   547   NOT\n",
              "3  1269   NOT\n",
              "4  1695   NOT"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8avMmBQvb_IR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dl57zICXM4c6",
        "colab_type": "text"
      },
      "source": [
        "# Submit file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LkCxvtfEnpl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHTCw4_jP_tr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test.to_csv('/content/weighted.csv',index=False,header=None)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tPo96DUz_EZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwKb7_NBWjAv",
        "colab_type": "text"
      },
      "source": [
        "# Reset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0Xi3s2KWlKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import keras\n",
        "# keras.backend.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T39YK5rbQBoT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}