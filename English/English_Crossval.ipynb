{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "English Crossval.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "FwKb7_NBWjAv"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/talhaanwarch/OffenseEval2020/blob/master/English/English_Crossval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd_N71KlcyII",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 856
        },
        "outputId": "1685dabd-2c33-48c5-a568-d51b4b52cf0a"
      },
      "source": [
        "!pip install focal-loss\n",
        "#!pip install keras-tcn==2.8.3\n",
        "!pip install keras-tcn\n",
        "!pip install tensorflow==2.1.0\n",
        "#!pip install git+https://github.com/philipperemy/keras-tcn.git\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: focal-loss in /usr/local/lib/python3.6/dist-packages (0.0.2)\n",
            "Requirement already satisfied: keras-tcn in /usr/local/lib/python3.6/dist-packages (3.0.1)\n",
            "Requirement already satisfied: keras>=2.3.1 in /usr/local/lib/python3.6/dist-packages (from keras-tcn) (2.3.1)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from keras-tcn) (0.2.2)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.6/dist-packages (from keras-tcn) (1.18.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.3.1->keras-tcn) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras>=2.3.1->keras-tcn) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras>=2.3.1->keras-tcn) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras>=2.3.1->keras-tcn) (1.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras>=2.3.1->keras-tcn) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras>=2.3.1->keras-tcn) (1.1.0)\n",
            "Collecting tensorflow==2.1.0\n",
            "  Using cached https://files.pythonhosted.org/packages/85/d4/c0cd1057b331bc38b65478302114194bd8e1b9c2bbc06e300935c0e93d90/tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.11.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.0.8)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.1.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (2.1.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.34.2)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.2.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.12.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.10.0)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.18.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.9.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (2.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.27.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1.0) (2.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.7.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (45.1.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.2.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.21.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.0.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.3.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.24.3)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.0)\n",
            "Installing collected packages: tensorflow\n",
            "Successfully installed tensorflow-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiDAUbMhubEc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "# tf.enable_eager_execution()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRdg5W5ZgMhM",
        "colab_type": "code",
        "outputId": "a503cdb1-bc9a-43b7-a962-c3d4cf7312cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6Q3msMuLDpE",
        "colab_type": "text"
      },
      "source": [
        "# Import lib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpTHlh_QLDL7",
        "colab_type": "code",
        "outputId": "00842657-ff32-44ce-e464-141b76a56941",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential,Model\n",
        "\n",
        "from tensorflow.keras.layers import Embedding,GRU,LSTM,Dense,Dropout,Bidirectional,BatchNormalization,GlobalMaxPooling1D,Flatten, GlobalAveragePooling1D, MaxPooling1D,SpatialDropout1D,Input,Activation,concatenate,Conv1D,multiply\n",
        "from tensorflow.keras.optimizers import RMSprop,Adam,Adadelta\n",
        "from tensorflow.keras.initializers import Constant\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import classification_report,f1_score\n",
        "# import keras\n",
        "import collections\n",
        "import numpy as np\n",
        "from focal_loss import BinaryFocalLoss\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from tensorflow.keras import backend as K\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "from tensorflow.keras.layers import Layer,Lambda,InputSpec\n",
        "from tensorflow.keras import initializers\n",
        "from tensorflow.keras import backend as K\n",
        "# import tensorflow as tf\n",
        "# tf.logging.set_verbosity(tf.logging.ERROR)\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Udk8qWz-K4cx",
        "colab_type": "text"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lx-1BQaY6rkq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "9c8f5360-285e-44f7-a858-8dfca2b0ab77"
      },
      "source": [
        "train=pd.read_csv( '/content/drive/My Drive/dataset/OLID/data/olid-training-v1.0.tsv',sep=\"\\t\")\n",
        "train.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>subtask_a</th>\n",
              "      <th>subtask_b</th>\n",
              "      <th>subtask_c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>86426</td>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>90194</td>\n",
              "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>TIN</td>\n",
              "      <td>IND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16820</td>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>62688</td>\n",
              "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>43605</td>\n",
              "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                              tweet  ... subtask_b subtask_c\n",
              "0  86426  @USER She should ask a few native Americans wh...  ...       UNT       NaN\n",
              "1  90194  @USER @USER Go home you’re drunk!!! @USER #MAG...  ...       TIN       IND\n",
              "2  16820  Amazon is investigating Chinese employees who ...  ...       NaN       NaN\n",
              "3  62688  @USER Someone should'veTaken\" this piece of sh...  ...       UNT       NaN\n",
              "4  43605  @USER @USER Obama wanted liberals &amp; illega...  ...       NaN       NaN\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsyaJHD98Fdn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "001fb659-64f8-4f52-845e-7e2212601432"
      },
      "source": [
        "val=pd.read_csv('/content/drive/My Drive/dataset/OLID/data/testset-levela.tsv',sep=\"\\t\")\n",
        "val_labels=pd.read_csv('/content/drive/My Drive/dataset/OLID/data/labels-levela.csv',sep=\",\",header=None)\n",
        "val_labels.columns=['idx','subtask_a']\n",
        "#val_labels.head()\n",
        "val=pd.concat([val,val_labels],axis=1)\n",
        "val.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>idx</th>\n",
              "      <th>subtask_a</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15923</td>\n",
              "      <td>#WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...</td>\n",
              "      <td>15923</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27014</td>\n",
              "      <td>#ConstitutionDay is revered by Conservatives, ...</td>\n",
              "      <td>27014</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>30530</td>\n",
              "      <td>#FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...</td>\n",
              "      <td>30530</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13876</td>\n",
              "      <td>#Watching #Boomer getting the news that she is...</td>\n",
              "      <td>13876</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60133</td>\n",
              "      <td>#NoPasaran: Unity demo to oppose the far-right...</td>\n",
              "      <td>60133</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                              tweet    idx subtask_a\n",
              "0  15923  #WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...  15923       OFF\n",
              "1  27014  #ConstitutionDay is revered by Conservatives, ...  27014       NOT\n",
              "2  30530  #FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...  30530       NOT\n",
              "3  13876  #Watching #Boomer getting the news that she is...  13876       NOT\n",
              "4  60133  #NoPasaran: Unity demo to oppose the far-right...  60133       OFF"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mv31K9V2h41l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels=train['subtask_a']\n",
        "train=train['tweet']\n",
        "\n",
        "\n",
        "val_labels=val['subtask_a']\n",
        "val=val['tweet']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIoM04y68Pwd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train=pd.concat([train,val])\n",
        "labels=pd.concat([train_labels,val_labels])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c58qlJvAih8C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpKtr-fN64Tw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "827ed1de-a452-4844-be44-59441fc8d85d"
      },
      "source": [
        "test=pd.read_csv( '/content/drive/My Drive/dataset/OffenseEval2020/data/English/test_a_tweets.tsv',sep=\"\\t\")\n",
        "test.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A0</td>\n",
              "      <td>¿Who the fuck is Yoru?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A1</td>\n",
              "      <td>@USER @USER He's an evil law breaker that shou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A2</td>\n",
              "      <td>Now hiring for 49 #Labor job opportunities in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A3</td>\n",
              "      <td>#NerkondaPaarvai' - As Of Now, There Is NO Ear...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A4</td>\n",
              "      <td>@USER Hahahaha I wish...but a week is good, I’...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                              tweet\n",
              "0  A0                             ¿Who the fuck is Yoru?\n",
              "1  A1  @USER @USER He's an evil law breaker that shou...\n",
              "2  A2  Now hiring for 49 #Labor job opportunities in ...\n",
              "3  A3  #NerkondaPaarvai' - As Of Now, There Is NO Ear...\n",
              "4  A4  @USER Hahahaha I wish...but a week is good, I’..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMbpcevIl7g9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
        "stop = stopwords.words('english')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6LRT-poitAn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "outputId": "5b635c88-2f6a-4b78-9982-e5ce94e433c7"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    @USER She should ask a few native Americans wh...\n",
              "1    @USER @USER Go home you’re drunk!!! @USER #MAG...\n",
              "2    Amazon is investigating Chinese employees who ...\n",
              "3    @USER Someone should'veTaken\" this piece of sh...\n",
              "4    @USER @USER Obama wanted liberals &amp; illega...\n",
              "Name: tweet, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YY8MVlxhggiD",
        "colab_type": "code",
        "outputId": "d363b75f-12fc-4f8a-fd04-9f5d50c605a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "\n",
        "train=train.str.replace('\\d+', '')\n",
        "train=train.str.replace('@USER', \"\") \n",
        "train=train.str.replace('URL', '')\n",
        "train= train.str.lower()\n",
        "#train = train.str.replace('[^\\w\\s]','')\n",
        "#train = train.apply(lambda x : [lemmatizer.lemmatize(y) for y in w_tokenizer.tokenize(x)])\n",
        "#train = train.apply(lambda x: [item for item in x if item not in stop])\n",
        "#train = train.apply(lambda x : \" \".join(x))\n",
        "train.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     she should ask a few native americans what th...\n",
              "1          go home you’re drunk!!!  #maga #trump 👊🇺🇸👊 \n",
              "2    amazon is investigating chinese employees who ...\n",
              "3     someone should'vetaken\" this piece of shit to...\n",
              "4      obama wanted liberals &amp; illegals to move...\n",
              "Name: tweet, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdwHh_q_LLus",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "fae1e11a-2d59-44dd-f3d6-7ffb1eb787be"
      },
      "source": [
        "\n",
        "test['tweet']=test['tweet'].str.replace('\\d+', '')\n",
        "test['tweet']=test['tweet'].str.replace('@USER', \"\") \n",
        "test['tweet']=test['tweet'].str.replace('URL', '')\n",
        "test[\"tweet\"]= test[\"tweet\"].str.lower()\n",
        "# test[\"tweet\"] = test[\"tweet\"].str.replace('[^\\w\\s]','')\n",
        "# test[\"tweet\"] = test[\"tweet\"].apply(lambda x : [lemmatizer.lemmatize(y) for y in w_tokenizer.tokenize(x)])\n",
        "# test[\"tweet\"] = test[\"tweet\"].apply(lambda x: [item for item in x if item not in stop])\n",
        "# test[\"tweet\"] = test[\"tweet\"].apply(lambda x : \" \".join(x))\n",
        "test.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A0</td>\n",
              "      <td>¿who the fuck is yoru?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A1</td>\n",
              "      <td>he's an evil law breaker that should be in p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A2</td>\n",
              "      <td>now hiring for  #labor job opportunities in #m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A3</td>\n",
              "      <td>#nerkondapaarvai' - as of now, there is no ear...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A4</td>\n",
              "      <td>hahahaha i wish...but a week is good, i’m ext...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                              tweet\n",
              "0  A0                             ¿who the fuck is yoru?\n",
              "1  A1    he's an evil law breaker that should be in p...\n",
              "2  A2  now hiring for  #labor job opportunities in #m...\n",
              "3  A3  #nerkondapaarvai' - as of now, there is no ear...\n",
              "4  A4   hahahaha i wish...but a week is good, i’m ext..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUFczyikLeYO",
        "colab_type": "text"
      },
      "source": [
        "#Label Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFPv0_zdLnlS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test=test['tweet']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCtBGu-B_kgZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "outputId": "1fd1bc92-5090-435f-8f1c-89a846a18cf9"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     she should ask a few native americans what th...\n",
              "1          go home you’re drunk!!!  #maga #trump 👊🇺🇸👊 \n",
              "2    amazon is investigating chinese employees who ...\n",
              "3     someone should'vetaken\" this piece of shit to...\n",
              "4      obama wanted liberals &amp; illegals to move...\n",
              "Name: tweet, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9PjbFwJLiNA",
        "colab_type": "code",
        "outputId": "2921fb1a-d311-40ee-82de-3624ccb2a83f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "le=LabelEncoder()\n",
        "labels=le.fit_transform(labels)\n",
        "print(len(labels))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqsY34bMheqV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_bert=train.copy()\n",
        "test_bert=test.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ek_ZUjDef7ZV",
        "colab_type": "text"
      },
      "source": [
        "# Common Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdtjDLnOACbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "class_weights = class_weight.compute_class_weight('balanced',np.unique(labels),labels)\n",
        "class_weights=dict(enumerate(class_weights))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-IToeBciV1m",
        "colab_type": "text"
      },
      "source": [
        "## Cylic learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIYW6ZAniXzU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "a08cf098-b1cd-4527-c526-17d73273b86b"
      },
      "source": [
        "# https://www.kaggle.com/hireme/fun-api-keras-f1-metric-cyclical-learning-rate/code\n",
        "from keras.callbacks import Callback\n",
        "class CyclicLR(Callback):\n",
        "    \"\"\"This callback implements a cyclical learning rate policy (CLR).\n",
        "    The method cycles the learning rate between two boundaries with\n",
        "    some constant frequency, as detailed in this paper (https://arxiv.org/abs/1506.01186).\n",
        "    The amplitude of the cycle can be scaled on a per-iteration or \n",
        "    per-cycle basis.\n",
        "    This class has three built-in policies, as put forth in the paper.\n",
        "    \"triangular\":\n",
        "        A basic triangular cycle w/ no amplitude scaling.\n",
        "    \"triangular2\":\n",
        "        A basic triangular cycle that scales initial amplitude by half each cycle.\n",
        "    \"exp_range\":\n",
        "        A cycle that scales initial amplitude by gamma**(cycle iterations) at each \n",
        "        cycle iteration.\n",
        "    For more detail, please see paper.\n",
        "    \n",
        "    # Example\n",
        "        ```python\n",
        "            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
        "                                step_size=2000., mode='triangular')\n",
        "            model.fit(X_train, Y_train, callbacks=[clr])\n",
        "        ```\n",
        "    \n",
        "    Class also supports custom scaling functions:\n",
        "        ```python\n",
        "            clr_fn = lambda x: 0.5*(1+np.sin(x*np.pi/2.))\n",
        "            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
        "                                step_size=2000., scale_fn=clr_fn,\n",
        "                                scale_mode='cycle')\n",
        "            model.fit(X_train, Y_train, callbacks=[clr])\n",
        "        ```    \n",
        "    # Arguments\n",
        "        base_lr: initial learning rate which is the\n",
        "            lower boundary in the cycle.\n",
        "        max_lr: upper boundary in the cycle. Functionally,\n",
        "            it defines the cycle amplitude (max_lr - base_lr).\n",
        "            The lr at any cycle is the sum of base_lr\n",
        "            and some scaling of the amplitude; therefore \n",
        "            max_lr may not actually be reached depending on\n",
        "            scaling function.\n",
        "        step_size: number of training iterations per\n",
        "            half cycle. Authors suggest setting step_size\n",
        "            2-8 x training iterations in epoch.\n",
        "        mode: one of {triangular, triangular2, exp_range}.\n",
        "            Default 'triangular'.\n",
        "            Values correspond to policies detailed above.\n",
        "            If scale_fn is not None, this argument is ignored.\n",
        "        gamma: constant in 'exp_range' scaling function:\n",
        "            gamma**(cycle iterations)\n",
        "        scale_fn: Custom scaling policy defined by a single\n",
        "            argument lambda function, where \n",
        "            0 <= scale_fn(x) <= 1 for all x >= 0.\n",
        "            mode paramater is ignored \n",
        "        scale_mode: {'cycle', 'iterations'}.\n",
        "            Defines whether scale_fn is evaluated on \n",
        "            cycle number or cycle iterations (training\n",
        "            iterations since start of cycle). Default is 'cycle'.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=2000., mode='triangular',\n",
        "                 gamma=1., scale_fn=None, scale_mode='cycle'):\n",
        "        super(CyclicLR, self).__init__()\n",
        "\n",
        "        self.base_lr = base_lr\n",
        "        self.max_lr = max_lr\n",
        "        self.step_size = step_size\n",
        "        self.mode = mode\n",
        "        self.gamma = gamma\n",
        "        if scale_fn == None:\n",
        "            if self.mode == 'triangular':\n",
        "                self.scale_fn = lambda x: 1.\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'triangular2':\n",
        "                self.scale_fn = lambda x: 1/(2.**(x-1))\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'exp_range':\n",
        "                self.scale_fn = lambda x: gamma**(x)\n",
        "                self.scale_mode = 'iterations'\n",
        "        else:\n",
        "            self.scale_fn = scale_fn\n",
        "            self.scale_mode = scale_mode\n",
        "        self.clr_iterations = 0.\n",
        "        self.trn_iterations = 0.\n",
        "        self.history = {}\n",
        "\n",
        "        self._reset()\n",
        "\n",
        "    def _reset(self, new_base_lr=None, new_max_lr=None,\n",
        "               new_step_size=None):\n",
        "        \"\"\"Resets cycle iterations.\n",
        "        Optional boundary/step size adjustment.\n",
        "        \"\"\"\n",
        "        if new_base_lr != None:\n",
        "            self.base_lr = new_base_lr\n",
        "        if new_max_lr != None:\n",
        "            self.max_lr = new_max_lr\n",
        "        if new_step_size != None:\n",
        "            self.step_size = new_step_size\n",
        "        self.clr_iterations = 0.\n",
        "        \n",
        "    def clr(self):\n",
        "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
        "        x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
        "        if self.scale_mode == 'cycle':\n",
        "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(cycle)\n",
        "        else:\n",
        "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(self.clr_iterations)\n",
        "        \n",
        "    def on_train_begin(self, logs={}):\n",
        "        logs = logs or {}\n",
        "\n",
        "        if self.clr_iterations == 0:\n",
        "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
        "        else:\n",
        "            K.set_value(self.model.optimizer.lr, self.clr())        \n",
        "            \n",
        "    def on_batch_end(self, epoch, logs=None):\n",
        "        \n",
        "        logs = logs or {}\n",
        "        self.trn_iterations += 1\n",
        "        self.clr_iterations += 1\n",
        "\n",
        "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
        "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
        "\n",
        "        for k, v in logs.items():\n",
        "            self.history.setdefault(k, []).append(v)\n",
        "        \n",
        "        K.set_value(self.model.optimizer.lr, self.clr())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIcxIjeYjHyo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clr = CyclicLR(base_lr=0.001, max_lr=0.005,\n",
        "                        step_size=4., mode='exp_range',\n",
        "                        gamma=0.99994)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAv_EEaQLXtY",
        "colab_type": "text"
      },
      "source": [
        "# Tokenize data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QomCkNlRLHPG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "max_words = 10000 #frequency of words to be kept\n",
        "max_len = 150\n",
        "\n",
        "tokenize = Tokenizer(num_words=max_words)\n",
        "tokenize.fit_on_texts(pd.concat([train,test]))\n",
        "sequences = tokenize.texts_to_sequences(train)\n",
        "word_index = tokenize.word_index\n",
        "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len,padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og1W2rCOLs4w",
        "colab_type": "code",
        "outputId": "b57ab690-833f-4d27-a7e5-9322601be8d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "len(sequences_matrix),len(labels)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14100, 14100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4kzu1RxLyGk",
        "colab_type": "code",
        "outputId": "e62c1330-772f-4600-918d-8cb1a824844f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "num_words = min(max_words, len(word_index)) + 1\n",
        "print(num_words)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4i7WSY3lMmdp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_sequences = tokenize.texts_to_sequences(test)\n",
        "X_test_sequences = sequence.pad_sequences(test_sequences,maxlen=max_len,padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRZxav1WNle-",
        "colab_type": "code",
        "outputId": "d440b4fc-36ba-44ec-d97b-63b2fff1826a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "len(X_test_sequences)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3887"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpzUIu4iL0PO",
        "colab_type": "text"
      },
      "source": [
        "# Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UASiPIPlnZKP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_path1 = \"drive/My Drive/dataset/OLID/wiki-news-300d-1M.vec\"\n",
        "embedding_path2 = \"drive/My Drive/dataset/OLID/glove/glove.840B.300d.txt\"\n",
        "embed_size = 300"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3UFPJAWL10_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_coefs(word,*arr):\n",
        "    return word, np.asarray(arr, dtype='float32')\n",
        "\n",
        "def build_matrix(embedding_path, word_index):\n",
        "    embedding_index = dict(get_coefs(*o.strip().split(\" \")) for o in open(embedding_path))\n",
        "\n",
        "    nb_words = min(max_words, len(word_index))\n",
        "    embedding_matrix = np.zeros((nb_words + 1, embed_size))\n",
        "    for word, i in word_index.items():\n",
        "        if i >= max_words:\n",
        "            continue\n",
        "        embedding_vector = embedding_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "    return embedding_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTviPXodLzRW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fasttext=build_matrix(embedding_path1, word_index)\n",
        "glove_emb=build_matrix(embedding_path2, word_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWgNaYzPnf2C",
        "colab_type": "code",
        "outputId": "973ebc43-813d-4c2a-b6cf-b8c1b60ea3f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "embeddings=np.mean((fasttext,glove_emb),axis=0)\n",
        "embeddings.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10001, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Csvc4vdey4x9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#np.save('/content/drive/My Drive/dataset/OffenseEval2020/data/English/en_embeddings.npy',embeddings)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8_AdRhffkS3",
        "colab_type": "text"
      },
      "source": [
        "# Base Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaShFhtgJ_Ef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.shape,labels.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvXD0v5mfm7M",
        "colab_type": "text"
      },
      "source": [
        "## Count Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7blhzyaD-xvK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def logistic_param_selection(X, y, func,nfolds):\n",
        "    C= [7,8,9,10,12,15,20,25]\n",
        "    param_grid = {'C': C}\n",
        "    grid_search = GridSearchCV(make_pipeline(func, LogisticRegression(solver='lbfgs',max_iter=500,class_weight=class_weights)),\n",
        "                    param_grid={'logisticregression__C':C}, cv=nfolds,scoring='f1_macro')\n",
        "    grid_search.fit(X, y)\n",
        "    return grid_search.best_score_,grid_search.best_params_\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHFZoqkGI79e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv_score,c=logistic_param_selection(train,labels,CountVectorizer(),5)\n",
        "cv_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiDB13I898UU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count_vectorizer = CountVectorizer()\n",
        "count_vectorizer.fit(train)\n",
        "X_train_cv = count_vectorizer.transform(train)\n",
        "X_test_cv=  count_vectorizer.transform(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwXHpKqo-cFB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv_classifier = LogisticRegression(solver='lbfgs',C=c['logisticregression__C'],max_iter=500,class_weight=class_weights)\n",
        "cv_classifier.fit(X_train_cv, labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBx50ckVP6iP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv_test=cv_classifier.predict_proba(X_test_cv)[:,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJDyK1lahqqG",
        "colab_type": "text"
      },
      "source": [
        "## TF IDF word vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gz1WZZEufmEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "word_vectorizer = TfidfVectorizer(\n",
        "    sublinear_tf=True,\n",
        "    strip_accents='unicode',\n",
        "    analyzer='word',\n",
        "    token_pattern=r'\\w{1,}',\n",
        "    ngram_range=(1, 4),\n",
        "    max_features=10000)\n",
        "word_vectorizer.fit(pd.concat([train, test]))\n",
        "train_word_features = word_vectorizer.transform(train)\n",
        "test_word_features = word_vectorizer.transform(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8hxtqPQ_KxI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfw_score,c=logistic_param_selection(train,labels,word_vectorizer,5)\n",
        "tfw_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04JmMwoEh4-d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfw_classifier = LogisticRegression(solver='lbfgs',C=c['logisticregression__C'],max_iter=500)\n",
        "tfw_classifier.fit(train_word_features, labels)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQRy9oaBQIfV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfw_test = tfw_classifier.predict_proba(test_word_features)[:,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNSvwaG1ioq0",
        "colab_type": "text"
      },
      "source": [
        "## TF IDF char vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_kqct6jiBq1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "char_vectorizer = TfidfVectorizer(\n",
        "    sublinear_tf=True,\n",
        "    strip_accents='unicode',\n",
        "    analyzer='char',\n",
        "    ngram_range=(1, 6),\n",
        "    max_features=30000)\n",
        "char_vectorizer.fit(train)\n",
        "train_char_features = char_vectorizer.transform(train)\n",
        "test_char_features = char_vectorizer.transform(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBU8cBQVCiAI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfc_score,c=logistic_param_selection(train,labels,char_vectorizer,5)\n",
        "tfc_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYhzRPO0iRMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfc_classifier = LogisticRegression(solver='lbfgs',C=c['logisticregression__C'],max_iter=500)\n",
        "tfc_classifier.fit(train_char_features, labels)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpkjinLBXX7j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfc_test = tfc_classifier.predict_proba(test_char_features)[:,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6sOo5OtMQnL",
        "colab_type": "text"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jv2yPgQWL9de",
        "colab_type": "text"
      },
      "source": [
        "##GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXvqlGD0L-sx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_gru():\n",
        "  inp = Input(shape=(max_len,))\n",
        "  x = Embedding(num_words,embed_size,embeddings_initializer=Constant(embeddings),input_length=max_len,trainable=False)(inp)\n",
        "  x = SpatialDropout1D(0.1)(x)\n",
        "  x = Bidirectional(LSTM(50, return_sequences=True))(x)\n",
        "  x, x_h, x_c = Bidirectional(GRU(50, activation= 'tanh',recurrent_activation ='sigmoid',recurrent_dropout=0,\n",
        "                      unroll =False,use_bias =True,reset_after=True,return_sequences = True, return_state = True))(x)\n",
        "  avg_pool = GlobalAveragePooling1D()(x)\n",
        "  max_pool = GlobalMaxPooling1D()(x)\n",
        "  conc = concatenate([avg_pool, x_h, max_pool])\n",
        "  outp = Dense(1, activation=\"sigmoid\")(conc)    \n",
        "  model = Model(inputs=inp, outputs=outp)\n",
        "  model.compile(loss=BinaryFocalLoss(gamma=2), optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEFZUSjOryy7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_gru1():\n",
        "  inp = Input(shape=(max_len,))\n",
        "  x = Embedding(num_words,embed_size,embeddings_initializer=Constant(embeddings),input_length=max_len,trainable=False)(inp)\n",
        "  x = SpatialDropout1D(0.2)(x)\n",
        "  x=Bidirectional(GRU(150,activation= 'tanh',recurrent_activation ='sigmoid',recurrent_dropout=0,\n",
        "                      unroll =False,use_bias =True,reset_after=True,return_sequences = True))(x)\n",
        "  avg_pool = GlobalAveragePooling1D()(x)\n",
        "  max_pool = GlobalMaxPooling1D()(x)\n",
        "  conc = concatenate([avg_pool, max_pool])\n",
        "\n",
        "\n",
        "  x=Dropout(0.1)(conc)\n",
        "  out=Dense(64, activation=\"relu\")(x)\n",
        "  out=Dense(32, activation=\"relu\")(x)\n",
        "\n",
        "  outp=Dense(1, activation=\"sigmoid\")(x)   \n",
        "  model = Model(inputs=inp, outputs=outp)\n",
        "  model.compile(loss=BinaryFocalLoss(gamma=2), optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7t_Ph6qafOQK",
        "colab_type": "text"
      },
      "source": [
        "## GRU attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyKea_xMkrmP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://github.com/zake7749/DeepToxic\n",
        "\n",
        "\n",
        "class AttentionWeightedAverage(Layer):\n",
        "    \"\"\"\n",
        "    Computes a weighted average of the different channels across timesteps.\n",
        "    Uses 1 parameter pr. channel to compute the attention value for a single timestep.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, return_attention=False, **kwargs):\n",
        "        self.init = initializers.get('uniform')\n",
        "        self.supports_masking = True\n",
        "        self.return_attention = return_attention\n",
        "        super(AttentionWeightedAverage, self).__init__(** kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.input_spec = [InputSpec(ndim=3)]\n",
        "        assert len(input_shape) == 3\n",
        "\n",
        "        self.W = self.add_weight(shape=(input_shape[2], 1),\n",
        "                                 name='{}_W'.format(self.name),\n",
        "                                 initializer=self.init)\n",
        "        self.trainable_weight = [self.W]\n",
        "        super(AttentionWeightedAverage, self).build(input_shape)\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        # computes a probability distribution over the timesteps\n",
        "        # uses 'max trick' for numerical stability\n",
        "        # reshape is done to avoid issue with Tensorflow\n",
        "        # and 1-dimensional weights\n",
        "        logits = K.dot(x, self.W)\n",
        "        x_shape = K.shape(x)\n",
        "        logits = K.reshape(logits, (x_shape[0], x_shape[1]))\n",
        "        ai = K.exp(logits - K.max(logits, axis=-1, keepdims=True))\n",
        "\n",
        "        # masked timesteps have zero weight\n",
        "        if mask is not None:\n",
        "            mask = K.cast(mask, K.floatx())\n",
        "            ai = ai * mask\n",
        "        att_weights = ai / (K.sum(ai, axis=1, keepdims=True) + K.epsilon())\n",
        "        weighted_input = x * K.expand_dims(att_weights)\n",
        "        result = K.sum(weighted_input, axis=1)\n",
        "        if self.return_attention:\n",
        "            return [result, att_weights]\n",
        "        return result\n",
        "\n",
        "    def get_output_shape_for(self, input_shape):\n",
        "        return self.compute_output_shape(input_shape)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        output_len = input_shape[2]\n",
        "        if self.return_attention:\n",
        "            return [(input_shape[0], output_len), (input_shape[0], input_shape[1])]\n",
        "        return (input_shape[0], output_len)\n",
        "\n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        if isinstance(input_mask, list):\n",
        "            return [None] * len(input_mask)\n",
        "        else:\n",
        "            return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hovBxS5jfRbn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_gru_attn():\n",
        "  inp = Input(shape=(max_len,))\n",
        "  x = Embedding(num_words,embed_size,embeddings_initializer=Constant(embeddings),input_length=max_len,trainable=False)(inp)\n",
        "  x = SpatialDropout1D(0.1)(x)\n",
        "  x = Bidirectional(LSTM(50, activation= 'tanh',recurrent_activation ='sigmoid',recurrent_dropout=0,\n",
        "                      unroll =False,use_bias =True,return_sequences = True))(x)\n",
        "  x = Bidirectional(GRU(50, activation= 'tanh',recurrent_activation ='sigmoid',recurrent_dropout=0,\n",
        "                      unroll =False,use_bias =True,reset_after=True,return_sequences = True))(x)\n",
        "  avg_pool = GlobalAveragePooling1D()(x)\n",
        "  max_pool = GlobalMaxPooling1D()(x)\n",
        "  last = Lambda(lambda t: t[:, -1])(x)\n",
        "  attn = AttentionWeightedAverage()(x)\n",
        "  conc = concatenate([avg_pool,  max_pool,last,attn])\n",
        "  outp = Dense(1, activation=\"sigmoid\")(conc)    \n",
        "  model = Model(inputs=inp, outputs=outp)\n",
        "  model.compile(loss=BinaryFocalLoss(gamma=2), optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I34DRPLqTVru",
        "colab_type": "text"
      },
      "source": [
        "##TCN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-euqTedTWjY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tcn import TCN\n",
        "\n",
        "def wave_net_activation(x):\n",
        "    # type: (Layer) -> Layer\n",
        "    \"\"\"This method defines the activation used for WaveNet\n",
        "    described in https://deepmind.com/blog/wavenet-generative-model-raw-audio/\n",
        "    Args:\n",
        "        x: The layer we want to apply the activation to\n",
        "    Returns:\n",
        "        A new layer with the wavenet activation applied\n",
        "    \"\"\"\n",
        "    tanh_out = Activation('tanh')(x)\n",
        "    sigm_out = Activation('sigmoid')(x)\n",
        "    return multiply([tanh_out, sigm_out])\n",
        "\n",
        "def model_tcn(embedding_matrix):\n",
        "    \n",
        "    inp = Input(shape=(max_len,))\n",
        "    x = Embedding(num_words,embed_size,embeddings_initializer=Constant(embeddings),input_length=max_len,trainable=False)(inp)\n",
        "    x = SpatialDropout1D(0.1)(x)\n",
        "    x = TCN(128,dilations = [1, 2, 4], return_sequences=True ,name = 'tnc1')(x)\n",
        "    x = wave_net_activation(x)\n",
        "    x = TCN(64,dilations = [1, 2, 4], return_sequences=True, name = 'tnc2')(x)\n",
        "    x = wave_net_activation(x)\n",
        "    #x = TCN(32,dilations = [1, 2, 4], return_sequences=True, activation = 'wavenet',name = 'tnc3')(x)\n",
        "    avg_pool = GlobalAveragePooling1D()(x)\n",
        "    max_pool = GlobalMaxPooling1D()(x)\n",
        "    \n",
        "    conc = concatenate([avg_pool, max_pool])\n",
        "    conc = Dense(64, activation=\"relu\")(conc)\n",
        "    conc = Dense(32, activation=\"relu\")(conc)\n",
        "\n",
        "    conc = Dropout(0.1)(conc)\n",
        "    outp = Dense(1, activation=\"sigmoid\")(conc)    \n",
        "    model = Model(inputs=inp, outputs=outp)\n",
        "    model.compile(loss=BinaryFocalLoss(gamma=2), optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNc6xxspBcTG",
        "colab_type": "text"
      },
      "source": [
        "##KIM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAgtTt9IBfMQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_filters=128\n",
        "def model_kim():\n",
        "  inp = Input(shape=(max_len,))\n",
        "  emb = Embedding(num_words,embed_size,embeddings_initializer=Constant(embeddings),input_length=max_len,trainable=False)(inp)\n",
        "  # Specify each convolution layer and their kernel siz i.e. n-grams \n",
        "  conv1_1 = Conv1D(filters=conv_filters, kernel_size=3)(emb)\n",
        "  btch1_1 = BatchNormalization()(conv1_1)\n",
        "  drp1_1  = Dropout(0.2)(btch1_1)\n",
        "  actv1_1 = Activation('relu')(drp1_1)\n",
        "  glmp1_1 = GlobalMaxPooling1D()(actv1_1)\n",
        "\n",
        "  conv1_2 = Conv1D(filters=conv_filters, kernel_size=4)(emb)\n",
        "  btch1_2 = BatchNormalization()(conv1_2)\n",
        "  drp1_2  = Dropout(0.2)(btch1_2)\n",
        "  actv1_2 = Activation('relu')(drp1_2)\n",
        "  glmp1_2 = GlobalMaxPooling1D()(actv1_2)\n",
        "\n",
        "  conv1_3 = Conv1D(filters=conv_filters, kernel_size=5)(emb)\n",
        "  btch1_3 = BatchNormalization()(conv1_3)\n",
        "  drp1_3  = Dropout(0.2)(btch1_3)\n",
        "  actv1_3 = Activation('relu')(drp1_3)\n",
        "  glmp1_3 = GlobalMaxPooling1D()(actv1_3)\n",
        "\n",
        "  conv1_4 = Conv1D(filters=conv_filters, kernel_size=6)(emb)\n",
        "  btch1_4 = BatchNormalization()(conv1_4)\n",
        "  drp1_4  = Dropout(0.2)(btch1_4)\n",
        "  actv1_4 = Activation('relu')(drp1_4)\n",
        "  glmp1_4 = GlobalMaxPooling1D()(actv1_4)\n",
        "\n",
        "  # Gather all convolution layers\n",
        "  cnct = concatenate([glmp1_1, glmp1_2, glmp1_3, glmp1_4], axis=1)\n",
        "  drp1 = Dropout(0.2)(cnct)\n",
        "\n",
        "  dns1  = Dense(32, activation='relu')(drp1)\n",
        "  btch1 = BatchNormalization()(dns1)\n",
        "  drp2  = Dropout(0.2)(btch1)\n",
        "\n",
        "  out = Dense(1, activation='sigmoid')(drp2)   \n",
        "  model = Model(inputs=inp, outputs=out)\n",
        "  model.compile(loss=BinaryFocalLoss(gamma=2), optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b46h68vVq4Wp",
        "colab_type": "text"
      },
      "source": [
        "##RNN_CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyFfCHOxq6lR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def model_gru_cnn():\n",
        "  inp = Input(shape=(max_len,))\n",
        "  x = Embedding(num_words,embed_size,embeddings_initializer=Constant(embeddings),input_length=max_len,trainable=False)(inp)\n",
        "  x = SpatialDropout1D(0.5)(x)\n",
        "  x = Bidirectional(LSTM(128, activation= 'tanh',recurrent_activation ='sigmoid',recurrent_dropout=0,\n",
        "                      unroll =False,use_bias =True,return_sequences = True))(x)\n",
        "  x = Conv1D(64, kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(x)\n",
        "  avg_pool = GlobalAveragePooling1D()(x)\n",
        "  max_pool = GlobalMaxPooling1D()(x)\n",
        "  x = concatenate([avg_pool, max_pool])\n",
        "  x = Dense(10, activation = \"relu\")(x)\n",
        "\n",
        "  outp=Dense(1, activation=\"sigmoid\")(x)   \n",
        "  model = Model(inputs=inp, outputs=outp)\n",
        "  model.compile(loss=BinaryFocalLoss(gamma=2), optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJCuBpqkNx8L",
        "colab_type": "text"
      },
      "source": [
        "# Train model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUygUis5N2yN",
        "colab_type": "text"
      },
      "source": [
        "##GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdwYL0fG3kQo",
        "colab_type": "code",
        "outputId": "189a9f11-a843-4e77-b671-ed6b31869e54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "kfold = StratifiedKFold(n_splits=5, shuffle=False)\n",
        "gru_scores = []\n",
        "gru_test=[]\n",
        "for train, val in kfold.split(sequences_matrix, labels):\n",
        "  gru_model=model_gru()\n",
        "  \n",
        "  gru_model.fit(sequences_matrix[train], labels[train],batch_size=64,epochs=10,verbose=2,\n",
        "            validation_data=(sequences_matrix[val],labels[val]),callbacks=[clr,])\n",
        "  y_pred = gru_model.predict(sequences_matrix[val], batch_size=64, verbose=1)\n",
        "\n",
        "  gru_test.append(gru_model.predict(X_test_sequences, batch_size=64, verbose=1).ravel())\n",
        "\n",
        "  y_pred = (y_pred > 0.5)\n",
        "  f1=f1_score(labels[val], y_pred, average='macro')\n",
        "  gru_scores.append(f1)\n",
        "  tf.keras.backend.clear_session()\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 11280 samples, validate on 2820 samples\n",
            "Epoch 1/10\n",
            "11280/11280 - 32s - loss: 0.1274 - accuracy: 0.7660 - val_loss: 0.1179 - val_accuracy: 0.7883\n",
            "Epoch 2/10\n",
            "11280/11280 - 26s - loss: 0.1146 - accuracy: 0.8005 - val_loss: 0.1163 - val_accuracy: 0.7936\n",
            "Epoch 3/10\n",
            "11280/11280 - 26s - loss: 0.1105 - accuracy: 0.8097 - val_loss: 0.1172 - val_accuracy: 0.7915\n",
            "Epoch 4/10\n",
            "11280/11280 - 26s - loss: 0.1074 - accuracy: 0.8163 - val_loss: 0.1199 - val_accuracy: 0.7830\n",
            "Epoch 5/10\n",
            "11280/11280 - 26s - loss: 0.0978 - accuracy: 0.8389 - val_loss: 0.1427 - val_accuracy: 0.7727\n",
            "Epoch 6/10\n",
            "11280/11280 - 26s - loss: 0.0950 - accuracy: 0.8424 - val_loss: 0.1355 - val_accuracy: 0.7858\n",
            "Epoch 7/10\n",
            "11280/11280 - 26s - loss: 0.0789 - accuracy: 0.8754 - val_loss: 0.1361 - val_accuracy: 0.7798\n",
            "Epoch 8/10\n",
            "11280/11280 - 26s - loss: 0.0721 - accuracy: 0.8876 - val_loss: 0.1363 - val_accuracy: 0.7851\n",
            "Epoch 9/10\n",
            "11280/11280 - 26s - loss: 0.0604 - accuracy: 0.9121 - val_loss: 0.1580 - val_accuracy: 0.7699\n",
            "Epoch 10/10\n",
            "11280/11280 - 26s - loss: 0.0477 - accuracy: 0.9300 - val_loss: 0.1878 - val_accuracy: 0.7617\n",
            "2820/2820 [==============================] - 4s 1ms/sample\n",
            "3887/3887 [==============================] - 3s 881us/sample\n",
            "Train on 11280 samples, validate on 2820 samples\n",
            "Epoch 1/10\n",
            "11280/11280 - 32s - loss: 0.1273 - accuracy: 0.7661 - val_loss: 0.1246 - val_accuracy: 0.7727\n",
            "Epoch 2/10\n",
            "11280/11280 - 26s - loss: 0.1165 - accuracy: 0.7943 - val_loss: 0.1164 - val_accuracy: 0.7876\n",
            "Epoch 3/10\n",
            "11280/11280 - 26s - loss: 0.1129 - accuracy: 0.8041 - val_loss: 0.1184 - val_accuracy: 0.7876\n",
            "Epoch 4/10\n",
            "11280/11280 - 26s - loss: 0.1081 - accuracy: 0.8126 - val_loss: 0.1293 - val_accuracy: 0.7745\n",
            "Epoch 5/10\n",
            "11280/11280 - 26s - loss: 0.1011 - accuracy: 0.8285 - val_loss: 0.1233 - val_accuracy: 0.7830\n",
            "Epoch 6/10\n",
            "11280/11280 - 26s - loss: 0.0907 - accuracy: 0.8493 - val_loss: 0.1263 - val_accuracy: 0.7791\n",
            "Epoch 7/10\n",
            "11280/11280 - 26s - loss: 0.0784 - accuracy: 0.8746 - val_loss: 0.1448 - val_accuracy: 0.7560\n",
            "Epoch 8/10\n",
            "11280/11280 - 26s - loss: 0.0682 - accuracy: 0.8943 - val_loss: 0.1502 - val_accuracy: 0.7656\n",
            "Epoch 9/10\n",
            "11280/11280 - 26s - loss: 0.0536 - accuracy: 0.9204 - val_loss: 0.1943 - val_accuracy: 0.7773\n",
            "Epoch 10/10\n",
            "11280/11280 - 26s - loss: 0.0461 - accuracy: 0.9330 - val_loss: 0.1975 - val_accuracy: 0.7652\n",
            "2820/2820 [==============================] - 3s 1ms/sample\n",
            "3887/3887 [==============================] - 3s 882us/sample\n",
            "Train on 11280 samples, validate on 2820 samples\n",
            "Epoch 1/10\n",
            "11280/11280 - 32s - loss: 0.1287 - accuracy: 0.7611 - val_loss: 0.1170 - val_accuracy: 0.7993\n",
            "Epoch 2/10\n",
            "11280/11280 - 26s - loss: 0.1160 - accuracy: 0.7934 - val_loss: 0.1332 - val_accuracy: 0.7688\n",
            "Epoch 3/10\n",
            "11280/11280 - 26s - loss: 0.1125 - accuracy: 0.8029 - val_loss: 0.1154 - val_accuracy: 0.7975\n",
            "Epoch 4/10\n",
            "11280/11280 - 26s - loss: 0.1066 - accuracy: 0.8142 - val_loss: 0.1167 - val_accuracy: 0.8074\n",
            "Epoch 5/10\n",
            "11280/11280 - 26s - loss: 0.0998 - accuracy: 0.8311 - val_loss: 0.1210 - val_accuracy: 0.7869\n",
            "Epoch 6/10\n",
            "11280/11280 - 26s - loss: 0.0909 - accuracy: 0.8488 - val_loss: 0.1297 - val_accuracy: 0.7911\n",
            "Epoch 7/10\n",
            "11280/11280 - 26s - loss: 0.0831 - accuracy: 0.8664 - val_loss: 0.1362 - val_accuracy: 0.7887\n",
            "Epoch 8/10\n",
            "11280/11280 - 26s - loss: 0.0682 - accuracy: 0.8907 - val_loss: 0.1535 - val_accuracy: 0.7787\n",
            "Epoch 9/10\n",
            "11280/11280 - 26s - loss: 0.0577 - accuracy: 0.9120 - val_loss: 0.1610 - val_accuracy: 0.7833\n",
            "Epoch 10/10\n",
            "11280/11280 - 26s - loss: 0.0452 - accuracy: 0.9355 - val_loss: 0.1962 - val_accuracy: 0.7535\n",
            "2820/2820 [==============================] - 3s 1ms/sample\n",
            "3887/3887 [==============================] - 3s 874us/sample\n",
            "Train on 11280 samples, validate on 2820 samples\n",
            "Epoch 1/10\n",
            "11280/11280 - 32s - loss: 0.1275 - accuracy: 0.7652 - val_loss: 0.1206 - val_accuracy: 0.7855\n",
            "Epoch 2/10\n",
            "11280/11280 - 26s - loss: 0.1155 - accuracy: 0.7974 - val_loss: 0.1162 - val_accuracy: 0.8014\n",
            "Epoch 3/10\n",
            "11280/11280 - 26s - loss: 0.1122 - accuracy: 0.8020 - val_loss: 0.1206 - val_accuracy: 0.7858\n",
            "Epoch 4/10\n",
            "11280/11280 - 26s - loss: 0.1057 - accuracy: 0.8166 - val_loss: 0.1172 - val_accuracy: 0.7901\n",
            "Epoch 5/10\n",
            "11280/11280 - 26s - loss: 0.0989 - accuracy: 0.8341 - val_loss: 0.1273 - val_accuracy: 0.7901\n",
            "Epoch 6/10\n",
            "11280/11280 - 26s - loss: 0.0900 - accuracy: 0.8532 - val_loss: 0.1271 - val_accuracy: 0.7954\n",
            "Epoch 7/10\n",
            "11280/11280 - 26s - loss: 0.0784 - accuracy: 0.8745 - val_loss: 0.1468 - val_accuracy: 0.7837\n",
            "Epoch 8/10\n",
            "11280/11280 - 26s - loss: 0.0644 - accuracy: 0.9032 - val_loss: 0.1415 - val_accuracy: 0.7709\n",
            "Epoch 9/10\n",
            "11280/11280 - 26s - loss: 0.0531 - accuracy: 0.9206 - val_loss: 0.1704 - val_accuracy: 0.7865\n",
            "Epoch 10/10\n",
            "11280/11280 - 26s - loss: 0.0450 - accuracy: 0.9354 - val_loss: 0.1901 - val_accuracy: 0.7777\n",
            "2820/2820 [==============================] - 3s 1ms/sample\n",
            "3887/3887 [==============================] - 3s 878us/sample\n",
            "Train on 11280 samples, validate on 2820 samples\n",
            "Epoch 1/10\n",
            "11280/11280 - 32s - loss: 0.1286 - accuracy: 0.7658 - val_loss: 0.1152 - val_accuracy: 0.7943\n",
            "Epoch 2/10\n",
            "11280/11280 - 26s - loss: 0.1184 - accuracy: 0.7898 - val_loss: 0.1138 - val_accuracy: 0.8000\n",
            "Epoch 3/10\n",
            "11280/11280 - 26s - loss: 0.1140 - accuracy: 0.7974 - val_loss: 0.1124 - val_accuracy: 0.8050\n",
            "Epoch 4/10\n",
            "11280/11280 - 26s - loss: 0.1076 - accuracy: 0.8128 - val_loss: 0.1319 - val_accuracy: 0.7518\n",
            "Epoch 5/10\n",
            "11280/11280 - 26s - loss: 0.1020 - accuracy: 0.8284 - val_loss: 0.1183 - val_accuracy: 0.8035\n",
            "Epoch 6/10\n",
            "11280/11280 - 26s - loss: 0.0934 - accuracy: 0.8440 - val_loss: 0.1214 - val_accuracy: 0.7865\n",
            "Epoch 7/10\n",
            "11280/11280 - 26s - loss: 0.0820 - accuracy: 0.8707 - val_loss: 0.1318 - val_accuracy: 0.7819\n",
            "Epoch 8/10\n",
            "11280/11280 - 26s - loss: 0.0745 - accuracy: 0.8839 - val_loss: 0.1482 - val_accuracy: 0.7819\n",
            "Epoch 9/10\n",
            "11280/11280 - 26s - loss: 0.0585 - accuracy: 0.9144 - val_loss: 0.1615 - val_accuracy: 0.7798\n",
            "Epoch 10/10\n",
            "11280/11280 - 26s - loss: 0.0454 - accuracy: 0.9349 - val_loss: 0.1855 - val_accuracy: 0.7667\n",
            "2820/2820 [==============================] - 3s 1ms/sample\n",
            "3887/3887 [==============================] - 3s 877us/sample\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKKs8iWX570n",
        "colab_type": "code",
        "outputId": "1f1a45a3-79c4-4a70-8ba1-bcf987b36dc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "np.mean(gru_scores)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7348080576258096"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcJjKG_6sJAC",
        "colab_type": "text"
      },
      "source": [
        "##GRU 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APrVpJEGsK0-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "80582e80-52c7-4e01-b2d6-e4dca3ee23a2"
      },
      "source": [
        "kfold = StratifiedKFold(n_splits=5, shuffle=False)\n",
        "gru_scores1 = []\n",
        "gru_test1=[]\n",
        "for train, val in kfold.split(sequences_matrix, labels):\n",
        "  gru_model=model_gru1()\n",
        "  \n",
        "  gru_model.fit(sequences_matrix[train], labels[train],batch_size=128,epochs=10,verbose=2,\n",
        "            validation_data=(sequences_matrix[val],labels[val]))\n",
        "  y_pred = gru_model.predict(sequences_matrix[val], batch_size=64, verbose=1)\n",
        "\n",
        "  gru_test1.append(gru_model.predict(X_test_sequences, batch_size=64, verbose=1).ravel())\n",
        "\n",
        "  y_pred = (y_pred > 0.5)\n",
        "  f1=f1_score(labels[val], y_pred, average='macro')\n",
        "  gru_scores1.append(f1)\n",
        "  tf.keras.backend.clear_session()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 11280 samples, validate on 2820 samples\n",
            "Epoch 1/10\n",
            "11280/11280 - 12s - loss: 0.1326 - accuracy: 0.7473 - val_loss: 0.1202 - val_accuracy: 0.7833\n",
            "Epoch 2/10\n",
            "11280/11280 - 9s - loss: 0.1168 - accuracy: 0.7925 - val_loss: 0.1182 - val_accuracy: 0.7865\n",
            "Epoch 3/10\n",
            "11280/11280 - 9s - loss: 0.1127 - accuracy: 0.8000 - val_loss: 0.1175 - val_accuracy: 0.7904\n",
            "Epoch 4/10\n",
            "11280/11280 - 9s - loss: 0.1094 - accuracy: 0.8094 - val_loss: 0.1178 - val_accuracy: 0.7876\n",
            "Epoch 5/10\n",
            "11280/11280 - 9s - loss: 0.1059 - accuracy: 0.8171 - val_loss: 0.1199 - val_accuracy: 0.7801\n",
            "Epoch 6/10\n",
            "11280/11280 - 9s - loss: 0.1028 - accuracy: 0.8258 - val_loss: 0.1229 - val_accuracy: 0.7894\n",
            "Epoch 7/10\n",
            "11280/11280 - 9s - loss: 0.0990 - accuracy: 0.8328 - val_loss: 0.1186 - val_accuracy: 0.7787\n",
            "Epoch 8/10\n",
            "11280/11280 - 9s - loss: 0.0932 - accuracy: 0.8463 - val_loss: 0.1205 - val_accuracy: 0.7887\n",
            "Epoch 9/10\n",
            "11280/11280 - 9s - loss: 0.0891 - accuracy: 0.8574 - val_loss: 0.1280 - val_accuracy: 0.7876\n",
            "Epoch 10/10\n",
            "11280/11280 - 9s - loss: 0.0835 - accuracy: 0.8684 - val_loss: 0.1209 - val_accuracy: 0.7848\n",
            "2820/2820 [==============================] - 2s 537us/sample\n",
            "3887/3887 [==============================] - 1s 374us/sample\n",
            "Train on 11280 samples, validate on 2820 samples\n",
            "Epoch 1/10\n",
            "11280/11280 - 12s - loss: 0.1344 - accuracy: 0.7456 - val_loss: 0.1226 - val_accuracy: 0.7766\n",
            "Epoch 2/10\n",
            "11280/11280 - 9s - loss: 0.1174 - accuracy: 0.7907 - val_loss: 0.1200 - val_accuracy: 0.7844\n",
            "Epoch 3/10\n",
            "11280/11280 - 9s - loss: 0.1137 - accuracy: 0.8011 - val_loss: 0.1177 - val_accuracy: 0.7830\n",
            "Epoch 4/10\n",
            "11280/11280 - 9s - loss: 0.1089 - accuracy: 0.8089 - val_loss: 0.1212 - val_accuracy: 0.7879\n",
            "Epoch 5/10\n",
            "11280/11280 - 9s - loss: 0.1058 - accuracy: 0.8180 - val_loss: 0.1172 - val_accuracy: 0.7879\n",
            "Epoch 6/10\n",
            "11280/11280 - 9s - loss: 0.1013 - accuracy: 0.8271 - val_loss: 0.1208 - val_accuracy: 0.7851\n",
            "Epoch 7/10\n",
            "11280/11280 - 9s - loss: 0.0978 - accuracy: 0.8339 - val_loss: 0.1205 - val_accuracy: 0.7947\n",
            "Epoch 8/10\n",
            "11280/11280 - 9s - loss: 0.0935 - accuracy: 0.8444 - val_loss: 0.1208 - val_accuracy: 0.7883\n",
            "Epoch 9/10\n",
            "11280/11280 - 9s - loss: 0.0889 - accuracy: 0.8535 - val_loss: 0.1224 - val_accuracy: 0.7872\n",
            "Epoch 10/10\n",
            "11280/11280 - 9s - loss: 0.0826 - accuracy: 0.8633 - val_loss: 0.1279 - val_accuracy: 0.7812\n",
            "2820/2820 [==============================] - 2s 542us/sample\n",
            "3887/3887 [==============================] - 1s 383us/sample\n",
            "Train on 11280 samples, validate on 2820 samples\n",
            "Epoch 1/10\n",
            "11280/11280 - 12s - loss: 0.1354 - accuracy: 0.7396 - val_loss: 0.1179 - val_accuracy: 0.7940\n",
            "Epoch 2/10\n",
            "11280/11280 - 9s - loss: 0.1182 - accuracy: 0.7887 - val_loss: 0.1157 - val_accuracy: 0.7982\n",
            "Epoch 3/10\n",
            "11280/11280 - 9s - loss: 0.1123 - accuracy: 0.8012 - val_loss: 0.1158 - val_accuracy: 0.8032\n",
            "Epoch 4/10\n",
            "11280/11280 - 9s - loss: 0.1100 - accuracy: 0.8068 - val_loss: 0.1163 - val_accuracy: 0.7968\n",
            "Epoch 5/10\n",
            "11280/11280 - 9s - loss: 0.1065 - accuracy: 0.8116 - val_loss: 0.1157 - val_accuracy: 0.8067\n",
            "Epoch 6/10\n",
            "11280/11280 - 9s - loss: 0.1020 - accuracy: 0.8214 - val_loss: 0.1184 - val_accuracy: 0.7982\n",
            "Epoch 7/10\n",
            "11280/11280 - 9s - loss: 0.0971 - accuracy: 0.8330 - val_loss: 0.1170 - val_accuracy: 0.8057\n",
            "Epoch 8/10\n",
            "11280/11280 - 9s - loss: 0.0927 - accuracy: 0.8441 - val_loss: 0.1246 - val_accuracy: 0.7897\n",
            "Epoch 9/10\n",
            "11280/11280 - 9s - loss: 0.0876 - accuracy: 0.8513 - val_loss: 0.1212 - val_accuracy: 0.8032\n",
            "Epoch 10/10\n",
            "11280/11280 - 9s - loss: 0.0826 - accuracy: 0.8629 - val_loss: 0.1220 - val_accuracy: 0.8043\n",
            "2820/2820 [==============================] - 2s 554us/sample\n",
            "3887/3887 [==============================] - 1s 378us/sample\n",
            "Train on 11280 samples, validate on 2820 samples\n",
            "Epoch 1/10\n",
            "11280/11280 - 12s - loss: 0.1354 - accuracy: 0.7386 - val_loss: 0.1174 - val_accuracy: 0.7890\n",
            "Epoch 2/10\n",
            "11280/11280 - 9s - loss: 0.1176 - accuracy: 0.7926 - val_loss: 0.1162 - val_accuracy: 0.7915\n",
            "Epoch 3/10\n",
            "11280/11280 - 9s - loss: 0.1126 - accuracy: 0.8008 - val_loss: 0.1157 - val_accuracy: 0.7950\n",
            "Epoch 4/10\n",
            "11280/11280 - 9s - loss: 0.1092 - accuracy: 0.8087 - val_loss: 0.1160 - val_accuracy: 0.7947\n",
            "Epoch 5/10\n",
            "11280/11280 - 9s - loss: 0.1058 - accuracy: 0.8132 - val_loss: 0.1167 - val_accuracy: 0.7957\n",
            "Epoch 6/10\n",
            "11280/11280 - 9s - loss: 0.1010 - accuracy: 0.8308 - val_loss: 0.1167 - val_accuracy: 0.7897\n",
            "Epoch 7/10\n",
            "11280/11280 - 9s - loss: 0.0983 - accuracy: 0.8324 - val_loss: 0.1206 - val_accuracy: 0.7940\n",
            "Epoch 8/10\n",
            "11280/11280 - 9s - loss: 0.0915 - accuracy: 0.8480 - val_loss: 0.1209 - val_accuracy: 0.7929\n",
            "Epoch 9/10\n",
            "11280/11280 - 9s - loss: 0.0867 - accuracy: 0.8596 - val_loss: 0.1226 - val_accuracy: 0.7855\n",
            "Epoch 10/10\n",
            "11280/11280 - 9s - loss: 0.0821 - accuracy: 0.8707 - val_loss: 0.1261 - val_accuracy: 0.7851\n",
            "2820/2820 [==============================] - 2s 546us/sample\n",
            "3887/3887 [==============================] - 1s 379us/sample\n",
            "Train on 11280 samples, validate on 2820 samples\n",
            "Epoch 1/10\n",
            "11280/11280 - 12s - loss: 0.1336 - accuracy: 0.7473 - val_loss: 0.1160 - val_accuracy: 0.7929\n",
            "Epoch 2/10\n",
            "11280/11280 - 9s - loss: 0.1185 - accuracy: 0.7908 - val_loss: 0.1138 - val_accuracy: 0.7989\n",
            "Epoch 3/10\n",
            "11280/11280 - 9s - loss: 0.1142 - accuracy: 0.7987 - val_loss: 0.1174 - val_accuracy: 0.7922\n",
            "Epoch 4/10\n",
            "11280/11280 - 9s - loss: 0.1109 - accuracy: 0.8061 - val_loss: 0.1133 - val_accuracy: 0.8014\n",
            "Epoch 5/10\n",
            "11280/11280 - 9s - loss: 0.1067 - accuracy: 0.8124 - val_loss: 0.1131 - val_accuracy: 0.8039\n",
            "Epoch 6/10\n",
            "11280/11280 - 9s - loss: 0.1040 - accuracy: 0.8232 - val_loss: 0.1124 - val_accuracy: 0.8043\n",
            "Epoch 7/10\n",
            "11280/11280 - 9s - loss: 0.0996 - accuracy: 0.8304 - val_loss: 0.1138 - val_accuracy: 0.8039\n",
            "Epoch 8/10\n",
            "11280/11280 - 9s - loss: 0.0949 - accuracy: 0.8418 - val_loss: 0.1136 - val_accuracy: 0.8035\n",
            "Epoch 9/10\n",
            "11280/11280 - 9s - loss: 0.0904 - accuracy: 0.8517 - val_loss: 0.1221 - val_accuracy: 0.7947\n",
            "Epoch 10/10\n",
            "11280/11280 - 9s - loss: 0.0845 - accuracy: 0.8617 - val_loss: 0.1176 - val_accuracy: 0.8014\n",
            "2820/2820 [==============================] - 2s 548us/sample\n",
            "3887/3887 [==============================] - 1s 375us/sample\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XTLgwdCt1WM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "cf7338d2-333d-47c6-adcb-3e92bb9bac3d"
      },
      "source": [
        "np.mean(gru_scores1)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7556838389107827"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaW-Uq0Kldp4",
        "colab_type": "text"
      },
      "source": [
        "## GRU attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XULscbNL6FiP",
        "colab_type": "code",
        "outputId": "380b2c0d-80ac-44a6-b208-11f1c44a24e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "kfold = StratifiedKFold(n_splits=5, shuffle=False)\n",
        "atten_scores = []\n",
        "atten_test=[]\n",
        "for train, val in kfold.split(sequences_matrix, labels):\n",
        "  attn_gru_model=model_gru_attn()\n",
        "  \n",
        "  attn_gru_model.fit(sequences_matrix[train], labels[train],batch_size=64,epochs=10,verbose=2,\n",
        "            validation_data=(sequences_matrix[val],labels[val]),callbacks=[clr,])\n",
        "  y_pred = attn_gru_model.predict(sequences_matrix[val], batch_size=64, verbose=1)\n",
        "\n",
        "  atten_test.append(attn_gru_model.predict(X_test_sequences, batch_size=64, verbose=1).ravel())\n",
        "\n",
        "  y_pred = (y_pred > 0.5)\n",
        "  f1=f1_score(labels[val], y_pred, average='macro')\n",
        "  atten_scores.append(f1)\n",
        "  tf.keras.backend.clear_session()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 11280 samples, validate on 2820 samples\n",
            "Epoch 1/10\n",
            "11280/11280 - 32s - loss: 0.1275 - accuracy: 0.7618 - val_loss: 0.1190 - val_accuracy: 0.7851\n",
            "Epoch 2/10\n",
            "11280/11280 - 26s - loss: 0.1147 - accuracy: 0.7999 - val_loss: 0.1169 - val_accuracy: 0.7901\n",
            "Epoch 3/10\n",
            "11280/11280 - 26s - loss: 0.1110 - accuracy: 0.8063 - val_loss: 0.1175 - val_accuracy: 0.7904\n",
            "Epoch 4/10\n",
            "11280/11280 - 26s - loss: 0.1084 - accuracy: 0.8139 - val_loss: 0.1174 - val_accuracy: 0.7883\n",
            "Epoch 5/10\n",
            "11280/11280 - 26s - loss: 0.1006 - accuracy: 0.8316 - val_loss: 0.1199 - val_accuracy: 0.7908\n",
            "Epoch 6/10\n",
            "11280/11280 - 26s - loss: 0.0943 - accuracy: 0.8453 - val_loss: 0.1222 - val_accuracy: 0.7872\n",
            "Epoch 7/10\n",
            "11280/11280 - 26s - loss: 0.0865 - accuracy: 0.8571 - val_loss: 0.1250 - val_accuracy: 0.7851\n",
            "Epoch 8/10\n",
            "11280/11280 - 26s - loss: 0.0740 - accuracy: 0.8855 - val_loss: 0.1356 - val_accuracy: 0.7833\n",
            "Epoch 9/10\n",
            "11280/11280 - 26s - loss: 0.0632 - accuracy: 0.9068 - val_loss: 0.1515 - val_accuracy: 0.7624\n",
            "Epoch 10/10\n",
            "11280/11280 - 26s - loss: 0.0526 - accuracy: 0.9206 - val_loss: 0.1832 - val_accuracy: 0.7418\n",
            "2820/2820 [==============================] - 4s 2ms/sample\n",
            "3887/3887 [==============================] - 3s 890us/sample\n",
            "Train on 11280 samples, validate on 2820 samples\n",
            "Epoch 1/10\n",
            "11280/11280 - 32s - loss: 0.1262 - accuracy: 0.7661 - val_loss: 0.1217 - val_accuracy: 0.7805\n",
            "Epoch 2/10\n",
            "11280/11280 - 26s - loss: 0.1178 - accuracy: 0.7890 - val_loss: 0.1169 - val_accuracy: 0.7833\n",
            "Epoch 3/10\n",
            "11280/11280 - 26s - loss: 0.1134 - accuracy: 0.8034 - val_loss: 0.1164 - val_accuracy: 0.7908\n",
            "Epoch 4/10\n",
            "11280/11280 - 26s - loss: 0.1078 - accuracy: 0.8145 - val_loss: 0.1195 - val_accuracy: 0.7858\n",
            "Epoch 5/10\n",
            "11280/11280 - 26s - loss: 0.1033 - accuracy: 0.8225 - val_loss: 0.1183 - val_accuracy: 0.7908\n",
            "Epoch 6/10\n",
            "11280/11280 - 26s - loss: 0.0960 - accuracy: 0.8409 - val_loss: 0.1240 - val_accuracy: 0.7904\n",
            "Epoch 7/10\n",
            "11280/11280 - 26s - loss: 0.0881 - accuracy: 0.8566 - val_loss: 0.1310 - val_accuracy: 0.7855\n",
            "Epoch 8/10\n",
            "11280/11280 - 26s - loss: 0.0768 - accuracy: 0.8787 - val_loss: 0.1474 - val_accuracy: 0.7879\n",
            "Epoch 9/10\n",
            "11280/11280 - 26s - loss: 0.0673 - accuracy: 0.8974 - val_loss: 0.1469 - val_accuracy: 0.7621\n",
            "Epoch 10/10\n",
            "11280/11280 - 26s - loss: 0.0519 - accuracy: 0.9265 - val_loss: 0.1754 - val_accuracy: 0.7574\n",
            "2820/2820 [==============================] - 4s 1ms/sample\n",
            "3887/3887 [==============================] - 3s 889us/sample\n",
            "Train on 11280 samples, validate on 2820 samples\n",
            "Epoch 1/10\n",
            "11280/11280 - 32s - loss: 0.1321 - accuracy: 0.7524 - val_loss: 0.1178 - val_accuracy: 0.7957\n",
            "Epoch 2/10\n",
            "11280/11280 - 26s - loss: 0.1158 - accuracy: 0.7944 - val_loss: 0.1197 - val_accuracy: 0.7879\n",
            "Epoch 3/10\n",
            "11280/11280 - 26s - loss: 0.1119 - accuracy: 0.8029 - val_loss: 0.1164 - val_accuracy: 0.8011\n",
            "Epoch 4/10\n",
            "11280/11280 - 26s - loss: 0.1070 - accuracy: 0.8129 - val_loss: 0.1187 - val_accuracy: 0.8000\n",
            "Epoch 5/10\n",
            "11280/11280 - 26s - loss: 0.1010 - accuracy: 0.8265 - val_loss: 0.1224 - val_accuracy: 0.7883\n",
            "Epoch 6/10\n",
            "11280/11280 - 26s - loss: 0.0939 - accuracy: 0.8412 - val_loss: 0.1445 - val_accuracy: 0.7404\n",
            "Epoch 7/10\n",
            "11280/11280 - 26s - loss: 0.0846 - accuracy: 0.8600 - val_loss: 0.1311 - val_accuracy: 0.7908\n",
            "Epoch 8/10\n",
            "11280/11280 - 26s - loss: 0.0724 - accuracy: 0.8831 - val_loss: 0.1448 - val_accuracy: 0.7876\n",
            "Epoch 9/10\n",
            "11280/11280 - 26s - loss: 0.0621 - accuracy: 0.9044 - val_loss: 0.1706 - val_accuracy: 0.7809\n",
            "Epoch 10/10\n",
            "11280/11280 - 26s - loss: 0.0485 - accuracy: 0.9340 - val_loss: 0.1744 - val_accuracy: 0.7706\n",
            "2820/2820 [==============================] - 3s 1ms/sample\n",
            "3887/3887 [==============================] - 3s 886us/sample\n",
            "Train on 11280 samples, validate on 2820 samples\n",
            "Epoch 1/10\n",
            "11280/11280 - 32s - loss: 0.1296 - accuracy: 0.7574 - val_loss: 0.1169 - val_accuracy: 0.7926\n",
            "Epoch 2/10\n",
            "11280/11280 - 26s - loss: 0.1162 - accuracy: 0.7953 - val_loss: 0.1167 - val_accuracy: 0.7929\n",
            "Epoch 3/10\n",
            "11280/11280 - 26s - loss: 0.1122 - accuracy: 0.8005 - val_loss: 0.1167 - val_accuracy: 0.7908\n",
            "Epoch 4/10\n",
            "11280/11280 - 26s - loss: 0.1077 - accuracy: 0.8128 - val_loss: 0.1207 - val_accuracy: 0.7801\n",
            "Epoch 5/10\n",
            "11280/11280 - 26s - loss: 0.1019 - accuracy: 0.8302 - val_loss: 0.1173 - val_accuracy: 0.7887\n",
            "Epoch 6/10\n",
            "11280/11280 - 26s - loss: 0.0942 - accuracy: 0.8445 - val_loss: 0.1237 - val_accuracy: 0.7805\n",
            "Epoch 7/10\n",
            "11280/11280 - 26s - loss: 0.0859 - accuracy: 0.8584 - val_loss: 0.1379 - val_accuracy: 0.7752\n",
            "Epoch 8/10\n",
            "11280/11280 - 26s - loss: 0.0757 - accuracy: 0.8814 - val_loss: 0.1467 - val_accuracy: 0.7770\n",
            "Epoch 9/10\n",
            "11280/11280 - 26s - loss: 0.0639 - accuracy: 0.9008 - val_loss: 0.1582 - val_accuracy: 0.7677\n",
            "Epoch 10/10\n",
            "11280/11280 - 26s - loss: 0.0527 - accuracy: 0.9237 - val_loss: 0.1718 - val_accuracy: 0.7762\n",
            "2820/2820 [==============================] - 4s 1ms/sample\n",
            "3887/3887 [==============================] - 3s 885us/sample\n",
            "Train on 11280 samples, validate on 2820 samples\n",
            "Epoch 1/10\n",
            "11280/11280 - 33s - loss: 0.1313 - accuracy: 0.7573 - val_loss: 0.1153 - val_accuracy: 0.7965\n",
            "Epoch 2/10\n",
            "11280/11280 - 26s - loss: 0.1192 - accuracy: 0.7877 - val_loss: 0.1135 - val_accuracy: 0.7986\n",
            "Epoch 3/10\n",
            "11280/11280 - 26s - loss: 0.1129 - accuracy: 0.7987 - val_loss: 0.1126 - val_accuracy: 0.8067\n",
            "Epoch 4/10\n",
            "11280/11280 - 26s - loss: 0.1082 - accuracy: 0.8122 - val_loss: 0.1173 - val_accuracy: 0.7954\n",
            "Epoch 5/10\n",
            "11280/11280 - 26s - loss: 0.1035 - accuracy: 0.8239 - val_loss: 0.1163 - val_accuracy: 0.8018\n",
            "Epoch 6/10\n",
            "11280/11280 - 26s - loss: 0.0968 - accuracy: 0.8377 - val_loss: 0.1198 - val_accuracy: 0.8007\n",
            "Epoch 7/10\n",
            "11280/11280 - 26s - loss: 0.0872 - accuracy: 0.8565 - val_loss: 0.1257 - val_accuracy: 0.7989\n",
            "Epoch 8/10\n",
            "11280/11280 - 26s - loss: 0.0749 - accuracy: 0.8816 - val_loss: 0.1361 - val_accuracy: 0.7922\n",
            "Epoch 9/10\n",
            "11280/11280 - 26s - loss: 0.0653 - accuracy: 0.9013 - val_loss: 0.1523 - val_accuracy: 0.7766\n",
            "Epoch 10/10\n",
            "11280/11280 - 26s - loss: 0.0547 - accuracy: 0.9188 - val_loss: 0.1659 - val_accuracy: 0.7752\n",
            "2820/2820 [==============================] - 4s 1ms/sample\n",
            "3887/3887 [==============================] - 3s 884us/sample\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vo1Ec10_FbH4",
        "colab_type": "code",
        "outputId": "7df47edf-23ba-43d0-d940-557a951889f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        " np.mean(atten_scores)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7335868950649289"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlFNurr4T1rh",
        "colab_type": "text"
      },
      "source": [
        "##TCN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKtfxHFBT2wB",
        "colab_type": "code",
        "outputId": "fbc99015-bcb7-4828-bb16-d11fdd7df67a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "kfold = StratifiedKFold(n_splits=5, shuffle=False)\n",
        "tcn_scores = []\n",
        "tcn_test=[]\n",
        "for train, val in kfold.split(sequences_matrix, labels):\n",
        "  model=model_tcn(embeddings)\n",
        "  \n",
        "  model.fit(sequences_matrix[train], labels[train],batch_size=64,epochs=10,verbose=2,\n",
        "            validation_data=(sequences_matrix[val],labels[val]),callbacks=[clr,])\n",
        "  y_pred = model.predict(sequences_matrix[val], batch_size=64, verbose=1)\n",
        "\n",
        "  tcn_test.append(model.predict(X_test_sequences, batch_size=64, verbose=1).ravel())\n",
        "\n",
        "  y_pred = (y_pred > 0.5)\n",
        "  f1=f1_score(labels[val], y_pred, average='macro')\n",
        "  tcn_scores.append(f1)\n",
        "  tf.keras.backend.clear_session()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 11280 samples, validate on 2820 samples\n",
            "Epoch 1/10\n",
            "11280/11280 - 11s - loss: 0.1545 - accuracy: 0.6800 - val_loss: 0.1330 - val_accuracy: 0.7599\n",
            "Epoch 2/10\n",
            "11280/11280 - 8s - loss: 0.1281 - accuracy: 0.7707 - val_loss: 0.1305 - val_accuracy: 0.7670\n",
            "Epoch 3/10\n",
            "11280/11280 - 8s - loss: 0.1224 - accuracy: 0.7887 - val_loss: 0.1343 - val_accuracy: 0.7652\n",
            "Epoch 4/10\n",
            "11280/11280 - 8s - loss: 0.1194 - accuracy: 0.7943 - val_loss: 0.1221 - val_accuracy: 0.7780\n",
            "Epoch 5/10\n",
            "11280/11280 - 8s - loss: 0.1166 - accuracy: 0.7939 - val_loss: 0.1213 - val_accuracy: 0.7738\n",
            "Epoch 6/10\n",
            "11280/11280 - 8s - loss: 0.1184 - accuracy: 0.7899 - val_loss: 0.1236 - val_accuracy: 0.7745\n",
            "Epoch 7/10\n",
            "11280/11280 - 8s - loss: 0.1147 - accuracy: 0.8027 - val_loss: 0.1244 - val_accuracy: 0.7908\n",
            "Epoch 8/10\n",
            "11280/11280 - 8s - loss: 0.1132 - accuracy: 0.8034 - val_loss: 0.1203 - val_accuracy: 0.7855\n",
            "Epoch 9/10\n",
            "11280/11280 - 8s - loss: 0.1099 - accuracy: 0.8105 - val_loss: 0.1209 - val_accuracy: 0.7922\n",
            "Epoch 10/10\n",
            "11280/11280 - 8s - loss: 0.1081 - accuracy: 0.8171 - val_loss: 0.1259 - val_accuracy: 0.7823\n",
            "2820/2820 [==============================] - 1s 407us/sample\n",
            "3887/3887 [==============================] - 2s 462us/sample\n",
            "Train on 11280 samples, validate on 2820 samples\n",
            "Epoch 1/10\n",
            "11280/11280 - 11s - loss: 0.1415 - accuracy: 0.7284 - val_loss: 0.1274 - val_accuracy: 0.7571\n",
            "Epoch 2/10\n",
            "11280/11280 - 8s - loss: 0.1261 - accuracy: 0.7809 - val_loss: 0.1239 - val_accuracy: 0.7801\n",
            "Epoch 3/10\n",
            "11280/11280 - 8s - loss: 0.1230 - accuracy: 0.7789 - val_loss: 0.1192 - val_accuracy: 0.7876\n",
            "Epoch 4/10\n",
            "11280/11280 - 8s - loss: 0.1198 - accuracy: 0.7905 - val_loss: 0.1203 - val_accuracy: 0.7830\n",
            "Epoch 5/10\n",
            "11280/11280 - 8s - loss: 0.1176 - accuracy: 0.7967 - val_loss: 0.1210 - val_accuracy: 0.7876\n",
            "Epoch 6/10\n",
            "11280/11280 - 8s - loss: 0.1158 - accuracy: 0.7993 - val_loss: 0.1203 - val_accuracy: 0.7872\n",
            "Epoch 7/10\n",
            "11280/11280 - 8s - loss: 0.1144 - accuracy: 0.7997 - val_loss: 0.1227 - val_accuracy: 0.7833\n",
            "Epoch 8/10\n",
            "11280/11280 - 8s - loss: 0.1129 - accuracy: 0.8089 - val_loss: 0.1171 - val_accuracy: 0.7897\n",
            "Epoch 9/10\n",
            "11280/11280 - 8s - loss: 0.1098 - accuracy: 0.8106 - val_loss: 0.1239 - val_accuracy: 0.7823\n",
            "Epoch 10/10\n",
            "11280/11280 - 8s - loss: 0.1088 - accuracy: 0.8137 - val_loss: 0.1202 - val_accuracy: 0.7872\n",
            "2820/2820 [==============================] - 1s 416us/sample\n",
            "3887/3887 [==============================] - 1s 278us/sample\n",
            "Train on 11280 samples, validate on 2820 samples\n",
            "Epoch 1/10\n",
            "11280/11280 - 12s - loss: 0.1520 - accuracy: 0.6862 - val_loss: 0.1339 - val_accuracy: 0.7348\n",
            "Epoch 2/10\n",
            "11280/11280 - 8s - loss: 0.1293 - accuracy: 0.7644 - val_loss: 0.1209 - val_accuracy: 0.7872\n",
            "Epoch 3/10\n",
            "11280/11280 - 8s - loss: 0.1241 - accuracy: 0.7846 - val_loss: 0.1200 - val_accuracy: 0.7894\n",
            "Epoch 4/10\n",
            "11280/11280 - 8s - loss: 0.1223 - accuracy: 0.7825 - val_loss: 0.1218 - val_accuracy: 0.7936\n",
            "Epoch 5/10\n",
            "11280/11280 - 8s - loss: 0.1211 - accuracy: 0.7879 - val_loss: 0.1181 - val_accuracy: 0.7894\n",
            "Epoch 6/10\n",
            "11280/11280 - 8s - loss: 0.1187 - accuracy: 0.7950 - val_loss: 0.1270 - val_accuracy: 0.7571\n",
            "Epoch 7/10\n",
            "11280/11280 - 8s - loss: 0.1162 - accuracy: 0.8013 - val_loss: 0.1211 - val_accuracy: 0.7855\n",
            "Epoch 8/10\n",
            "11280/11280 - 8s - loss: 0.1157 - accuracy: 0.8032 - val_loss: 0.1209 - val_accuracy: 0.7770\n",
            "Epoch 9/10\n",
            "11280/11280 - 8s - loss: 0.1166 - accuracy: 0.7957 - val_loss: 0.1208 - val_accuracy: 0.7812\n",
            "Epoch 10/10\n",
            "11280/11280 - 8s - loss: 0.1147 - accuracy: 0.8031 - val_loss: 0.1214 - val_accuracy: 0.7883\n",
            "2820/2820 [==============================] - 1s 419us/sample\n",
            "3887/3887 [==============================] - 1s 279us/sample\n",
            "Train on 11280 samples, validate on 2820 samples\n",
            "Epoch 1/10\n",
            "11280/11280 - 11s - loss: 0.1523 - accuracy: 0.6908 - val_loss: 0.1384 - val_accuracy: 0.7287\n",
            "Epoch 2/10\n",
            "11280/11280 - 8s - loss: 0.1274 - accuracy: 0.7707 - val_loss: 0.1229 - val_accuracy: 0.7840\n",
            "Epoch 3/10\n",
            "11280/11280 - 8s - loss: 0.1210 - accuracy: 0.7866 - val_loss: 0.1251 - val_accuracy: 0.7670\n",
            "Epoch 4/10\n",
            "11280/11280 - 8s - loss: 0.1195 - accuracy: 0.7893 - val_loss: 0.1200 - val_accuracy: 0.7933\n",
            "Epoch 5/10\n",
            "11280/11280 - 8s - loss: 0.1161 - accuracy: 0.7983 - val_loss: 0.1207 - val_accuracy: 0.7794\n",
            "Epoch 6/10\n",
            "11280/11280 - 8s - loss: 0.1140 - accuracy: 0.8036 - val_loss: 0.1223 - val_accuracy: 0.7805\n",
            "Epoch 7/10\n",
            "11280/11280 - 8s - loss: 0.1101 - accuracy: 0.8121 - val_loss: 0.1200 - val_accuracy: 0.7933\n",
            "Epoch 8/10\n",
            "11280/11280 - 8s - loss: 0.1098 - accuracy: 0.8116 - val_loss: 0.1265 - val_accuracy: 0.7695\n",
            "Epoch 9/10\n",
            "11280/11280 - 8s - loss: 0.1073 - accuracy: 0.8158 - val_loss: 0.1348 - val_accuracy: 0.7883\n",
            "Epoch 10/10\n",
            "11280/11280 - 8s - loss: 0.1056 - accuracy: 0.8196 - val_loss: 0.1345 - val_accuracy: 0.7592\n",
            "2820/2820 [==============================] - 1s 406us/sample\n",
            "3887/3887 [==============================] - 1s 271us/sample\n",
            "Train on 11280 samples, validate on 2820 samples\n",
            "Epoch 1/10\n",
            "11280/11280 - 11s - loss: 0.1482 - accuracy: 0.7017 - val_loss: 0.1281 - val_accuracy: 0.7855\n",
            "Epoch 2/10\n",
            "11280/11280 - 8s - loss: 0.1296 - accuracy: 0.7681 - val_loss: 0.1228 - val_accuracy: 0.7858\n",
            "Epoch 3/10\n",
            "11280/11280 - 8s - loss: 0.1232 - accuracy: 0.7840 - val_loss: 0.1203 - val_accuracy: 0.7766\n",
            "Epoch 4/10\n",
            "11280/11280 - 8s - loss: 0.1205 - accuracy: 0.7929 - val_loss: 0.1181 - val_accuracy: 0.7979\n",
            "Epoch 5/10\n",
            "11280/11280 - 8s - loss: 0.1175 - accuracy: 0.7966 - val_loss: 0.1164 - val_accuracy: 0.7989\n",
            "Epoch 6/10\n",
            "11280/11280 - 8s - loss: 0.1168 - accuracy: 0.7967 - val_loss: 0.1207 - val_accuracy: 0.7904\n",
            "Epoch 7/10\n",
            "11280/11280 - 8s - loss: 0.1140 - accuracy: 0.8024 - val_loss: 0.1161 - val_accuracy: 0.7957\n",
            "Epoch 8/10\n",
            "11280/11280 - 8s - loss: 0.1118 - accuracy: 0.8058 - val_loss: 0.1201 - val_accuracy: 0.7975\n",
            "Epoch 9/10\n",
            "11280/11280 - 8s - loss: 0.1108 - accuracy: 0.8096 - val_loss: 0.1172 - val_accuracy: 0.7901\n",
            "Epoch 10/10\n",
            "11280/11280 - 8s - loss: 0.1088 - accuracy: 0.8117 - val_loss: 0.1211 - val_accuracy: 0.7979\n",
            "2820/2820 [==============================] - 1s 405us/sample\n",
            "3887/3887 [==============================] - 1s 271us/sample\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QX_otDrKtboX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "6552feea-7601-4229-8876-77429225fe01"
      },
      "source": [
        "np.mean(tcn_scores)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7444826147601272"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tr_J6FWTCYXB",
        "colab_type": "text"
      },
      "source": [
        "##KIM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgmUF8liCa4M",
        "colab_type": "code",
        "outputId": "5e44d9a3-4e8f-4be8-883b-2ffe333621d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "kfold = StratifiedKFold(n_splits=5, shuffle=False)\n",
        "kim_scores = []\n",
        "kim_test=[]\n",
        "for train, val in kfold.split(sequences_matrix, labels):\n",
        "  model=model_kim()\n",
        "  \n",
        "  model.fit(sequences_matrix[train], labels[train],batch_size=64,epochs=10,verbose=2,\n",
        "            validation_data=(sequences_matrix[val],labels[val]),callbacks=[clr,])\n",
        "  y_pred = model.predict(sequences_matrix[val], batch_size=64, verbose=1)\n",
        "\n",
        "  kim_test.append(model.predict(X_test_sequences, batch_size=64, verbose=1).ravel())\n",
        "\n",
        "  y_pred = (y_pred > 0.5)\n",
        "  f1=f1_score(labels[val], y_pred, average='macro')\n",
        "  kim_scores.append(f1)\n",
        "  tf.keras.backend.clear_session()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 11280 samples, validate on 2820 samples\n",
            "Epoch 1/10\n",
            "11280/11280 - 9s - loss: 0.2076 - accuracy: 0.6854 - val_loss: 0.2119 - val_accuracy: 0.6709\n",
            "Epoch 2/10\n",
            "11280/11280 - 6s - loss: 0.1377 - accuracy: 0.7612 - val_loss: 0.1799 - val_accuracy: 0.6755\n",
            "Epoch 3/10\n",
            "11280/11280 - 6s - loss: 0.1196 - accuracy: 0.7947 - val_loss: 0.1384 - val_accuracy: 0.7418\n",
            "Epoch 4/10\n",
            "11280/11280 - 6s - loss: 0.1045 - accuracy: 0.8223 - val_loss: 0.1398 - val_accuracy: 0.7628\n",
            "Epoch 5/10\n",
            "11280/11280 - 6s - loss: 0.0975 - accuracy: 0.8365 - val_loss: 0.1281 - val_accuracy: 0.7809\n",
            "Epoch 6/10\n",
            "11280/11280 - 6s - loss: 0.0842 - accuracy: 0.8668 - val_loss: 0.1313 - val_accuracy: 0.7865\n",
            "Epoch 7/10\n",
            "11280/11280 - 6s - loss: 0.0737 - accuracy: 0.8818 - val_loss: 0.1363 - val_accuracy: 0.7610\n",
            "Epoch 8/10\n",
            "11280/11280 - 6s - loss: 0.0675 - accuracy: 0.8989 - val_loss: 0.1455 - val_accuracy: 0.7833\n",
            "Epoch 9/10\n",
            "11280/11280 - 6s - loss: 0.0568 - accuracy: 0.9152 - val_loss: 0.1499 - val_accuracy: 0.7773\n",
            "Epoch 10/10\n",
            "11280/11280 - 6s - loss: 0.0517 - accuracy: 0.9232 - val_loss: 0.1661 - val_accuracy: 0.7387\n",
            "2820/2820 [==============================] - 1s 233us/sample\n",
            "3887/3887 [==============================] - 1s 191us/sample\n",
            "Train on 11280 samples, validate on 2820 samples\n",
            "Epoch 1/10\n",
            "11280/11280 - 8s - loss: 0.1819 - accuracy: 0.6998 - val_loss: 0.2058 - val_accuracy: 0.6709\n",
            "Epoch 2/10\n",
            "11280/11280 - 6s - loss: 0.1298 - accuracy: 0.7797 - val_loss: 0.1561 - val_accuracy: 0.6844\n",
            "Epoch 3/10\n",
            "11280/11280 - 6s - loss: 0.1124 - accuracy: 0.8056 - val_loss: 0.1236 - val_accuracy: 0.7695\n",
            "Epoch 4/10\n",
            "11280/11280 - 6s - loss: 0.1007 - accuracy: 0.8310 - val_loss: 0.1242 - val_accuracy: 0.7762\n",
            "Epoch 5/10\n",
            "11280/11280 - 6s - loss: 0.0888 - accuracy: 0.8543 - val_loss: 0.1303 - val_accuracy: 0.7684\n",
            "Epoch 6/10\n",
            "11280/11280 - 6s - loss: 0.0819 - accuracy: 0.8671 - val_loss: 0.1816 - val_accuracy: 0.7521\n",
            "Epoch 7/10\n",
            "11280/11280 - 6s - loss: 0.0724 - accuracy: 0.8890 - val_loss: 0.1360 - val_accuracy: 0.7823\n",
            "Epoch 8/10\n",
            "11280/11280 - 6s - loss: 0.0607 - accuracy: 0.9091 - val_loss: 0.1478 - val_accuracy: 0.7663\n",
            "Epoch 9/10\n",
            "11280/11280 - 6s - loss: 0.0565 - accuracy: 0.9140 - val_loss: 0.1722 - val_accuracy: 0.7748\n",
            "Epoch 10/10\n",
            "11280/11280 - 6s - loss: 0.0520 - accuracy: 0.9247 - val_loss: 0.1559 - val_accuracy: 0.7638\n",
            "2820/2820 [==============================] - 1s 237us/sample\n",
            "3887/3887 [==============================] - 1s 178us/sample\n",
            "Train on 11280 samples, validate on 2820 samples\n",
            "Epoch 1/10\n",
            "11280/11280 - 8s - loss: 0.1949 - accuracy: 0.6890 - val_loss: 0.1849 - val_accuracy: 0.6709\n",
            "Epoch 2/10\n",
            "11280/11280 - 6s - loss: 0.1320 - accuracy: 0.7687 - val_loss: 0.1767 - val_accuracy: 0.6752\n",
            "Epoch 3/10\n",
            "11280/11280 - 6s - loss: 0.1174 - accuracy: 0.7971 - val_loss: 0.1414 - val_accuracy: 0.7379\n",
            "Epoch 4/10\n",
            "11280/11280 - 6s - loss: 0.1050 - accuracy: 0.8249 - val_loss: 0.1218 - val_accuracy: 0.7876\n",
            "Epoch 5/10\n",
            "11280/11280 - 6s - loss: 0.0984 - accuracy: 0.8338 - val_loss: 0.1225 - val_accuracy: 0.7883\n",
            "Epoch 6/10\n",
            "11280/11280 - 6s - loss: 0.0834 - accuracy: 0.8642 - val_loss: 0.1264 - val_accuracy: 0.7823\n",
            "Epoch 7/10\n",
            "11280/11280 - 6s - loss: 0.0744 - accuracy: 0.8836 - val_loss: 0.1343 - val_accuracy: 0.7897\n",
            "Epoch 8/10\n",
            "11280/11280 - 6s - loss: 0.0663 - accuracy: 0.8988 - val_loss: 0.1454 - val_accuracy: 0.7862\n",
            "Epoch 9/10\n",
            "11280/11280 - 6s - loss: 0.0580 - accuracy: 0.9132 - val_loss: 0.1454 - val_accuracy: 0.7809\n",
            "Epoch 10/10\n",
            "11280/11280 - 6s - loss: 0.0544 - accuracy: 0.9187 - val_loss: 0.1844 - val_accuracy: 0.7837\n",
            "2820/2820 [==============================] - 1s 234us/sample\n",
            "3887/3887 [==============================] - 1s 175us/sample\n",
            "Train on 11280 samples, validate on 2820 samples\n",
            "Epoch 1/10\n",
            "11280/11280 - 8s - loss: 0.2024 - accuracy: 0.6827 - val_loss: 0.2062 - val_accuracy: 0.6713\n",
            "Epoch 2/10\n",
            "11280/11280 - 6s - loss: 0.1393 - accuracy: 0.7593 - val_loss: 0.1661 - val_accuracy: 0.6805\n",
            "Epoch 3/10\n",
            "11280/11280 - 6s - loss: 0.1224 - accuracy: 0.7838 - val_loss: 0.1352 - val_accuracy: 0.7422\n",
            "Epoch 4/10\n",
            "11280/11280 - 6s - loss: 0.1085 - accuracy: 0.8179 - val_loss: 0.1205 - val_accuracy: 0.7901\n",
            "Epoch 5/10\n",
            "11280/11280 - 6s - loss: 0.0956 - accuracy: 0.8405 - val_loss: 0.1408 - val_accuracy: 0.7660\n",
            "Epoch 6/10\n",
            "11280/11280 - 6s - loss: 0.0846 - accuracy: 0.8632 - val_loss: 0.1255 - val_accuracy: 0.7801\n",
            "Epoch 7/10\n",
            "11280/11280 - 6s - loss: 0.0737 - accuracy: 0.8857 - val_loss: 0.1315 - val_accuracy: 0.7720\n",
            "Epoch 8/10\n",
            "11280/11280 - 6s - loss: 0.0667 - accuracy: 0.8992 - val_loss: 0.1426 - val_accuracy: 0.7663\n",
            "Epoch 9/10\n",
            "11280/11280 - 6s - loss: 0.0604 - accuracy: 0.9110 - val_loss: 0.2307 - val_accuracy: 0.7500\n",
            "Epoch 10/10\n",
            "11280/11280 - 6s - loss: 0.0539 - accuracy: 0.9222 - val_loss: 0.1464 - val_accuracy: 0.7709\n",
            "2820/2820 [==============================] - 1s 234us/sample\n",
            "3887/3887 [==============================] - 1s 176us/sample\n",
            "Train on 11280 samples, validate on 2820 samples\n",
            "Epoch 1/10\n",
            "11280/11280 - 9s - loss: 0.2048 - accuracy: 0.6803 - val_loss: 0.2193 - val_accuracy: 0.6709\n",
            "Epoch 2/10\n",
            "11280/11280 - 6s - loss: 0.1396 - accuracy: 0.7580 - val_loss: 0.1687 - val_accuracy: 0.6777\n",
            "Epoch 3/10\n",
            "11280/11280 - 6s - loss: 0.1221 - accuracy: 0.7879 - val_loss: 0.1208 - val_accuracy: 0.7819\n",
            "Epoch 4/10\n",
            "11280/11280 - 6s - loss: 0.1064 - accuracy: 0.8160 - val_loss: 0.1277 - val_accuracy: 0.7840\n",
            "Epoch 5/10\n",
            "11280/11280 - 6s - loss: 0.0955 - accuracy: 0.8399 - val_loss: 0.1456 - val_accuracy: 0.7660\n",
            "Epoch 6/10\n",
            "11280/11280 - 6s - loss: 0.0818 - accuracy: 0.8697 - val_loss: 0.1592 - val_accuracy: 0.7681\n",
            "Epoch 7/10\n",
            "11280/11280 - 6s - loss: 0.0726 - accuracy: 0.8875 - val_loss: 0.1325 - val_accuracy: 0.7887\n",
            "Epoch 8/10\n",
            "11280/11280 - 6s - loss: 0.0639 - accuracy: 0.9032 - val_loss: 0.1417 - val_accuracy: 0.7660\n",
            "Epoch 9/10\n",
            "11280/11280 - 6s - loss: 0.0580 - accuracy: 0.9135 - val_loss: 0.1615 - val_accuracy: 0.7837\n",
            "Epoch 10/10\n",
            "11280/11280 - 6s - loss: 0.0520 - accuracy: 0.9257 - val_loss: 0.1797 - val_accuracy: 0.7855\n",
            "2820/2820 [==============================] - 1s 237us/sample\n",
            "3887/3887 [==============================] - 1s 179us/sample\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-3gnxQNthHT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "ced8853c-9b78-40f5-afb3-74428e10b647"
      },
      "source": [
        "np.mean(kim_scores)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7245472865145907"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cl7x9txIrSRr",
        "colab_type": "text"
      },
      "source": [
        "##GRU_CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rl6lTvncrTai",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5c5a7cc9-97ca-4edc-d3b6-c9aebc6719a3"
      },
      "source": [
        "kfold = StratifiedKFold(n_splits=5, shuffle=False)\n",
        "grucnn_scores = []\n",
        "grucnn_test=[]\n",
        "for train, val in kfold.split(sequences_matrix, labels):\n",
        "  model=model_gru_cnn()\n",
        "  \n",
        "  model.fit(sequences_matrix[train], labels[train],batch_size=64,epochs=10,verbose=2,\n",
        "            validation_data=(sequences_matrix[val],labels[val]),callbacks=[clr,])\n",
        "  y_pred = model.predict(sequences_matrix[val], batch_size=64, verbose=1)\n",
        "\n",
        "  grucnn_test.append(model.predict(X_test_sequences, batch_size=64, verbose=1).ravel())\n",
        "\n",
        "  y_pred = (y_pred > 0.5)\n",
        "  f1=f1_score(labels[val], y_pred, average='macro')\n",
        "  grucnn_scores.append(f1)\n",
        "  tf.keras.backend.clear_session()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 11280 samples, validate on 2820 samples\n",
            "Epoch 1/10\n",
            "11280/11280 - 16s - loss: 0.1353 - accuracy: 0.7413 - val_loss: 0.1228 - val_accuracy: 0.7755\n",
            "Epoch 2/10\n",
            "11280/11280 - 13s - loss: 0.1224 - accuracy: 0.7801 - val_loss: 0.1199 - val_accuracy: 0.7805\n",
            "Epoch 3/10\n",
            "11280/11280 - 13s - loss: 0.1200 - accuracy: 0.7873 - val_loss: 0.1175 - val_accuracy: 0.7929\n",
            "Epoch 4/10\n",
            "11280/11280 - 13s - loss: 0.1172 - accuracy: 0.7936 - val_loss: 0.1180 - val_accuracy: 0.7887\n",
            "Epoch 5/10\n",
            "11280/11280 - 13s - loss: 0.1158 - accuracy: 0.7955 - val_loss: 0.1171 - val_accuracy: 0.7879\n",
            "Epoch 6/10\n",
            "11280/11280 - 13s - loss: 0.1142 - accuracy: 0.7947 - val_loss: 0.1166 - val_accuracy: 0.7848\n",
            "Epoch 7/10\n",
            "11280/11280 - 13s - loss: 0.1108 - accuracy: 0.8050 - val_loss: 0.1184 - val_accuracy: 0.7901\n",
            "Epoch 8/10\n",
            "11280/11280 - 13s - loss: 0.1096 - accuracy: 0.8068 - val_loss: 0.1233 - val_accuracy: 0.7635\n",
            "Epoch 9/10\n",
            "11280/11280 - 13s - loss: 0.1060 - accuracy: 0.8153 - val_loss: 0.1261 - val_accuracy: 0.7851\n",
            "Epoch 10/10\n",
            "11280/11280 - 13s - loss: 0.1037 - accuracy: 0.8239 - val_loss: 0.1176 - val_accuracy: 0.7823\n",
            "2820/2820 [==============================] - 2s 560us/sample\n",
            "3887/3887 [==============================] - 1s 350us/sample\n",
            "Train on 11280 samples, validate on 2820 samples\n",
            "Epoch 1/10\n",
            "11280/11280 - 16s - loss: 0.1365 - accuracy: 0.7441 - val_loss: 0.1225 - val_accuracy: 0.7816\n",
            "Epoch 2/10\n",
            "11280/11280 - 13s - loss: 0.1234 - accuracy: 0.7828 - val_loss: 0.1186 - val_accuracy: 0.7816\n",
            "Epoch 3/10\n",
            "11280/11280 - 13s - loss: 0.1192 - accuracy: 0.7916 - val_loss: 0.1205 - val_accuracy: 0.7826\n",
            "Epoch 4/10\n",
            "11280/11280 - 13s - loss: 0.1179 - accuracy: 0.7953 - val_loss: 0.1172 - val_accuracy: 0.7862\n",
            "Epoch 5/10\n",
            "11280/11280 - 13s - loss: 0.1152 - accuracy: 0.7988 - val_loss: 0.1169 - val_accuracy: 0.7862\n",
            "Epoch 6/10\n",
            "11280/11280 - 13s - loss: 0.1127 - accuracy: 0.8051 - val_loss: 0.1172 - val_accuracy: 0.7883\n",
            "Epoch 7/10\n",
            "11280/11280 - 13s - loss: 0.1106 - accuracy: 0.8079 - val_loss: 0.1193 - val_accuracy: 0.7862\n",
            "Epoch 8/10\n",
            "11280/11280 - 13s - loss: 0.1080 - accuracy: 0.8159 - val_loss: 0.1211 - val_accuracy: 0.7770\n",
            "Epoch 9/10\n",
            "11280/11280 - 13s - loss: 0.1066 - accuracy: 0.8142 - val_loss: 0.1200 - val_accuracy: 0.7894\n",
            "Epoch 10/10\n",
            "11280/11280 - 12s - loss: 0.1019 - accuracy: 0.8278 - val_loss: 0.1287 - val_accuracy: 0.7479\n",
            "2820/2820 [==============================] - 2s 552us/sample\n",
            "3887/3887 [==============================] - 1s 348us/sample\n",
            "Train on 11280 samples, validate on 2820 samples\n",
            "Epoch 1/10\n",
            "11280/11280 - 16s - loss: 0.1407 - accuracy: 0.7236 - val_loss: 0.1194 - val_accuracy: 0.7890\n",
            "Epoch 2/10\n",
            "11280/11280 - 13s - loss: 0.1228 - accuracy: 0.7785 - val_loss: 0.1167 - val_accuracy: 0.7947\n",
            "Epoch 3/10\n",
            "11280/11280 - 13s - loss: 0.1193 - accuracy: 0.7862 - val_loss: 0.1235 - val_accuracy: 0.7798\n",
            "Epoch 4/10\n",
            "11280/11280 - 12s - loss: 0.1178 - accuracy: 0.7909 - val_loss: 0.1233 - val_accuracy: 0.7819\n",
            "Epoch 5/10\n",
            "11280/11280 - 12s - loss: 0.1155 - accuracy: 0.7982 - val_loss: 0.1173 - val_accuracy: 0.7975\n",
            "Epoch 6/10\n",
            "11280/11280 - 12s - loss: 0.1136 - accuracy: 0.7976 - val_loss: 0.1175 - val_accuracy: 0.8021\n",
            "Epoch 7/10\n",
            "11280/11280 - 12s - loss: 0.1108 - accuracy: 0.8049 - val_loss: 0.1214 - val_accuracy: 0.7805\n",
            "Epoch 8/10\n",
            "11280/11280 - 13s - loss: 0.1101 - accuracy: 0.8090 - val_loss: 0.1181 - val_accuracy: 0.7940\n",
            "Epoch 9/10\n",
            "11280/11280 - 13s - loss: 0.1056 - accuracy: 0.8181 - val_loss: 0.1186 - val_accuracy: 0.8004\n",
            "Epoch 10/10\n",
            "11280/11280 - 13s - loss: 0.1040 - accuracy: 0.8221 - val_loss: 0.1201 - val_accuracy: 0.8007\n",
            "2820/2820 [==============================] - 2s 561us/sample\n",
            "3887/3887 [==============================] - 1s 356us/sample\n",
            "Train on 11280 samples, validate on 2820 samples\n",
            "Epoch 1/10\n",
            "11280/11280 - 16s - loss: 0.1372 - accuracy: 0.7332 - val_loss: 0.1210 - val_accuracy: 0.7869\n",
            "Epoch 2/10\n",
            "11280/11280 - 13s - loss: 0.1220 - accuracy: 0.7787 - val_loss: 0.1184 - val_accuracy: 0.7855\n",
            "Epoch 3/10\n",
            "11280/11280 - 13s - loss: 0.1207 - accuracy: 0.7841 - val_loss: 0.1189 - val_accuracy: 0.7887\n",
            "Epoch 4/10\n",
            "11280/11280 - 13s - loss: 0.1183 - accuracy: 0.7910 - val_loss: 0.1186 - val_accuracy: 0.7918\n",
            "Epoch 5/10\n",
            "11280/11280 - 13s - loss: 0.1158 - accuracy: 0.7978 - val_loss: 0.1194 - val_accuracy: 0.7823\n",
            "Epoch 6/10\n",
            "11280/11280 - 13s - loss: 0.1130 - accuracy: 0.7973 - val_loss: 0.1180 - val_accuracy: 0.7897\n",
            "Epoch 7/10\n",
            "11280/11280 - 13s - loss: 0.1106 - accuracy: 0.8071 - val_loss: 0.1174 - val_accuracy: 0.7957\n",
            "Epoch 8/10\n",
            "11280/11280 - 13s - loss: 0.1094 - accuracy: 0.8114 - val_loss: 0.1183 - val_accuracy: 0.7904\n",
            "Epoch 9/10\n",
            "11280/11280 - 13s - loss: 0.1060 - accuracy: 0.8193 - val_loss: 0.1187 - val_accuracy: 0.7862\n",
            "Epoch 10/10\n",
            "11280/11280 - 13s - loss: 0.1048 - accuracy: 0.8175 - val_loss: 0.1201 - val_accuracy: 0.7840\n",
            "2820/2820 [==============================] - 2s 785us/sample\n",
            "3887/3887 [==============================] - 1s 354us/sample\n",
            "Train on 11280 samples, validate on 2820 samples\n",
            "Epoch 1/10\n",
            "11280/11280 - 16s - loss: 0.1369 - accuracy: 0.7427 - val_loss: 0.1219 - val_accuracy: 0.7798\n",
            "Epoch 2/10\n",
            "11280/11280 - 13s - loss: 0.1240 - accuracy: 0.7787 - val_loss: 0.1158 - val_accuracy: 0.8011\n",
            "Epoch 3/10\n",
            "11280/11280 - 13s - loss: 0.1213 - accuracy: 0.7844 - val_loss: 0.1139 - val_accuracy: 0.8018\n",
            "Epoch 4/10\n",
            "11280/11280 - 13s - loss: 0.1193 - accuracy: 0.7890 - val_loss: 0.1141 - val_accuracy: 0.8014\n",
            "Epoch 5/10\n",
            "11280/11280 - 13s - loss: 0.1168 - accuracy: 0.7935 - val_loss: 0.1141 - val_accuracy: 0.8028\n",
            "Epoch 6/10\n",
            "11280/11280 - 13s - loss: 0.1125 - accuracy: 0.8028 - val_loss: 0.1154 - val_accuracy: 0.7986\n",
            "Epoch 7/10\n",
            "11280/11280 - 13s - loss: 0.1121 - accuracy: 0.8021 - val_loss: 0.1149 - val_accuracy: 0.8025\n",
            "Epoch 8/10\n",
            "11280/11280 - 13s - loss: 0.1094 - accuracy: 0.8101 - val_loss: 0.1153 - val_accuracy: 0.8067\n",
            "Epoch 9/10\n",
            "11280/11280 - 13s - loss: 0.1061 - accuracy: 0.8155 - val_loss: 0.1150 - val_accuracy: 0.8064\n",
            "Epoch 10/10\n",
            "11280/11280 - 13s - loss: 0.1033 - accuracy: 0.8216 - val_loss: 0.1168 - val_accuracy: 0.7933\n",
            "2820/2820 [==============================] - 2s 566us/sample\n",
            "3887/3887 [==============================] - 1s 356us/sample\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIiSnpMKtop7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "c5ebcec2-b154-453b-c237-278b75923b8d"
      },
      "source": [
        "np.mean(grucnn_scores)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7553129479407418"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bXDiFxJH5Ny",
        "colab_type": "text"
      },
      "source": [
        "#**Result**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXd8VkdPhAq2",
        "colab_type": "text"
      },
      "source": [
        "# Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnC41n_HRKQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gru_scores=np.average(np.array(gru_scores))\n",
        "atten_scores=np.average(np.array(atten_scores))\n",
        "tcn_scores=np.average(np.array(tcn_scores))\n",
        "kim_scores=np.average(np.array(kim_scores))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBp341Qog_uv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('f1 score of count vec' ,cv_score)\n",
        "print('f1 score of word tfidf' ,tfw_score)\n",
        "print('f1 score of char tfidf' ,tfc_score)\n",
        "\n",
        "print('f1 score of RNN' ,gru_scores)\n",
        "print('f1 score of gated attention',atten_scores )\n",
        "print('f1 score of tcn',tcn_scores)\n",
        "print('f1 score of kim',kim_scores)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipijYwvjJPyx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kim_test_avg=np.mean(np.array(kim_test),axis=0)\n",
        "gru_test_avg=np.mean(np.array(gru_test),axis=0)\n",
        "atten_test_avg=np.mean(np.array(atten_test),axis=0)\n",
        "tcn_test_avg=np.mean(np.array(tcn_test),axis=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAMx_NI2jltK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kim_test[0].shape,cv_test.shape,kim_test_avg.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZ8CR7s1Qe18",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(cv_test[5:15].round())\n",
        "print(tfw_test[5:15].round())\n",
        "print(tfc_test[5:15].round())\n",
        "print(gru_test_avg[5:15].round())\n",
        "print(atten_test_avg[5:15].round())\n",
        "print(kim_test_avg[5:15].round())\n",
        "print(tcn_test_avg[5:15].round())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DW1OugTMEpZg",
        "colab_type": "text"
      },
      "source": [
        "# Ensemble"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6VT0aVcUIhm",
        "colab_type": "text"
      },
      "source": [
        "we will choose only those, having f1 greater than 0.7. Once they are selected, we will decode labels, and keep label according to mod"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wmQlS5LkZLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wt=gru_scores+atten_scores+cv_score+tfw_score+tfc_score+tcn_scores+kim_scores\n",
        "wt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkCLYtxOcXCA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#i am bit changing the distribution in order to give more weightage to ml than dl\n",
        "y_test=gru_scores/wt * gru_test_avg + atten_scores/wt * atten_test_avg + cv_score/wt * cv_test + tfw_score/wt *tfw_test + tfc_score/wt *tfc_test +kim_scores/wt * kim_test_avg + tcn_scores/wt *tcn_test_avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzRAIebNSpMz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test[5:15].round()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9Pu0LvuZIf8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode(y_test):\n",
        "  y_test[y_test>0.5]=1\n",
        "  y_test[y_test<0.5]=0\n",
        "  y_test=y_test.astype('int16').ravel()\n",
        "\n",
        "  y_test=le.inverse_transform(y_test)\n",
        "  y_test=pd.DataFrame(y_test,columns=['label'])\n",
        "  y_test=pd.concat([ids, y_test['label']], axis=1)\n",
        "  return y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PgV77IYZRGP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test[y_test>0.5]=1\n",
        "y_test[y_test<0.5]=0\n",
        "y_test=y_test.astype('int16').ravel()\n",
        "\n",
        "y_test=pd.DataFrame(y_test,columns=['label'])\n",
        "y_test=pd.concat([ids, y_test['label']], axis=1)\n",
        "y_test.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8avMmBQvb_IR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dl57zICXM4c6",
        "colab_type": "text"
      },
      "source": [
        "# Submit file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LkCxvtfEnpl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHTCw4_jP_tr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test.to_csv('/content/disaster.csv',index=False,header=None)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tPo96DUz_EZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwKb7_NBWjAv",
        "colab_type": "text"
      },
      "source": [
        "# Reset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0Xi3s2KWlKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import keras\n",
        "# keras.backend.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T39YK5rbQBoT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}