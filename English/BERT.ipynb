{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNAMW4wq5iqEf0wWuGl7BHA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/talhaanwarch/OffenseEval2020/blob/master/English/BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfYIrsFDNSzj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "b102f026-268f-40c1-e072-e7fff56b7bea"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wz6ME5HqOJmX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "outputId": "97426ee4-c2fe-4bba-f5c8-4df17a5cd35d"
      },
      "source": [
        "!pip install tensorflow==2.1.0\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.1.0)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.4.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.17.5)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.12.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.9.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.11.2)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.2.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.27.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.0.8)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.34.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (2.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.1.8)\n",
            "Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (2.1.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.10.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.8.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1.0) (2.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.7.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.21.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (45.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.0.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.0.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkVwbeQbOAPe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential,Model\n",
        "from tensorflow.keras.layers import Embedding,Dense,Dropout,Flatten, Input\n",
        "from tensorflow.keras.optimizers import RMSprop,Adam,Adadelta"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Udk8qWz-K4cx",
        "colab_type": "text"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lx-1BQaY6rkq",
        "colab_type": "code",
        "outputId": "cbc12194-50fc-47c1-a4e0-f324c9d1efdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "train=pd.read_csv( '/content/drive/My Drive/dataset/OLID/data/olid-training-v1.0.tsv',sep=\"\\t\")\n",
        "train.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>subtask_a</th>\n",
              "      <th>subtask_b</th>\n",
              "      <th>subtask_c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>86426</td>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>90194</td>\n",
              "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>TIN</td>\n",
              "      <td>IND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16820</td>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>62688</td>\n",
              "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>43605</td>\n",
              "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                              tweet  ... subtask_b subtask_c\n",
              "0  86426  @USER She should ask a few native Americans wh...  ...       UNT       NaN\n",
              "1  90194  @USER @USER Go home you’re drunk!!! @USER #MAG...  ...       TIN       IND\n",
              "2  16820  Amazon is investigating Chinese employees who ...  ...       NaN       NaN\n",
              "3  62688  @USER Someone should'veTaken\" this piece of sh...  ...       UNT       NaN\n",
              "4  43605  @USER @USER Obama wanted liberals &amp; illega...  ...       NaN       NaN\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsyaJHD98Fdn",
        "colab_type": "code",
        "outputId": "3f98a490-50be-4910-e4dd-5a00074e20d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "val=pd.read_csv('/content/drive/My Drive/dataset/OLID/data/testset-levela.tsv',sep=\"\\t\")\n",
        "val_labels=pd.read_csv('/content/drive/My Drive/dataset/OLID/data/labels-levela.csv',sep=\",\",header=None)\n",
        "val_labels.columns=['idx','subtask_a']\n",
        "#val_labels.head()\n",
        "val=pd.concat([val,val_labels],axis=1)\n",
        "val.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>idx</th>\n",
              "      <th>subtask_a</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15923</td>\n",
              "      <td>#WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...</td>\n",
              "      <td>15923</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27014</td>\n",
              "      <td>#ConstitutionDay is revered by Conservatives, ...</td>\n",
              "      <td>27014</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>30530</td>\n",
              "      <td>#FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...</td>\n",
              "      <td>30530</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13876</td>\n",
              "      <td>#Watching #Boomer getting the news that she is...</td>\n",
              "      <td>13876</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60133</td>\n",
              "      <td>#NoPasaran: Unity demo to oppose the far-right...</td>\n",
              "      <td>60133</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                              tweet    idx subtask_a\n",
              "0  15923  #WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...  15923       OFF\n",
              "1  27014  #ConstitutionDay is revered by Conservatives, ...  27014       NOT\n",
              "2  30530  #FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...  30530       NOT\n",
              "3  13876  #Watching #Boomer getting the news that she is...  13876       NOT\n",
              "4  60133  #NoPasaran: Unity demo to oppose the far-right...  60133       OFF"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mv31K9V2h41l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels=train['subtask_a']\n",
        "train=train['tweet']\n",
        "\n",
        "\n",
        "val_labels=val['subtask_a']\n",
        "val=val['tweet']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIoM04y68Pwd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train=pd.concat([train,val])\n",
        "labels=pd.concat([train_labels,val_labels])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c58qlJvAih8C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpKtr-fN64Tw",
        "colab_type": "code",
        "outputId": "b1d32962-a85c-4f8c-b7bc-bb5507ccc08d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "test=pd.read_csv( '/content/drive/My Drive/dataset/OffenseEval2020/data/English/test_a_tweets.tsv',sep=\"\\t\")\n",
        "test.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A0</td>\n",
              "      <td>¿Who the fuck is Yoru?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A1</td>\n",
              "      <td>@USER @USER He's an evil law breaker that shou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A2</td>\n",
              "      <td>Now hiring for 49 #Labor job opportunities in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A3</td>\n",
              "      <td>#NerkondaPaarvai' - As Of Now, There Is NO Ear...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A4</td>\n",
              "      <td>@USER Hahahaha I wish...but a week is good, I’...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                              tweet\n",
              "0  A0                             ¿Who the fuck is Yoru?\n",
              "1  A1  @USER @USER He's an evil law breaker that shou...\n",
              "2  A2  Now hiring for 49 #Labor job opportunities in ...\n",
              "3  A3  #NerkondaPaarvai' - As Of Now, There Is NO Ear...\n",
              "4  A4  @USER Hahahaha I wish...but a week is good, I’..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YY8MVlxhggiD",
        "colab_type": "code",
        "outputId": "445fe557-b80e-4362-a945-23ffd5586846",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "\n",
        "train=train.str.replace('\\d+', '')\n",
        "train=train.str.replace('@USER', \"\") \n",
        "train=train.str.replace('URL', '')\n",
        "train= train.str.lower()\n",
        "#train = train.str.replace('[^\\w\\s]','')\n",
        "#train = train.apply(lambda x : [lemmatizer.lemmatize(y) for y in w_tokenizer.tokenize(x)])\n",
        "#train = train.apply(lambda x: [item for item in x if item not in stop])\n",
        "#train = train.apply(lambda x : \" \".join(x))\n",
        "train.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     she should ask a few native americans what th...\n",
              "1          go home you’re drunk!!!  #maga #trump 👊🇺🇸👊 \n",
              "2    amazon is investigating chinese employees who ...\n",
              "3     someone should'vetaken\" this piece of shit to...\n",
              "4      obama wanted liberals &amp; illegals to move...\n",
              "Name: tweet, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdwHh_q_LLus",
        "colab_type": "code",
        "outputId": "c4d2c71c-3246-41e6-f6e0-061618c8e0e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "\n",
        "test['tweet']=test['tweet'].str.replace('\\d+', '')\n",
        "test['tweet']=test['tweet'].str.replace('@USER', \"\") \n",
        "test['tweet']=test['tweet'].str.replace('URL', '')\n",
        "test[\"tweet\"]= test[\"tweet\"].str.lower()\n",
        "# test[\"tweet\"] = test[\"tweet\"].str.replace('[^\\w\\s]','')\n",
        "# test[\"tweet\"] = test[\"tweet\"].apply(lambda x : [lemmatizer.lemmatize(y) for y in w_tokenizer.tokenize(x)])\n",
        "# test[\"tweet\"] = test[\"tweet\"].apply(lambda x: [item for item in x if item not in stop])\n",
        "# test[\"tweet\"] = test[\"tweet\"].apply(lambda x : \" \".join(x))\n",
        "test.head()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A0</td>\n",
              "      <td>¿who the fuck is yoru?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A1</td>\n",
              "      <td>he's an evil law breaker that should be in p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A2</td>\n",
              "      <td>now hiring for  #labor job opportunities in #m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A3</td>\n",
              "      <td>#nerkondapaarvai' - as of now, there is no ear...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A4</td>\n",
              "      <td>hahahaha i wish...but a week is good, i’m ext...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                              tweet\n",
              "0  A0                             ¿who the fuck is yoru?\n",
              "1  A1    he's an evil law breaker that should be in p...\n",
              "2  A2  now hiring for  #labor job opportunities in #m...\n",
              "3  A3  #nerkondapaarvai' - as of now, there is no ear...\n",
              "4  A4   hahahaha i wish...but a week is good, i’m ext..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUFczyikLeYO",
        "colab_type": "text"
      },
      "source": [
        "#Label Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFPv0_zdLnlS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test=test['tweet']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCtBGu-B_kgZ",
        "colab_type": "code",
        "outputId": "748437bb-4280-4622-cfcd-cdaa49f1a1b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     she should ask a few native americans what th...\n",
              "1          go home you’re drunk!!!  #maga #trump 👊🇺🇸👊 \n",
              "2    amazon is investigating chinese employees who ...\n",
              "3     someone should'vetaken\" this piece of shit to...\n",
              "4      obama wanted liberals &amp; illegals to move...\n",
              "Name: tweet, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9PjbFwJLiNA",
        "colab_type": "code",
        "outputId": "09653f24-76b5-4b7f-a8f5-0dd760c20f9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "le=LabelEncoder()\n",
        "labels=le.fit_transform(labels)\n",
        "print(len(labels))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqsY34bMheqV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_bert=train.copy()\n",
        "test_bert=test.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbQNqrW_jsSM",
        "colab_type": "text"
      },
      "source": [
        "#BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDU6bS5SkJQg",
        "colab_type": "code",
        "outputId": "aa89cd14-1f53-4a0f-bfba-f76edbd278e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!pip install sentencepiece\n",
        "!pip install tensorflow-hub"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 2.8MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.85\n",
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub) (3.10.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub) (1.17.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow-hub) (45.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "414pY8LyjtH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bert_encode(texts, tokenizer, max_len=512):\n",
        "    all_tokens = []\n",
        "    all_masks = []\n",
        "    all_segments = []\n",
        "    \n",
        "    for text in texts:\n",
        "        text = tokenizer.tokenize(text)\n",
        "            \n",
        "        text = text[:max_len-2]\n",
        "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
        "        pad_len = max_len - len(input_sequence)\n",
        "        \n",
        "        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
        "        tokens += [0] * pad_len\n",
        "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
        "        segment_ids = [0] * max_len\n",
        "        \n",
        "        all_tokens.append(tokens)\n",
        "        all_masks.append(pad_masks)\n",
        "        all_segments.append(segment_ids)\n",
        "    \n",
        "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39_f3IqJkDqD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(bert_layer, max_len=512):\n",
        "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
        "    input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
        "    segment_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
        "\n",
        "    _, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
        "    clf_output = sequence_output[:, 0, :]\n",
        "    out = Dense(1, activation='sigmoid')(clf_output)\n",
        "    \n",
        "    model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n",
        "    model.compile(Adam(lr=2e-6), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rngHxIMDkEG_",
        "colab_type": "code",
        "outputId": "4fac2cee-4289-44d3-e9d9-3227ebfbfcca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "%%time\n",
        "import tensorflow_hub as hub\n",
        "module_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1\"\n",
        "bert_layer = hub.KerasLayer(module_url, trainable=True)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 9.34 s, sys: 1.64 s, total: 11 s\n",
            "Wall time: 10.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKFhfLdqkWE_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget --quiet https://raw.githubusercontent.com/google-research/ALBERT/master/tokenization.py\n",
        "import tokenization\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCc3VM7tHgIf",
        "colab_type": "code",
        "outputId": "3599a257-e7d1-42c1-cf6b-76e56184a2da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "len(train_bert),len(test_bert)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14100, 3887)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_nMcl-SH5U4",
        "colab_type": "code",
        "outputId": "569d6438-bab0-4d2d-e9f7-44a21c11f70a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "source": [
        "train_bert.values[0:5]"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([' she should ask a few native americans what their take on this is.',\n",
              "       '  go home you’re drunk!!!  #maga #trump 👊🇺🇸👊 ',\n",
              "       'amazon is investigating chinese employees who are selling internal data to third-party sellers looking for an edge in the competitive marketplace.  #amazon #maga #kag #china #tcot',\n",
              "       ' someone should\\'vetaken\" this piece of shit to a volcano. 😂\"',\n",
              "       '  obama wanted liberals &amp; illegals to move into red states'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xcodh2t8kkiU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_input = bert_encode(train_bert.values, tokenizer, max_len=160)\n",
        "test_input = bert_encode(test_bert.values, tokenizer, max_len=160)\n",
        "train_labels = labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35Z4PXVkHYQ5",
        "colab_type": "code",
        "outputId": "8313896f-ed4d-46c6-d17a-f887a9e42514",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "len(train_input),len(train_labels),len(test_input)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 14100, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlWK8CTBkl2T",
        "colab_type": "code",
        "outputId": "f93154ba-fae4-4c6c-c4b9-8c73c4581bc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        }
      },
      "source": [
        "bert_model = build_model(bert_layer, max_len=160)\n",
        "bert_model.summary()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_word_ids (InputLayer)     [(None, 160)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_mask (InputLayer)         [(None, 160)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "segment_ids (InputLayer)        [(None, 160)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer_2 (KerasLayer)      [(None, 1024), (None 335141889   input_word_ids[0][0]             \n",
            "                                                                 input_mask[0][0]                 \n",
            "                                                                 segment_ids[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice (Tens [(None, 1024)]       0           keras_layer_2[0][1]              \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1)            1025        tf_op_layer_strided_slice[0][0]  \n",
            "==================================================================================================\n",
            "Total params: 335,142,914\n",
            "Trainable params: 335,142,913\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t96g6FnrJ_cC",
        "colab_type": "code",
        "outputId": "28531c50-ba5a-4e7b-b7b0-883b6e30ad48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "train_history = bert_model.fit(\n",
        "    train_input, train_labels,\n",
        "    validation_split=0.2,\n",
        "    epochs=5,\n",
        "    batch_size=16)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 11280 samples, validate on 2820 samples\n",
            "Epoch 1/5\n",
            "11280/11280 [==============================] - 1265s 112ms/sample - loss: 0.5188 - accuracy: 0.7416 - val_loss: 0.4271 - val_accuracy: 0.8043\n",
            "Epoch 2/5\n",
            " 5120/11280 [============>.................] - ETA: 10:20 - loss: 0.4046 - accuracy: 0.8182"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGuNGsBOPtWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ES0pdE_f8XQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ztl36NpScAT7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}