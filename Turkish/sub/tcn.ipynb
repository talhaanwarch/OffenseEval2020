{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "biGRU.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/talhaanwarch/OffenseEval2020/blob/master/Turkish/sub/tcn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_tja7FDUpcC",
        "colab_type": "text"
      },
      "source": [
        "# Turkish Language"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8yyBcABHgE8",
        "colab_type": "code",
        "outputId": "dde43503-6205-4251-b45a-d3b7bffd9f52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzpBLLtl6MXy",
        "colab_type": "code",
        "outputId": "433a4da4-0ec9-4871-f791-f3f44d213d77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "!pip install focal-loss"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting focal-loss\n",
            "  Downloading https://files.pythonhosted.org/packages/66/ed/17450291228192ad8595de4514c8ec28a587697b03c707d12d4af5b7f331/focal_loss-0.0.2-py3-none-any.whl\n",
            "Installing collected packages: focal-loss\n",
            "Successfully installed focal-loss-0.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0Yzi-0oHqTD",
        "colab_type": "code",
        "outputId": "b7914ecd-717a-41b8-e562-3fe6d3052024",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/My Drive/dataset/OffenseEval2020/data/Turkish/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/dataset/OffenseEval2020/data/Turkish\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fN7zvpdTOdo",
        "colab_type": "code",
        "outputId": "c5332315-ab27-45b3-a610-5ae721919e6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cc.tr.300.vec     offenseval-annotation.txt     offenseval-tr-training-v1.tsv\n",
            "cc.tr.300.vec.gz  offenseval-tr-testset-v1.tsv  readme-trainingset-tr.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04n7RsXqIBlz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le=LabelEncoder()\n",
        "train=pd.read_csv( 'offenseval-tr-training-v1.tsv',sep='\\t',quoting=csv.QUOTE_NONE,encoding='utf-8')\n",
        "train=train.sample(frac=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqmIsFmsIFPY",
        "colab_type": "code",
        "outputId": "64b9168e-47f4-4ec9-bf95-6c8ae2b2548a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>subtask_a</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13744</th>\n",
              "      <td>40119</td>\n",
              "      <td>@USER Ne o totoş sağda solda yakalarlar benimd...</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24906</th>\n",
              "      <td>43432</td>\n",
              "      <td>@USER LetGo'ya koyup satalım bari napalım isra...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15037</th>\n",
              "      <td>23541</td>\n",
              "      <td>Saat 5 buçuk olmuş siyasi yazıyosunuz ya</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28476</th>\n",
              "      <td>37573</td>\n",
              "      <td>Allaha şükür karakterimiz bozuk tipimiz değil</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27440</th>\n",
              "      <td>14411</td>\n",
              "      <td>@USER ben haziran diye gördüm yarın mı cidden ?</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id                                              tweet subtask_a\n",
              "13744  40119  @USER Ne o totoş sağda solda yakalarlar benimd...       OFF\n",
              "24906  43432  @USER LetGo'ya koyup satalım bari napalım isra...       NOT\n",
              "15037  23541           Saat 5 buçuk olmuş siyasi yazıyosunuz ya       NOT\n",
              "28476  37573      Allaha şükür karakterimiz bozuk tipimiz değil       OFF\n",
              "27440  14411    @USER ben haziran diye gördüm yarın mı cidden ?       NOT"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4tNYHWFesiA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train[\"tweet\"]= train[\"tweet\"].str.replace('@USER', \"\") \n",
        "train['tweet']=train['tweet'].str.replace('\\d+', '')\n",
        "train['tweet']=train['tweet'].str.replace('URL', '')\n",
        "train[\"tweet\"]= train[\"tweet\"].str.lower()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvxTEpwde46o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels=train['subtask_a']\n",
        "train=train['tweet']\n",
        "labels=le.fit_transform(train_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ptkGujpIwMH",
        "colab_type": "code",
        "outputId": "d116c50c-3b4f-4f12-e30c-d60d6393a779",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "train.tail()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7444      yıllık tecrübesiyle ahirete sizi artık rahat ...\n",
              "9123       yemin ederim bu sene bejwke kadar kollansayd...\n",
              "15270          din büyükler için uydurulmuş bir masaldır !\n",
              "18123      valla bir arkadaşım aradı italyadan tam ital...\n",
              "8154            yarışalım baba haydi takip edin arkadaşlar\n",
              "Name: tweet, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qLSfSq9fb1Z",
        "colab_type": "code",
        "outputId": "7626cb6c-be30-4b3e-c610-d1b9c95aec5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "labels[0:5]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVmlJvlfIP9k",
        "colab_type": "code",
        "outputId": "62f4f117-adb6-46c0-f140-8b970bc049e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import collections\n",
        "collections.Counter(labels)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 25625, 1: 6131})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRZItSB-IogR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "max_words = 10000 #frequency of words to be kept\n",
        "max_len = 200\n",
        "\n",
        "tokenize = Tokenizer(num_words=max_words)\n",
        "tokenize.fit_on_texts(train)\n",
        "sequences = tokenize.texts_to_sequences(train)\n",
        "word_index = tokenize.word_index\n",
        "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsBKuk1UOu4W",
        "colab_type": "code",
        "outputId": "0dbe4339-34d0-40d5-b537-18ab3961cd27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(sequences_matrix),len(labels)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31756, 31756)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_CbYz9jJ1Bc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Embedding,CuDNNGRU,Input,Dense,Dropout,Bidirectional,GlobalMaxPooling1D,GlobalAveragePooling1D, concatenate, Concatenate\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.initializers import Constant\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import classification_report,f1_score\n",
        "import keras\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from focal_loss import BinaryFocalLoss\n",
        "import tensorflow as tf\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUpgHo7nCE3C",
        "colab_type": "code",
        "outputId": "1b101821-82b7-44bb-af03-5b3edb38f3c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "num_words = min(max_words, len(word_index)) + 1\n",
        "print(num_words)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WSdBiOv-qbS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.tr.300.vec.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JmlK-tG-r43",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import gzip\n",
        "# import shutil\n",
        "# with gzip.open('cc.tr.300.vec.gz', 'rb') as f_in:\n",
        "#     with open('cc.tr.300.vec', 'wb') as f_out:\n",
        "#         shutil.copyfileobj(f_in, f_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hohu_6rE-Z6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed_size=300\n",
        "def get_coefs(word,*arr):\n",
        "    return word, np.asarray(arr, dtype='float32')\n",
        "\n",
        "def build_matrix(embedding_path, word_index):\n",
        "    embedding_index = dict(get_coefs(*o.strip().split(\" \")) for o in open(embedding_path))\n",
        "\n",
        "    nb_words = min(max_words, len(word_index))\n",
        "    embedding_matrix = np.zeros((nb_words + 1, embed_size))\n",
        "    for word, i in word_index.items():\n",
        "        if i >= max_words:\n",
        "            continue\n",
        "        embedding_vector = embedding_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "    return embedding_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faZVMLbw-cN-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings=build_matrix('cc.tr.300.vec', word_index)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "et7AvsISBjZP",
        "colab_type": "code",
        "outputId": "e79dab00-0f65-46d9-de0b-4b2b7bd899ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embeddings.shape"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10001, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPExMeUk6Zrx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "opt=Adam(0.0001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ja2KXaGZNg6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# from https://github.com/philipperemy/keras-tcn\n",
        "\n",
        "\n",
        "import keras.backend as K\n",
        "import keras.layers\n",
        "from keras import optimizers\n",
        "from keras.engine.topology import Layer\n",
        "from keras.layers import Activation, Lambda\n",
        "from keras.layers import Conv1D, SpatialDropout1D\n",
        "from keras.layers import Convolution1D, Dense\n",
        "from keras.models import Input, Model\n",
        "from typing import List, Tuple\n",
        "\n",
        "\n",
        "def channel_normalization(x):\n",
        "    # type: (Layer) -> Layer\n",
        "    \"\"\" Normalize a layer to the maximum activation\n",
        "    This keeps a layers values between zero and one.\n",
        "    It helps with relu's unbounded activation\n",
        "    Args:\n",
        "        x: The layer to normalize\n",
        "    Returns:\n",
        "        A maximal normalized layer\n",
        "    \"\"\"\n",
        "    max_values = K.max(K.abs(x), 2, keepdims=True) + 1e-5\n",
        "    out = x / max_values\n",
        "    return out\n",
        "\n",
        "\n",
        "def wave_net_activation(x):\n",
        "    # type: (Layer) -> Layer\n",
        "    \"\"\"This method defines the activation used for WaveNet\n",
        "    described in https://deepmind.com/blog/wavenet-generative-model-raw-audio/\n",
        "    Args:\n",
        "        x: The layer we want to apply the activation to\n",
        "    Returns:\n",
        "        A new layer with the wavenet activation applied\n",
        "    \"\"\"\n",
        "    tanh_out = Activation('tanh')(x)\n",
        "    sigm_out = Activation('sigmoid')(x)\n",
        "    return keras.layers.multiply([tanh_out, sigm_out])\n",
        "\n",
        "\n",
        "def residual_block(x, s, i, activation, nb_filters, kernel_size, padding, dropout_rate=0, name=''):\n",
        "    # type: (Layer, int, int, str, int, int, float, str) -> Tuple[Layer, Layer]\n",
        "    \"\"\"Defines the residual block for the WaveNet TCN\n",
        "    Args:\n",
        "        x: The previous layer in the model\n",
        "        s: The stack index i.e. which stack in the overall TCN\n",
        "        i: The dilation power of 2 we are using for this residual block\n",
        "        activation: The name of the type of activation to use\n",
        "        nb_filters: The number of convolutional filters to use in this block\n",
        "        kernel_size: The size of the convolutional kernel\n",
        "        padding: The padding used in the convolutional layers, 'same' or 'causal'.\n",
        "        dropout_rate: Float between 0 and 1. Fraction of the input units to drop.\n",
        "        name: Name of the model. Useful when having multiple TCN.\n",
        "    Returns:\n",
        "        A tuple where the first element is the residual model layer, and the second\n",
        "        is the skip connection.\n",
        "    \"\"\"\n",
        "\n",
        "    original_x = x\n",
        "    conv = Conv1D(filters=nb_filters, kernel_size=kernel_size,\n",
        "                  dilation_rate=i, padding=padding,\n",
        "                  name=name + '_dilated_conv_%d_tanh_s%d' % (i, s))(x)\n",
        "    if activation == 'norm_relu':\n",
        "        x = Activation('relu')(conv)\n",
        "        x = Lambda(channel_normalization)(x)\n",
        "    elif activation == 'wavenet':\n",
        "        x = wave_net_activation(conv)\n",
        "    else:\n",
        "        x = Activation(activation)(conv)\n",
        "\n",
        "    x = SpatialDropout1D(dropout_rate, name=name + '_spatial_dropout1d_%d_s%d_%f' % (i, s, dropout_rate))(x)\n",
        "\n",
        "    # 1x1 conv.\n",
        "    x = Convolution1D(nb_filters, 1, padding='same')(x)\n",
        "    res_x = keras.layers.add([original_x, x])\n",
        "    return res_x, x\n",
        "\n",
        "\n",
        "def process_dilations(dilations):\n",
        "    def is_power_of_two(num):\n",
        "        return num != 0 and ((num & (num - 1)) == 0)\n",
        "\n",
        "    if all([is_power_of_two(i) for i in dilations]):\n",
        "        return dilations\n",
        "\n",
        "    else:\n",
        "        new_dilations = [2 ** i for i in dilations]\n",
        "        # print(f'Updated dilations from {dilations} to {new_dilations} because of backwards compatibility.')\n",
        "        return new_dilations\n",
        "\n",
        "\n",
        "class TCN:\n",
        "    \"\"\"Creates a TCN layer.\n",
        "        Args:\n",
        "            input_layer: A tensor of shape (batch_size, timesteps, input_dim).\n",
        "            nb_filters: The number of filters to use in the convolutional layers.\n",
        "            kernel_size: The size of the kernel to use in each convolutional layer.\n",
        "            dilations: The list of the dilations. Example is: [1, 2, 4, 8, 16, 32, 64].\n",
        "            nb_stacks : The number of stacks of residual blocks to use.\n",
        "            activation: The activations to use (norm_relu, wavenet, relu...).\n",
        "            padding: The padding to use in the convolutional layers, 'causal' or 'same'.\n",
        "            use_skip_connections: Boolean. If we want to add skip connections from input to each residual block.\n",
        "            return_sequences: Boolean. Whether to return the last output in the output sequence, or the full sequence.\n",
        "            dropout_rate: Float between 0 and 1. Fraction of the input units to drop.\n",
        "            name: Name of the model. Useful when having multiple TCN.\n",
        "        Returns:\n",
        "            A TCN layer.\n",
        "        \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 nb_filters=64,\n",
        "                 kernel_size=2,\n",
        "                 nb_stacks=1,\n",
        "                 dilations=None,\n",
        "                 activation='norm_relu',\n",
        "                 padding='causal',\n",
        "                 use_skip_connections=True,\n",
        "                 dropout_rate=0.0,\n",
        "                 return_sequences=True,\n",
        "                 name='tcn'):\n",
        "        self.name = name\n",
        "        self.return_sequences = return_sequences\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.use_skip_connections = use_skip_connections\n",
        "        self.activation = activation\n",
        "        self.dilations = dilations\n",
        "        self.nb_stacks = nb_stacks\n",
        "        self.kernel_size = kernel_size\n",
        "        self.nb_filters = nb_filters\n",
        "        self.padding = padding\n",
        "\n",
        "        # backwards incompatibility warning.\n",
        "        # o = tcn.TCN(i, return_sequences=False) =>\n",
        "        # o = tcn.TCN(return_sequences=False)(i)\n",
        "\n",
        "        if padding != 'causal' and padding != 'same':\n",
        "            raise ValueError(\"Only 'causal' or 'same' paddings are compatible for this layer.\")\n",
        "\n",
        "        if not isinstance(nb_filters, int):\n",
        "            print('An interface change occurred after the version 2.1.2.')\n",
        "            print('Before: tcn.TCN(i, return_sequences=False, ...)')\n",
        "            print('Now should be: tcn.TCN(return_sequences=False, ...)(i)')\n",
        "            print('Second solution is to pip install keras-tcn==2.1.2 to downgrade.')\n",
        "            raise Exception()\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        if self.dilations is None:\n",
        "            self.dilations = [1, 2, 4, 8, 16, 32]\n",
        "        x = inputs\n",
        "        x = Convolution1D(self.nb_filters, 1, padding=self.padding, name=self.name + '_initial_conv')(x)\n",
        "        skip_connections = []\n",
        "        for s in range(self.nb_stacks):\n",
        "            for i in self.dilations:\n",
        "                x, skip_out = residual_block(x, s, i, self.activation, self.nb_filters,\n",
        "                                             self.kernel_size, self.padding, self.dropout_rate, name=self.name)\n",
        "                skip_connections.append(skip_out)\n",
        "        if self.use_skip_connections:\n",
        "            x = keras.layers.add(skip_connections)\n",
        "        x = Activation('relu')(x)\n",
        "\n",
        "        if not self.return_sequences:\n",
        "            output_slice_index = -1\n",
        "            x = Lambda(lambda tt: tt[:, output_slice_index, :])(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTLZ31tIJ4Js",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_tcn(embedding_matrix):\n",
        "    \n",
        "    inp = Input(shape=(max_len,))\n",
        "    x = Embedding(num_words,embed_size,embeddings_initializer=Constant(embeddings),input_length=max_len,trainable=False)(inp)\n",
        "    x = SpatialDropout1D(0.1)(x)\n",
        "    x = TCN(128,dilations = [1, 2, 4], return_sequences=True, activation = 'wavenet',name = 'tnc1')(x)\n",
        "    x = TCN(64,dilations = [1, 2, 4], return_sequences=True, activation = 'wavenet',name = 'tnc2')(x)\n",
        "\n",
        "    #x = TCN(32,dilations = [1, 2, 4], return_sequences=True, activation = 'wavenet',name = 'tnc3')(x)\n",
        "    avg_pool = GlobalAveragePooling1D()(x)\n",
        "    max_pool = GlobalMaxPool1D()(x)\n",
        "    \n",
        "    conc = concatenate([avg_pool, max_pool])\n",
        "    conc = Dense(64, activation=\"relu\")(conc)\n",
        "    conc = Dense(32, activation=\"relu\")(conc)\n",
        "\n",
        "    conc = Dropout(0.1)(conc)\n",
        "    outp = Dense(1, activation=\"sigmoid\")(conc)    \n",
        "    opt=Adam(0.0001)\n",
        "    model = Model(inputs=inp, outputs=outp)\n",
        "    model.compile(loss=BinaryFocalLoss(gamma=3), optimizer=opt, metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9qM_Y38hWEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "class_weights = class_weight.compute_class_weight('balanced',np.unique(labels),labels)\n",
        "class_weights=dict(enumerate(class_weights))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHE3OFWz3DTk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ReduceLROnPlateau\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
        "                              patience=2, min_lr=0.000001, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-6ga8jGg5Pj",
        "colab_type": "code",
        "outputId": "99b3ae01-b6ad-4027-b812-1c153280204e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_val,y_train,y_val=train_test_split(sequences_matrix,labels,test_size=0.15,stratify=labels,shuffle=True)\n",
        "model=model_tcn(embeddings)\n",
        "model.fit(x_train,y_train,batch_size=64,epochs=10,verbose=2,class_weight=class_weights,validation_data=(x_val,y_val))"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 26992 samples, validate on 4764 samples\n",
            "Epoch 1/10\n",
            " - 9s - loss: 0.0616 - acc: 0.8157 - val_loss: 0.0515 - val_acc: 0.8453\n",
            "Epoch 2/10\n",
            " - 6s - loss: 0.0528 - acc: 0.8475 - val_loss: 0.0502 - val_acc: 0.8587\n",
            "Epoch 3/10\n",
            " - 6s - loss: 0.0507 - acc: 0.8531 - val_loss: 0.0487 - val_acc: 0.8585\n",
            "Epoch 4/10\n",
            " - 6s - loss: 0.0496 - acc: 0.8561 - val_loss: 0.0484 - val_acc: 0.8589\n",
            "Epoch 5/10\n",
            " - 6s - loss: 0.0485 - acc: 0.8608 - val_loss: 0.0482 - val_acc: 0.8615\n",
            "Epoch 6/10\n",
            " - 6s - loss: 0.0474 - acc: 0.8632 - val_loss: 0.0498 - val_acc: 0.8520\n",
            "Epoch 7/10\n",
            " - 6s - loss: 0.0462 - acc: 0.8667 - val_loss: 0.0488 - val_acc: 0.8625\n",
            "Epoch 8/10\n",
            " - 6s - loss: 0.0454 - acc: 0.8693 - val_loss: 0.0489 - val_acc: 0.8518\n",
            "Epoch 9/10\n",
            " - 6s - loss: 0.0445 - acc: 0.8734 - val_loss: 0.0484 - val_acc: 0.8571\n",
            "Epoch 10/10\n",
            " - 6s - loss: 0.0426 - acc: 0.8780 - val_loss: 0.0494 - val_acc: 0.8585\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f889fd01b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwZrmmcPMfKm",
        "colab_type": "code",
        "outputId": "adc12794-8b37-409a-ae1d-af4dc4c37fb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred = model.predict(x_val, batch_size=64, verbose=1)\n",
        "y_pred_bool = np.argmax(y_pred, axis=1)\n",
        "y_pred = (y_pred > 0.50)\n",
        "\n",
        "print(classification_report(y_val, y_pred))"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4764/4764 [==============================] - 0s 82us/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.95      0.92      3844\n",
            "           1       0.70      0.47      0.56       920\n",
            "\n",
            "    accuracy                           0.86      4764\n",
            "   macro avg       0.79      0.71      0.74      4764\n",
            "weighted avg       0.85      0.86      0.85      4764\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sepj7fJ_REvZ",
        "colab_type": "code",
        "outputId": "e07ba18b-f3a2-4a72-d653-3cf2dff0a2b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "test=pd.read_csv( 'offenseval-tr-testset-v1.tsv',sep='\\t',quoting=csv.QUOTE_NONE,encoding='utf-8')\n",
        "test[\"tweet\"]= test[\"tweet\"].str.replace('@USER', \"\") \n",
        "test['tweet']=test['tweet'].str.replace('\\d+', '')\n",
        "test['tweet']=test['tweet'].str.replace('URL', '')\n",
        "test['tweet']=test['tweet'].str.lower()\n",
        "\n",
        "test.head()"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>41993</td>\n",
              "      <td>sayın başkanım bu şekilde devam inşallah👏</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>23000</td>\n",
              "      <td>herkes gevşekliği kadar duyar kasıyor,hayat bö...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>42478</td>\n",
              "      <td>olgun ilişkisi olan arkadaş size en güzel hedi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>21748</td>\n",
              "      <td>burada atıp tutacağına o kötü koşullarda  ku...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13607</td>\n",
              "      <td>i̇şte o onur dediğin sende yok sorun o işte</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                              tweet\n",
              "0  41993          sayın başkanım bu şekilde devam inşallah👏\n",
              "1  23000  herkes gevşekliği kadar duyar kasıyor,hayat bö...\n",
              "2  42478  olgun ilişkisi olan arkadaş size en güzel hedi...\n",
              "3  21748    burada atıp tutacağına o kötü koşullarda  ku...\n",
              "4  13607        i̇şte o onur dediğin sende yok sorun o işte"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hcb3NVrmlHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test=test['tweet']\n",
        "\n",
        "test_sequences = tokenize.texts_to_sequences(X_test)\n",
        "X_test_sequences = sequence.pad_sequences(test_sequences,maxlen=max_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PS1oidhTmsQA",
        "colab_type": "code",
        "outputId": "5f5229d0-474c-4c57-8d27-2761b912c240",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_test = model.predict(X_test_sequences, batch_size=64, verbose=1)\n"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3528/3528 [==============================] - 0s 79us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3x5FIIbtCkd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save('/content/tcn.npy',y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oYvlcGomuxr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test[y_test>0.45]=1\n",
        "y_test[y_test<0.45]=0\n",
        "y_test=y_test.astype('int16').ravel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "corZDy57m3ZX",
        "colab_type": "code",
        "outputId": "881d1de7-a8e7-4bd7-b2db-dfb0e40ee44d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "y_test=le.inverse_transform(y_test)\n",
        "y_test=pd.DataFrame(y_test,columns=['label'])\n",
        "y_test=pd.concat([test['id'], y_test['label']], axis=1)\n",
        "y_test.head()\n"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>41993</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>23000</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>42478</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>21748</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13607</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id label\n",
              "0  41993   NOT\n",
              "1  23000   NOT\n",
              "2  42478   NOT\n",
              "3  21748   NOT\n",
              "4  13607   NOT"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tigzlRV4m_ih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test.to_csv('/content/sub1.csv',index=False,header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOV6cK9fnA11",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "keras.backend.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSN1g93ITI4u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HS7ImOIDVJmV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}