{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "biGRU.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/talhaanwarch/OffenseEval2020/blob/master/Turkish/FastText_biGRU_crossval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_tja7FDUpcC",
        "colab_type": "text"
      },
      "source": [
        "# Turkish Language"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8yyBcABHgE8",
        "colab_type": "code",
        "outputId": "005a98cd-0ad6-444a-e376-c9d28be841ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzpBLLtl6MXy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "14fffbe8-fec8-4b9e-8c6f-57deff1e7aee"
      },
      "source": [
        "!pip install focal-loss"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting focal-loss\n",
            "  Downloading https://files.pythonhosted.org/packages/66/ed/17450291228192ad8595de4514c8ec28a587697b03c707d12d4af5b7f331/focal_loss-0.0.2-py3-none-any.whl\n",
            "Installing collected packages: focal-loss\n",
            "Successfully installed focal-loss-0.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0Yzi-0oHqTD",
        "colab_type": "code",
        "outputId": "0f419bc3-2046-4d94-895c-8544fe2e7edb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/My Drive/dataset/OffenseEval2020/data/Turkish/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/dataset/OffenseEval2020/data/Turkish\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fN7zvpdTOdo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "579289f9-2d88-4de3-caca-4b0cbcc65e82"
      },
      "source": [
        "ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cc.tr.300.vec     offenseval-annotation.txt      readme-trainingset-tr.txt\n",
            "cc.tr.300.vec.gz  offenseval-tr-training-v1.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04n7RsXqIBlz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "train=pd.read_csv( 'offenseval-tr-training-v1.tsv',sep=\"\\t\")\n",
        "train=train.sample(frac=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqmIsFmsIFPY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "655ac3dd-beaa-49df-ecb6-04ab47fb8604"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>subtask_a</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>29507</th>\n",
              "      <td>38775</td>\n",
              "      <td>Bi gün yemek yapmıştım babam beğenmedi ve yeme...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8612</th>\n",
              "      <td>43317</td>\n",
              "      <td>Poğaçacı abi hesabı ödedikden sonra; İyi bir h...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8195</th>\n",
              "      <td>26839</td>\n",
              "      <td>#TaksicilerAçıklamaBekliyor Uberi yasaklayın y...</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9580</th>\n",
              "      <td>24562</td>\n",
              "      <td>“ Bir çiçek bahçesinde geceye durgun kalışın, ...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3788</th>\n",
              "      <td>45773</td>\n",
              "      <td>Bugün Senin İçin Bir Şey Yapmıyorsam,    Dün S...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id                                              tweet subtask_a\n",
              "29507  38775  Bi gün yemek yapmıştım babam beğenmedi ve yeme...       NOT\n",
              "8612   43317  Poğaçacı abi hesabı ödedikden sonra; İyi bir h...       NOT\n",
              "8195   26839  #TaksicilerAçıklamaBekliyor Uberi yasaklayın y...       OFF\n",
              "9580   24562  “ Bir çiçek bahçesinde geceye durgun kalışın, ...       NOT\n",
              "3788   45773  Bugün Senin İçin Bir Şey Yapmıyorsam,    Dün S...       NOT"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ptkGujpIwMH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "3803a112-927e-4327-eb6d-9a9610c16310"
      },
      "source": [
        "train.tail()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>subtask_a</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>27194</th>\n",
              "      <td>37520</td>\n",
              "      <td>@USER ~ilk hissettiklerim:bir jichu gördüm san...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22221</th>\n",
              "      <td>39051</td>\n",
              "      <td>güzel olan her şey şeytani</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1014</th>\n",
              "      <td>45084</td>\n",
              "      <td>@USER Canım benim görende 4 te 4 yaptınız sanı...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21307</th>\n",
              "      <td>39583</td>\n",
              "      <td>@USER Hayatı zorlaştıran böyle şeyler galiba</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>611</th>\n",
              "      <td>18778</td>\n",
              "      <td>Ayrıca Atatürk siyaset üstüdür. Hiçbir siyasiy...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id                                              tweet subtask_a\n",
              "27194  37520  @USER ~ilk hissettiklerim:bir jichu gördüm san...       NOT\n",
              "22221  39051                         güzel olan her şey şeytani       NOT\n",
              "1014   45084  @USER Canım benim görende 4 te 4 yaptınız sanı...       NOT\n",
              "21307  39583       @USER Hayatı zorlaştıran böyle şeyler galiba       NOT\n",
              "611    18778  Ayrıca Atatürk siyaset üstüdür. Hiçbir siyasiy...       NOT"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TYe8X52IGha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels=train['subtask_a']\n",
        "train=train['tweet']\n",
        "labels=pd.factorize(labels)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVmlJvlfIP9k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e883cf55-19b4-48fb-8e7d-f921657384be"
      },
      "source": [
        "import collections\n",
        "collections.Counter(labels)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 25231, 1: 6046})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRZItSB-IogR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "outputId": "4de3bd03-5d8a-4c6a-9f4a-92cdba2f7f28"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "max_words = 10000 #frequency of words to be kept\n",
        "max_len = 200\n",
        "\n",
        "tokenize = Tokenizer(num_words=max_words)\n",
        "tokenize.fit_on_texts(train)\n",
        "sequences = tokenize.texts_to_sequences(train)\n",
        "word_index = tokenize.word_index\n",
        "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsBKuk1UOu4W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0f56dcff-23d1-4038-b72f-05a46367343c"
      },
      "source": [
        "len(sequences_matrix),len(labels)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31277, 31277)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_CbYz9jJ1Bc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding,CuDNNGRU,GRU,Dense,Dropout,Bidirectional,GlobalMaxPool1D,GlobalAveragePooling1D, SpatialDropout1D\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.initializers import Constant\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import classification_report,f1_score\n",
        "import keras\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from focal_loss import BinaryFocalLoss\n",
        "import tensorflow as tf\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUpgHo7nCE3C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "24ef55de-4723-4b51-ebdd-588e900d59af"
      },
      "source": [
        "num_words = min(max_words, len(word_index)) + 1\n",
        "print(num_words)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WSdBiOv-qbS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.tr.300.vec.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JmlK-tG-r43",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import gzip\n",
        "# import shutil\n",
        "# with gzip.open('cc.tr.300.vec.gz', 'rb') as f_in:\n",
        "#     with open('cc.tr.300.vec', 'wb') as f_out:\n",
        "#         shutil.copyfileobj(f_in, f_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hohu_6rE-Z6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed_size=300\n",
        "def get_coefs(word,*arr):\n",
        "    return word, np.asarray(arr, dtype='float32')\n",
        "\n",
        "def build_matrix(embedding_path, word_index):\n",
        "    embedding_index = dict(get_coefs(*o.strip().split(\" \")) for o in open(embedding_path))\n",
        "\n",
        "    nb_words = min(max_words, len(word_index))\n",
        "    embedding_matrix = np.zeros((nb_words + 1, embed_size))\n",
        "    for word, i in word_index.items():\n",
        "        if i >= max_words:\n",
        "            continue\n",
        "        embedding_vector = embedding_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "    return embedding_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faZVMLbw-cN-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings=build_matrix('cc.tr.300.vec', word_index)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "et7AvsISBjZP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b9613744-18c7-45c4-b01e-5121504f304b"
      },
      "source": [
        "embeddings.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10001, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPExMeUk6Zrx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTLZ31tIJ4Js",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_func():\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(num_words,embed_size,embeddings_initializer=Constant(embeddings),input_length=max_len,trainable=False))\n",
        "  model.add(Bidirectional(CuDNNGRU(50, return_sequences = True)))\n",
        "  #model.add(Bidirectional(CuDNNGRU(32, return_sequences = True)))\n",
        "  model.add(GlobalMaxPool1D())\n",
        "  model.add(Dense(50, activation=\"relu\"))\n",
        "  model.add(Dense(20, activation=\"relu\"))\n",
        "  model.add(Dense(10, activation=\"relu\"))\n",
        "\n",
        "  model.add(Dropout(0.05))\n",
        "  model.add(Dense(1, activation=\"sigmoid\"))\n",
        "  model.compile(loss=BinaryFocalLoss(gamma=2), optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9qM_Y38hWEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "class_weights = class_weight.compute_class_weight('balanced',np.unique(labels),labels)\n",
        "class_weights=dict(enumerate(class_weights))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHE3OFWz3DTk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ReduceLROnPlateau\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
        "                              patience=2, min_lr=0.000001, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-6ga8jGg5Pj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c9ef7d2b-523c-4dfc-cc18-5faff1fa8105"
      },
      "source": [
        "kfold = StratifiedKFold(n_splits=10, shuffle=False, random_state=2020)\n",
        "cvscores = []\n",
        "\n",
        "for train, test in kfold.split(sequences_matrix, labels):\n",
        "  model=model_func()\n",
        "  \n",
        "  model.fit(sequences_matrix[train], labels[train],batch_size=256,epochs=10,verbose=2,class_weight=class_weights,\n",
        "            validation_data=(sequences_matrix[test],labels[test]),callbacks=[reduce_lr])\n",
        "  y_pred = model.predict(sequences_matrix[test], batch_size=128, verbose=1)\n",
        "  y_pred_bool = np.argmax(y_pred, axis=1)\n",
        "  y_pred = (y_pred > 0.5)\n",
        "  f1=f1_score(labels[test], y_pred, average='macro')\n",
        "  cvscores.append(f1)\n",
        "  keras.backend.clear_session()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 28149 samples, validate on 3128 samples\n",
            "Epoch 1/10\n",
            " - 4s - loss: 0.1242 - acc: 0.8108 - val_loss: 0.1007 - val_acc: 0.8465\n",
            "Epoch 2/10\n",
            " - 4s - loss: 0.1007 - acc: 0.8468 - val_loss: 0.0949 - val_acc: 0.8597\n",
            "Epoch 3/10\n",
            " - 4s - loss: 0.0951 - acc: 0.8580 - val_loss: 0.0935 - val_acc: 0.8616\n",
            "Epoch 4/10\n",
            " - 4s - loss: 0.0923 - acc: 0.8624 - val_loss: 0.0906 - val_acc: 0.8696\n",
            "Epoch 5/10\n",
            " - 4s - loss: 0.0890 - acc: 0.8671 - val_loss: 0.0894 - val_acc: 0.8680\n",
            "Epoch 6/10\n",
            " - 4s - loss: 0.0866 - acc: 0.8710 - val_loss: 0.0891 - val_acc: 0.8667\n",
            "Epoch 7/10\n",
            " - 4s - loss: 0.0825 - acc: 0.8782 - val_loss: 0.0899 - val_acc: 0.8645\n",
            "Epoch 8/10\n",
            " - 4s - loss: 0.0800 - acc: 0.8791 - val_loss: 0.0933 - val_acc: 0.8638\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 9/10\n",
            " - 4s - loss: 0.0707 - acc: 0.8969 - val_loss: 0.0915 - val_acc: 0.8657\n",
            "Epoch 10/10\n",
            " - 4s - loss: 0.0681 - acc: 0.9006 - val_loss: 0.0930 - val_acc: 0.8648\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "3128/3128 [==============================] - 0s 113us/step\n",
            "Train on 28149 samples, validate on 3128 samples\n",
            "Epoch 1/10\n",
            " - 4s - loss: 0.1266 - acc: 0.7954 - val_loss: 0.1027 - val_acc: 0.8363\n",
            "Epoch 2/10\n",
            " - 4s - loss: 0.0996 - acc: 0.8462 - val_loss: 0.0975 - val_acc: 0.8520\n",
            "Epoch 3/10\n",
            " - 4s - loss: 0.0951 - acc: 0.8570 - val_loss: 0.0943 - val_acc: 0.8581\n",
            "Epoch 4/10\n",
            " - 4s - loss: 0.0912 - acc: 0.8633 - val_loss: 0.0935 - val_acc: 0.8590\n",
            "Epoch 5/10\n",
            " - 4s - loss: 0.0883 - acc: 0.8680 - val_loss: 0.0923 - val_acc: 0.8606\n",
            "Epoch 6/10\n",
            " - 4s - loss: 0.0845 - acc: 0.8743 - val_loss: 0.0927 - val_acc: 0.8590\n",
            "Epoch 7/10\n",
            " - 4s - loss: 0.0805 - acc: 0.8804 - val_loss: 0.0953 - val_acc: 0.8571\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 8/10\n",
            " - 4s - loss: 0.0727 - acc: 0.8948 - val_loss: 0.0967 - val_acc: 0.8552\n",
            "Epoch 9/10\n",
            " - 4s - loss: 0.0702 - acc: 0.8993 - val_loss: 0.0987 - val_acc: 0.8555\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 10/10\n",
            " - 4s - loss: 0.0671 - acc: 0.9048 - val_loss: 0.0993 - val_acc: 0.8555\n",
            "3128/3128 [==============================] - 0s 105us/step\n",
            "Train on 28149 samples, validate on 3128 samples\n",
            "Epoch 1/10\n",
            " - 4s - loss: 0.1213 - acc: 0.8116 - val_loss: 0.0995 - val_acc: 0.8475\n",
            "Epoch 2/10\n",
            " - 4s - loss: 0.0988 - acc: 0.8483 - val_loss: 0.0939 - val_acc: 0.8616\n",
            "Epoch 3/10\n",
            " - 4s - loss: 0.0939 - acc: 0.8570 - val_loss: 0.0918 - val_acc: 0.8625\n",
            "Epoch 4/10\n",
            " - 4s - loss: 0.0910 - acc: 0.8639 - val_loss: 0.0908 - val_acc: 0.8651\n",
            "Epoch 5/10\n",
            " - 4s - loss: 0.0877 - acc: 0.8680 - val_loss: 0.0923 - val_acc: 0.8597\n",
            "Epoch 6/10\n",
            " - 4s - loss: 0.0846 - acc: 0.8724 - val_loss: 0.0910 - val_acc: 0.8657\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 7/10\n",
            " - 4s - loss: 0.0784 - acc: 0.8831 - val_loss: 0.0921 - val_acc: 0.8587\n",
            "Epoch 8/10\n",
            " - 4s - loss: 0.0759 - acc: 0.8867 - val_loss: 0.0932 - val_acc: 0.8629\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 9/10\n",
            " - 4s - loss: 0.0738 - acc: 0.8907 - val_loss: 0.0932 - val_acc: 0.8603\n",
            "Epoch 10/10\n",
            " - 4s - loss: 0.0727 - acc: 0.8923 - val_loss: 0.0934 - val_acc: 0.8590\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "3128/3128 [==============================] - 0s 102us/step\n",
            "Train on 28149 samples, validate on 3128 samples\n",
            "Epoch 1/10\n",
            " - 4s - loss: 0.1253 - acc: 0.7985 - val_loss: 0.1014 - val_acc: 0.8418\n",
            "Epoch 2/10\n",
            " - 4s - loss: 0.0994 - acc: 0.8474 - val_loss: 0.0961 - val_acc: 0.8539\n",
            "Epoch 3/10\n",
            " - 4s - loss: 0.0947 - acc: 0.8579 - val_loss: 0.0956 - val_acc: 0.8574\n",
            "Epoch 4/10\n",
            " - 4s - loss: 0.0909 - acc: 0.8648 - val_loss: 0.0939 - val_acc: 0.8574\n",
            "Epoch 5/10\n",
            " - 4s - loss: 0.0872 - acc: 0.8695 - val_loss: 0.0935 - val_acc: 0.8571\n",
            "Epoch 6/10\n",
            " - 4s - loss: 0.0834 - acc: 0.8758 - val_loss: 0.0942 - val_acc: 0.8593\n",
            "Epoch 7/10\n",
            " - 4s - loss: 0.0790 - acc: 0.8819 - val_loss: 0.0982 - val_acc: 0.8587\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 8/10\n",
            " - 4s - loss: 0.0703 - acc: 0.8972 - val_loss: 0.0987 - val_acc: 0.8513\n",
            "Epoch 9/10\n",
            " - 4s - loss: 0.0674 - acc: 0.9020 - val_loss: 0.1005 - val_acc: 0.8494\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 10/10\n",
            " - 4s - loss: 0.0643 - acc: 0.9071 - val_loss: 0.1017 - val_acc: 0.8529\n",
            "3128/3128 [==============================] - 0s 102us/step\n",
            "Train on 28149 samples, validate on 3128 samples\n",
            "Epoch 1/10\n",
            " - 4s - loss: 0.1245 - acc: 0.8059 - val_loss: 0.1055 - val_acc: 0.8373\n",
            "Epoch 2/10\n",
            " - 4s - loss: 0.1016 - acc: 0.8435 - val_loss: 0.1025 - val_acc: 0.8424\n",
            "Epoch 3/10\n",
            " - 4s - loss: 0.0954 - acc: 0.8547 - val_loss: 0.0948 - val_acc: 0.8558\n",
            "Epoch 4/10\n",
            " - 4s - loss: 0.0916 - acc: 0.8617 - val_loss: 0.0943 - val_acc: 0.8584\n",
            "Epoch 5/10\n",
            " - 4s - loss: 0.0889 - acc: 0.8642 - val_loss: 0.0938 - val_acc: 0.8549\n",
            "Epoch 6/10\n",
            " - 4s - loss: 0.0860 - acc: 0.8690 - val_loss: 0.0949 - val_acc: 0.8577\n",
            "Epoch 7/10\n",
            " - 4s - loss: 0.0824 - acc: 0.8747 - val_loss: 0.0954 - val_acc: 0.8565\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 8/10\n",
            " - 4s - loss: 0.0763 - acc: 0.8818 - val_loss: 0.0963 - val_acc: 0.8561\n",
            "Epoch 9/10\n",
            " - 4s - loss: 0.0744 - acc: 0.8855 - val_loss: 0.0969 - val_acc: 0.8504\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 10/10\n",
            " - 4s - loss: 0.0723 - acc: 0.8880 - val_loss: 0.0976 - val_acc: 0.8552\n",
            "3128/3128 [==============================] - 0s 105us/step\n",
            "Train on 28149 samples, validate on 3128 samples\n",
            "Epoch 1/10\n",
            " - 4s - loss: 0.1206 - acc: 0.8147 - val_loss: 0.1040 - val_acc: 0.8312\n",
            "Epoch 2/10\n",
            " - 4s - loss: 0.0997 - acc: 0.8507 - val_loss: 0.0993 - val_acc: 0.8437\n",
            "Epoch 3/10\n",
            " - 4s - loss: 0.0941 - acc: 0.8604 - val_loss: 0.0991 - val_acc: 0.8469\n",
            "Epoch 4/10\n",
            " - 4s - loss: 0.0905 - acc: 0.8639 - val_loss: 0.0951 - val_acc: 0.8504\n",
            "Epoch 5/10\n",
            " - 4s - loss: 0.0863 - acc: 0.8708 - val_loss: 0.0965 - val_acc: 0.8517\n",
            "Epoch 6/10\n",
            " - 4s - loss: 0.0835 - acc: 0.8754 - val_loss: 0.0945 - val_acc: 0.8469\n",
            "Epoch 7/10\n",
            " - 4s - loss: 0.0781 - acc: 0.8842 - val_loss: 0.0976 - val_acc: 0.8504\n",
            "Epoch 8/10\n",
            " - 4s - loss: 0.0718 - acc: 0.8948 - val_loss: 0.1030 - val_acc: 0.8465\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 9/10\n",
            " - 4s - loss: 0.0615 - acc: 0.9123 - val_loss: 0.1046 - val_acc: 0.8434\n",
            "Epoch 10/10\n",
            " - 4s - loss: 0.0574 - acc: 0.9201 - val_loss: 0.1078 - val_acc: 0.8379\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "3128/3128 [==============================] - 0s 102us/step\n",
            "Train on 28149 samples, validate on 3128 samples\n",
            "Epoch 1/10\n",
            " - 4s - loss: 0.1218 - acc: 0.8066 - val_loss: 0.1060 - val_acc: 0.8242\n",
            "Epoch 2/10\n",
            " - 4s - loss: 0.1002 - acc: 0.8461 - val_loss: 0.0975 - val_acc: 0.8533\n",
            "Epoch 3/10\n",
            " - 4s - loss: 0.0940 - acc: 0.8581 - val_loss: 0.0953 - val_acc: 0.8571\n",
            "Epoch 4/10\n",
            " - 4s - loss: 0.0903 - acc: 0.8637 - val_loss: 0.0950 - val_acc: 0.8565\n",
            "Epoch 5/10\n",
            " - 4s - loss: 0.0869 - acc: 0.8675 - val_loss: 0.0963 - val_acc: 0.8568\n",
            "Epoch 6/10\n",
            " - 4s - loss: 0.0837 - acc: 0.8735 - val_loss: 0.0967 - val_acc: 0.8577\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 7/10\n",
            " - 4s - loss: 0.0778 - acc: 0.8817 - val_loss: 0.0969 - val_acc: 0.8549\n",
            "Epoch 8/10\n",
            " - 4s - loss: 0.0755 - acc: 0.8853 - val_loss: 0.0985 - val_acc: 0.8558\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 9/10\n",
            " - 4s - loss: 0.0731 - acc: 0.8896 - val_loss: 0.0990 - val_acc: 0.8526\n",
            "Epoch 10/10\n",
            " - 4s - loss: 0.0727 - acc: 0.8908 - val_loss: 0.0995 - val_acc: 0.8517\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "3128/3128 [==============================] - 0s 105us/step\n",
            "Train on 28150 samples, validate on 3127 samples\n",
            "Epoch 1/10\n",
            " - 4s - loss: 0.1217 - acc: 0.8119 - val_loss: 0.1014 - val_acc: 0.8452\n",
            "Epoch 2/10\n",
            " - 4s - loss: 0.1003 - acc: 0.8453 - val_loss: 0.0974 - val_acc: 0.8561\n",
            "Epoch 3/10\n",
            " - 4s - loss: 0.0945 - acc: 0.8568 - val_loss: 0.0947 - val_acc: 0.8628\n",
            "Epoch 4/10\n",
            " - 4s - loss: 0.0913 - acc: 0.8633 - val_loss: 0.0921 - val_acc: 0.8650\n",
            "Epoch 5/10\n",
            " - 4s - loss: 0.0890 - acc: 0.8657 - val_loss: 0.0978 - val_acc: 0.8634\n",
            "Epoch 6/10\n",
            " - 4s - loss: 0.0846 - acc: 0.8715 - val_loss: 0.0946 - val_acc: 0.8650\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 7/10\n",
            " - 4s - loss: 0.0785 - acc: 0.8826 - val_loss: 0.0934 - val_acc: 0.8670\n",
            "Epoch 8/10\n",
            " - 4s - loss: 0.0763 - acc: 0.8858 - val_loss: 0.0936 - val_acc: 0.8686\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 9/10\n",
            " - 4s - loss: 0.0741 - acc: 0.8898 - val_loss: 0.0942 - val_acc: 0.8670\n",
            "Epoch 10/10\n",
            " - 4s - loss: 0.0737 - acc: 0.8896 - val_loss: 0.0944 - val_acc: 0.8666\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "3127/3127 [==============================] - 0s 103us/step\n",
            "Train on 28150 samples, validate on 3127 samples\n",
            "Epoch 1/10\n",
            " - 4s - loss: 0.1247 - acc: 0.8093 - val_loss: 0.1069 - val_acc: 0.8283\n",
            "Epoch 2/10\n",
            " - 4s - loss: 0.0995 - acc: 0.8482 - val_loss: 0.1013 - val_acc: 0.8459\n",
            "Epoch 3/10\n",
            " - 4s - loss: 0.0938 - acc: 0.8606 - val_loss: 0.0995 - val_acc: 0.8491\n",
            "Epoch 4/10\n",
            " - 4s - loss: 0.0896 - acc: 0.8669 - val_loss: 0.1001 - val_acc: 0.8500\n",
            "Epoch 5/10\n",
            " - 4s - loss: 0.0865 - acc: 0.8716 - val_loss: 0.0993 - val_acc: 0.8491\n",
            "Epoch 6/10\n",
            " - 4s - loss: 0.0828 - acc: 0.8779 - val_loss: 0.1027 - val_acc: 0.8494\n",
            "Epoch 7/10\n",
            " - 4s - loss: 0.0791 - acc: 0.8813 - val_loss: 0.1038 - val_acc: 0.8475\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 8/10\n",
            " - 4s - loss: 0.0714 - acc: 0.8977 - val_loss: 0.1066 - val_acc: 0.8471\n",
            "Epoch 9/10\n",
            " - 4s - loss: 0.0683 - acc: 0.9007 - val_loss: 0.1087 - val_acc: 0.8468\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 10/10\n",
            " - 4s - loss: 0.0657 - acc: 0.9056 - val_loss: 0.1097 - val_acc: 0.8417\n",
            "3127/3127 [==============================] - 0s 105us/step\n",
            "Train on 28150 samples, validate on 3127 samples\n",
            "Epoch 1/10\n",
            " - 4s - loss: 0.1200 - acc: 0.8169 - val_loss: 0.1044 - val_acc: 0.8375\n",
            "Epoch 2/10\n",
            " - 4s - loss: 0.0996 - acc: 0.8478 - val_loss: 0.1031 - val_acc: 0.8427\n",
            "Epoch 3/10\n",
            " - 4s - loss: 0.0948 - acc: 0.8574 - val_loss: 0.0983 - val_acc: 0.8526\n",
            "Epoch 4/10\n",
            " - 4s - loss: 0.0909 - acc: 0.8640 - val_loss: 0.0961 - val_acc: 0.8571\n",
            "Epoch 5/10\n",
            " - 4s - loss: 0.0864 - acc: 0.8696 - val_loss: 0.0959 - val_acc: 0.8561\n",
            "Epoch 6/10\n",
            " - 4s - loss: 0.0839 - acc: 0.8745 - val_loss: 0.0981 - val_acc: 0.8500\n",
            "Epoch 7/10\n",
            " - 4s - loss: 0.0796 - acc: 0.8811 - val_loss: 0.0992 - val_acc: 0.8561\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 8/10\n",
            " - 4s - loss: 0.0697 - acc: 0.8966 - val_loss: 0.1011 - val_acc: 0.8602\n",
            "Epoch 9/10\n",
            " - 4s - loss: 0.0667 - acc: 0.9035 - val_loss: 0.1033 - val_acc: 0.8571\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 10/10\n",
            " - 4s - loss: 0.0633 - acc: 0.9085 - val_loss: 0.1041 - val_acc: 0.8510\n",
            "3127/3127 [==============================] - 0s 101us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKgIrCHXJ_Gc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "de8b84ca-d076-466b-e410-aecda8057061"
      },
      "source": [
        "np.array(cvscores).mean()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7360764729687974"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwZrmmcPMfKm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sepj7fJ_REvZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}