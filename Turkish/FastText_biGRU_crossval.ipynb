{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "biGRU.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/talhaanwarch/OffenseEval2020/blob/master/Turkish/FastText_biGRU_crossval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_tja7FDUpcC",
        "colab_type": "text"
      },
      "source": [
        "# Turkish Language"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8yyBcABHgE8",
        "colab_type": "code",
        "outputId": "005a98cd-0ad6-444a-e376-c9d28be841ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0Yzi-0oHqTD",
        "colab_type": "code",
        "outputId": "0f419bc3-2046-4d94-895c-8544fe2e7edb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/My Drive/dataset/OffenseEval2020/data/Turkish/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/dataset/OffenseEval2020/data/Turkish\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fN7zvpdTOdo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "579289f9-2d88-4de3-caca-4b0cbcc65e82"
      },
      "source": [
        "ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cc.tr.300.vec     offenseval-annotation.txt      readme-trainingset-tr.txt\n",
            "cc.tr.300.vec.gz  offenseval-tr-training-v1.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04n7RsXqIBlz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "train=pd.read_csv( 'offenseval-tr-training-v1.tsv',sep=\"\\t\")\n",
        "train=train.sample(frac=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqmIsFmsIFPY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "655ac3dd-beaa-49df-ecb6-04ab47fb8604"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>subtask_a</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>29507</th>\n",
              "      <td>38775</td>\n",
              "      <td>Bi gün yemek yapmıştım babam beğenmedi ve yeme...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8612</th>\n",
              "      <td>43317</td>\n",
              "      <td>Poğaçacı abi hesabı ödedikden sonra; İyi bir h...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8195</th>\n",
              "      <td>26839</td>\n",
              "      <td>#TaksicilerAçıklamaBekliyor Uberi yasaklayın y...</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9580</th>\n",
              "      <td>24562</td>\n",
              "      <td>“ Bir çiçek bahçesinde geceye durgun kalışın, ...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3788</th>\n",
              "      <td>45773</td>\n",
              "      <td>Bugün Senin İçin Bir Şey Yapmıyorsam,    Dün S...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id                                              tweet subtask_a\n",
              "29507  38775  Bi gün yemek yapmıştım babam beğenmedi ve yeme...       NOT\n",
              "8612   43317  Poğaçacı abi hesabı ödedikden sonra; İyi bir h...       NOT\n",
              "8195   26839  #TaksicilerAçıklamaBekliyor Uberi yasaklayın y...       OFF\n",
              "9580   24562  “ Bir çiçek bahçesinde geceye durgun kalışın, ...       NOT\n",
              "3788   45773  Bugün Senin İçin Bir Şey Yapmıyorsam,    Dün S...       NOT"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ptkGujpIwMH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "3803a112-927e-4327-eb6d-9a9610c16310"
      },
      "source": [
        "train.tail()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>subtask_a</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>27194</th>\n",
              "      <td>37520</td>\n",
              "      <td>@USER ~ilk hissettiklerim:bir jichu gördüm san...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22221</th>\n",
              "      <td>39051</td>\n",
              "      <td>güzel olan her şey şeytani</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1014</th>\n",
              "      <td>45084</td>\n",
              "      <td>@USER Canım benim görende 4 te 4 yaptınız sanı...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21307</th>\n",
              "      <td>39583</td>\n",
              "      <td>@USER Hayatı zorlaştıran böyle şeyler galiba</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>611</th>\n",
              "      <td>18778</td>\n",
              "      <td>Ayrıca Atatürk siyaset üstüdür. Hiçbir siyasiy...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id                                              tweet subtask_a\n",
              "27194  37520  @USER ~ilk hissettiklerim:bir jichu gördüm san...       NOT\n",
              "22221  39051                         güzel olan her şey şeytani       NOT\n",
              "1014   45084  @USER Canım benim görende 4 te 4 yaptınız sanı...       NOT\n",
              "21307  39583       @USER Hayatı zorlaştıran böyle şeyler galiba       NOT\n",
              "611    18778  Ayrıca Atatürk siyaset üstüdür. Hiçbir siyasiy...       NOT"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TYe8X52IGha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels=train['subtask_a']\n",
        "train=train['tweet']\n",
        "labels=pd.factorize(labels)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVmlJvlfIP9k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e883cf55-19b4-48fb-8e7d-f921657384be"
      },
      "source": [
        "import collections\n",
        "collections.Counter(labels)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 25231, 1: 6046})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRZItSB-IogR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "outputId": "4de3bd03-5d8a-4c6a-9f4a-92cdba2f7f28"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "max_words = 10000 #frequency of words to be kept\n",
        "max_len = 200\n",
        "\n",
        "tokenize = Tokenizer(num_words=max_words)\n",
        "tokenize.fit_on_texts(train)\n",
        "sequences = tokenize.texts_to_sequences(train)\n",
        "word_index = tokenize.word_index\n",
        "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsBKuk1UOu4W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0f56dcff-23d1-4038-b72f-05a46367343c"
      },
      "source": [
        "len(sequences_matrix),len(labels)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31277, 31277)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_CbYz9jJ1Bc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding,CuDNNGRU,GRU,Dense,Dropout,Bidirectional,GlobalMaxPool1D,GlobalAveragePooling1D, SpatialDropout1D\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.initializers import Constant\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import classification_report,f1_score\n",
        "import keras\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import tensorflow as tf\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQC6dlJWLv3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "def f1(y_true, y_pred):\n",
        "    '''\n",
        "    metric from here \n",
        "    https://stackoverflow.com/questions/43547402/how-to-calculate-f1-macro-in-keras\n",
        "    '''\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "\n",
        "        Only computes a batch-wise average of precision.\n",
        "\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUpgHo7nCE3C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "24ef55de-4723-4b51-ebdd-588e900d59af"
      },
      "source": [
        "num_words = min(max_words, len(word_index)) + 1\n",
        "print(num_words)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WSdBiOv-qbS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.tr.300.vec.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JmlK-tG-r43",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import gzip\n",
        "# import shutil\n",
        "# with gzip.open('cc.tr.300.vec.gz', 'rb') as f_in:\n",
        "#     with open('cc.tr.300.vec', 'wb') as f_out:\n",
        "#         shutil.copyfileobj(f_in, f_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hohu_6rE-Z6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed_size=300\n",
        "def get_coefs(word,*arr):\n",
        "    return word, np.asarray(arr, dtype='float32')\n",
        "\n",
        "def build_matrix(embedding_path, word_index):\n",
        "    embedding_index = dict(get_coefs(*o.strip().split(\" \")) for o in open(embedding_path))\n",
        "\n",
        "    nb_words = min(max_words, len(word_index))\n",
        "    embedding_matrix = np.zeros((nb_words + 1, embed_size))\n",
        "    for word, i in word_index.items():\n",
        "        if i >= max_words:\n",
        "            continue\n",
        "        embedding_vector = embedding_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "    return embedding_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faZVMLbw-cN-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings=build_matrix('cc.tr.300.vec', word_index)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "et7AvsISBjZP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b9613744-18c7-45c4-b01e-5121504f304b"
      },
      "source": [
        "embeddings.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10001, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTLZ31tIJ4Js",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_func():\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(num_words,embed_size,embeddings_initializer=Constant(embeddings),input_length=max_len,trainable=False))\n",
        "  model.add(Bidirectional(CuDNNGRU(150, return_sequences = True)))\n",
        "  #model.add(Bidirectional(CuDNNGRU(32, return_sequences = True)))\n",
        "  model.add(GlobalMaxPool1D())\n",
        "  model.add(Dense(50, activation=\"relu\"))\n",
        "  model.add(Dense(20, activation=\"relu\"))\n",
        "\n",
        "  model.add(Dropout(0.05))\n",
        "  model.add(Dense(1, activation=\"sigmoid\"))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9qM_Y38hWEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "class_weights = class_weight.compute_class_weight('balanced',np.unique(labels),labels)\n",
        "class_weights=dict(enumerate(class_weights))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHE3OFWz3DTk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ReduceLROnPlateau\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
        "                              patience=2, min_lr=0.000001, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-6ga8jGg5Pj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "951f92da-dade-4133-f6d7-1b71fda194b9"
      },
      "source": [
        "kfold = StratifiedKFold(n_splits=10, shuffle=False, random_state=2020)\n",
        "cvscores = []\n",
        "\n",
        "for train, test in kfold.split(sequences_matrix, labels):\n",
        "  model=model_func()\n",
        "  \n",
        "  model.fit(sequences_matrix[train], labels[train],batch_size=256,epochs=10,verbose=2,class_weight=class_weights,\n",
        "            validation_data=(sequences_matrix[test],labels[test]),callbacks=[reduce_lr])\n",
        "  y_pred = model.predict(sequences_matrix[test], batch_size=128, verbose=1)\n",
        "  y_pred_bool = np.argmax(y_pred, axis=1)\n",
        "  y_pred = (y_pred > 0.5)\n",
        "  f1=f1_score(labels[test], y_pred, average='macro')\n",
        "  cvscores.append(f1)\n",
        "  keras.backend.clear_session()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 28149 samples, validate on 3128 samples\n",
            "Epoch 1/10\n",
            " - 9s - loss: 0.5814 - acc: 0.7121 - val_loss: 0.4865 - val_acc: 0.7935\n",
            "Epoch 2/10\n",
            " - 8s - loss: 0.5142 - acc: 0.7704 - val_loss: 0.5343 - val_acc: 0.7375\n",
            "Epoch 3/10\n",
            " - 8s - loss: 0.4901 - acc: 0.7835 - val_loss: 0.4682 - val_acc: 0.7948\n",
            "Epoch 4/10\n",
            " - 8s - loss: 0.4666 - acc: 0.7954 - val_loss: 0.4333 - val_acc: 0.8127\n",
            "Epoch 5/10\n",
            " - 8s - loss: 0.4325 - acc: 0.8131 - val_loss: 0.3642 - val_acc: 0.8469\n",
            "Epoch 6/10\n",
            " - 8s - loss: 0.3998 - acc: 0.8264 - val_loss: 0.4560 - val_acc: 0.7826\n",
            "Epoch 7/10\n",
            " - 8s - loss: 0.3376 - acc: 0.8574 - val_loss: 0.4876 - val_acc: 0.7711\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 8/10\n",
            " - 8s - loss: 0.2499 - acc: 0.9044 - val_loss: 0.4449 - val_acc: 0.8091\n",
            "Epoch 9/10\n",
            " - 8s - loss: 0.2162 - acc: 0.9192 - val_loss: 0.4281 - val_acc: 0.8258\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 10/10\n",
            " - 8s - loss: 0.1904 - acc: 0.9332 - val_loss: 0.4312 - val_acc: 0.8274\n",
            "3128/3128 [==============================] - 0s 159us/step\n",
            "Train on 28149 samples, validate on 3128 samples\n",
            "Epoch 1/10\n",
            " - 9s - loss: 0.5807 - acc: 0.6868 - val_loss: 0.5577 - val_acc: 0.7481\n",
            "Epoch 2/10\n",
            " - 8s - loss: 0.5169 - acc: 0.7720 - val_loss: 0.4428 - val_acc: 0.8207\n",
            "Epoch 3/10\n",
            " - 8s - loss: 0.4941 - acc: 0.7827 - val_loss: 0.4809 - val_acc: 0.7829\n",
            "Epoch 4/10\n",
            " - 8s - loss: 0.4711 - acc: 0.7918 - val_loss: 0.5406 - val_acc: 0.7414\n",
            "\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 5/10\n",
            " - 8s - loss: 0.4375 - acc: 0.8137 - val_loss: 0.4457 - val_acc: 0.8066\n",
            "Epoch 6/10\n",
            " - 8s - loss: 0.4217 - acc: 0.8237 - val_loss: 0.4242 - val_acc: 0.8175\n",
            "Epoch 7/10\n",
            " - 8s - loss: 0.4114 - acc: 0.8267 - val_loss: 0.4638 - val_acc: 0.7973\n",
            "Epoch 8/10\n",
            " - 8s - loss: 0.4003 - acc: 0.8331 - val_loss: 0.4683 - val_acc: 0.7906\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 9/10\n",
            " - 8s - loss: 0.3843 - acc: 0.8428 - val_loss: 0.4596 - val_acc: 0.7983\n",
            "Epoch 10/10\n",
            " - 8s - loss: 0.3808 - acc: 0.8452 - val_loss: 0.4546 - val_acc: 0.8027\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "3128/3128 [==============================] - 0s 146us/step\n",
            "Train on 28149 samples, validate on 3128 samples\n",
            "Epoch 1/10\n",
            " - 9s - loss: 0.5954 - acc: 0.6683 - val_loss: 0.5128 - val_acc: 0.7775\n",
            "Epoch 2/10\n",
            " - 8s - loss: 0.5169 - acc: 0.7709 - val_loss: 0.4729 - val_acc: 0.7935\n",
            "Epoch 3/10\n",
            " - 8s - loss: 0.4943 - acc: 0.7822 - val_loss: 0.4525 - val_acc: 0.8043\n",
            "Epoch 4/10\n",
            " - 8s - loss: 0.4718 - acc: 0.7975 - val_loss: 0.4412 - val_acc: 0.8104\n",
            "Epoch 5/10\n",
            " - 8s - loss: 0.4530 - acc: 0.8008 - val_loss: 0.3968 - val_acc: 0.8344\n",
            "Epoch 6/10\n",
            " - 8s - loss: 0.4175 - acc: 0.8219 - val_loss: 0.4250 - val_acc: 0.8120\n",
            "Epoch 7/10\n",
            " - 8s - loss: 0.3778 - acc: 0.8415 - val_loss: 0.3941 - val_acc: 0.8357\n",
            "Epoch 8/10\n",
            " - 8s - loss: 0.3316 - acc: 0.8627 - val_loss: 0.4341 - val_acc: 0.8165\n",
            "Epoch 9/10\n",
            " - 8s - loss: 0.2820 - acc: 0.8858 - val_loss: 0.5167 - val_acc: 0.7804\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 10/10\n",
            " - 8s - loss: 0.2023 - acc: 0.9278 - val_loss: 0.4403 - val_acc: 0.8264\n",
            "3128/3128 [==============================] - 0s 146us/step\n",
            "Train on 28149 samples, validate on 3128 samples\n",
            "Epoch 1/10\n",
            " - 9s - loss: 0.5778 - acc: 0.7277 - val_loss: 0.4771 - val_acc: 0.8015\n",
            "Epoch 2/10\n",
            " - 8s - loss: 0.5147 - acc: 0.7762 - val_loss: 0.4758 - val_acc: 0.7919\n",
            "Epoch 3/10\n",
            " - 8s - loss: 0.4918 - acc: 0.7881 - val_loss: 0.5434 - val_acc: 0.7436\n",
            "Epoch 4/10\n",
            " - 8s - loss: 0.4672 - acc: 0.7983 - val_loss: 0.4204 - val_acc: 0.8139\n",
            "Epoch 5/10\n",
            " - 8s - loss: 0.4503 - acc: 0.8084 - val_loss: 0.5116 - val_acc: 0.7625\n",
            "Epoch 6/10\n",
            " - 8s - loss: 0.4085 - acc: 0.8275 - val_loss: 0.5184 - val_acc: 0.7452\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 7/10\n",
            " - 8s - loss: 0.3452 - acc: 0.8632 - val_loss: 0.4427 - val_acc: 0.8034\n",
            "Epoch 8/10\n",
            " - 8s - loss: 0.3204 - acc: 0.8735 - val_loss: 0.4453 - val_acc: 0.7999\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 9/10\n",
            " - 8s - loss: 0.2978 - acc: 0.8871 - val_loss: 0.4434 - val_acc: 0.8056\n",
            "Epoch 10/10\n",
            " - 8s - loss: 0.2913 - acc: 0.8892 - val_loss: 0.4568 - val_acc: 0.8008\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "3128/3128 [==============================] - 0s 147us/step\n",
            "Train on 28149 samples, validate on 3128 samples\n",
            "Epoch 1/10\n",
            " - 9s - loss: 0.5840 - acc: 0.6969 - val_loss: 0.5762 - val_acc: 0.7337\n",
            "Epoch 2/10\n",
            " - 8s - loss: 0.5158 - acc: 0.7765 - val_loss: 0.5811 - val_acc: 0.7228\n",
            "Epoch 3/10\n",
            " - 8s - loss: 0.4891 - acc: 0.7876 - val_loss: 0.5243 - val_acc: 0.7542\n",
            "Epoch 4/10\n",
            " - 8s - loss: 0.4639 - acc: 0.7980 - val_loss: 0.4225 - val_acc: 0.8155\n",
            "Epoch 5/10\n",
            " - 8s - loss: 0.4394 - acc: 0.8103 - val_loss: 0.4174 - val_acc: 0.8219\n",
            "Epoch 6/10\n",
            " - 8s - loss: 0.4053 - acc: 0.8296 - val_loss: 0.4306 - val_acc: 0.8120\n",
            "Epoch 7/10\n",
            " - 8s - loss: 0.3629 - acc: 0.8461 - val_loss: 0.4956 - val_acc: 0.7788\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 8/10\n",
            " - 8s - loss: 0.2828 - acc: 0.8933 - val_loss: 0.4630 - val_acc: 0.7996\n",
            "Epoch 9/10\n",
            " - 8s - loss: 0.2542 - acc: 0.9073 - val_loss: 0.4696 - val_acc: 0.8005\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 10/10\n",
            " - 8s - loss: 0.2312 - acc: 0.9174 - val_loss: 0.4557 - val_acc: 0.8101\n",
            "3128/3128 [==============================] - 0s 147us/step\n",
            "Train on 28149 samples, validate on 3128 samples\n",
            "Epoch 1/10\n",
            " - 9s - loss: 0.5923 - acc: 0.6543 - val_loss: 0.5301 - val_acc: 0.7711\n",
            "Epoch 2/10\n",
            " - 8s - loss: 0.5155 - acc: 0.7803 - val_loss: 0.4704 - val_acc: 0.8043\n",
            "Epoch 3/10\n",
            " - 8s - loss: 0.4906 - acc: 0.7894 - val_loss: 0.4971 - val_acc: 0.7785\n",
            "Epoch 4/10\n",
            " - 8s - loss: 0.4716 - acc: 0.7991 - val_loss: 0.4668 - val_acc: 0.7976\n",
            "Epoch 5/10\n",
            " - 8s - loss: 0.4394 - acc: 0.8134 - val_loss: 0.4188 - val_acc: 0.8149\n",
            "Epoch 6/10\n",
            " - 8s - loss: 0.4101 - acc: 0.8271 - val_loss: 0.4113 - val_acc: 0.8238\n",
            "Epoch 7/10\n",
            " - 8s - loss: 0.3696 - acc: 0.8456 - val_loss: 0.4414 - val_acc: 0.8015\n",
            "Epoch 8/10\n",
            " - 8s - loss: 0.3212 - acc: 0.8677 - val_loss: 0.4940 - val_acc: 0.7861\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 9/10\n",
            " - 8s - loss: 0.2366 - acc: 0.9149 - val_loss: 0.4702 - val_acc: 0.8075\n",
            "Epoch 10/10\n",
            " - 8s - loss: 0.2078 - acc: 0.9289 - val_loss: 0.5042 - val_acc: 0.7935\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "3128/3128 [==============================] - 0s 148us/step\n",
            "Train on 28149 samples, validate on 3128 samples\n",
            "Epoch 1/10\n",
            " - 9s - loss: 0.5824 - acc: 0.7031 - val_loss: 0.5507 - val_acc: 0.7503\n",
            "Epoch 2/10\n",
            " - 8s - loss: 0.5143 - acc: 0.7721 - val_loss: 0.5688 - val_acc: 0.7267\n",
            "Epoch 3/10\n",
            " - 8s - loss: 0.4867 - acc: 0.7852 - val_loss: 0.4178 - val_acc: 0.8296\n",
            "Epoch 4/10\n",
            " - 8s - loss: 0.4653 - acc: 0.7946 - val_loss: 0.4520 - val_acc: 0.7989\n",
            "Epoch 5/10\n",
            " - 8s - loss: 0.4295 - acc: 0.8175 - val_loss: 0.6059 - val_acc: 0.6845\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 6/10\n",
            " - 8s - loss: 0.3801 - acc: 0.8422 - val_loss: 0.4561 - val_acc: 0.7935\n",
            "Epoch 7/10\n",
            " - 8s - loss: 0.3556 - acc: 0.8565 - val_loss: 0.5104 - val_acc: 0.7567\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 8/10\n",
            " - 8s - loss: 0.3351 - acc: 0.8678 - val_loss: 0.4482 - val_acc: 0.7999\n",
            "Epoch 9/10\n",
            " - 8s - loss: 0.3300 - acc: 0.8708 - val_loss: 0.4412 - val_acc: 0.8047\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "Epoch 10/10\n",
            " - 8s - loss: 0.3256 - acc: 0.8735 - val_loss: 0.4524 - val_acc: 0.7980\n",
            "3128/3128 [==============================] - 0s 154us/step\n",
            "Train on 28150 samples, validate on 3127 samples\n",
            "Epoch 1/10\n",
            " - 9s - loss: 0.5870 - acc: 0.6748 - val_loss: 0.5223 - val_acc: 0.7777\n",
            "Epoch 2/10\n",
            " - 8s - loss: 0.5190 - acc: 0.7718 - val_loss: 0.4222 - val_acc: 0.8324\n",
            "Epoch 3/10\n",
            " - 8s - loss: 0.4973 - acc: 0.7829 - val_loss: 0.4469 - val_acc: 0.8091\n",
            "Epoch 4/10\n",
            " - 8s - loss: 0.4688 - acc: 0.7938 - val_loss: 0.5340 - val_acc: 0.7320\n",
            "\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 5/10\n",
            " - 8s - loss: 0.4354 - acc: 0.8150 - val_loss: 0.4507 - val_acc: 0.8027\n",
            "Epoch 6/10\n",
            " - 8s - loss: 0.4229 - acc: 0.8223 - val_loss: 0.4195 - val_acc: 0.8209\n",
            "Epoch 7/10\n",
            " - 8s - loss: 0.4146 - acc: 0.8252 - val_loss: 0.4457 - val_acc: 0.8075\n",
            "Epoch 8/10\n",
            " - 8s - loss: 0.3999 - acc: 0.8320 - val_loss: 0.4332 - val_acc: 0.8113\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 9/10\n",
            " - 8s - loss: 0.3851 - acc: 0.8405 - val_loss: 0.4516 - val_acc: 0.8017\n",
            "Epoch 10/10\n",
            " - 8s - loss: 0.3814 - acc: 0.8433 - val_loss: 0.4550 - val_acc: 0.8004\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "3127/3127 [==============================] - 0s 151us/step\n",
            "Train on 28150 samples, validate on 3127 samples\n",
            "Epoch 1/10\n",
            " - 9s - loss: 0.5827 - acc: 0.6928 - val_loss: 0.5373 - val_acc: 0.7634\n",
            "Epoch 2/10\n",
            " - 8s - loss: 0.5140 - acc: 0.7801 - val_loss: 0.5406 - val_acc: 0.7512\n",
            "Epoch 3/10\n",
            " - 8s - loss: 0.4891 - acc: 0.7890 - val_loss: 0.5679 - val_acc: 0.7410\n",
            "\n",
            "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 4/10\n",
            " - 8s - loss: 0.4576 - acc: 0.8083 - val_loss: 0.5015 - val_acc: 0.7713\n",
            "Epoch 5/10\n",
            " - 8s - loss: 0.4453 - acc: 0.8156 - val_loss: 0.5073 - val_acc: 0.7704\n",
            "Epoch 6/10\n",
            " - 8s - loss: 0.4348 - acc: 0.8188 - val_loss: 0.5170 - val_acc: 0.7621\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 7/10\n",
            " - 8s - loss: 0.4231 - acc: 0.8265 - val_loss: 0.4656 - val_acc: 0.7953\n",
            "Epoch 8/10\n",
            " - 8s - loss: 0.4211 - acc: 0.8269 - val_loss: 0.5031 - val_acc: 0.7723\n",
            "Epoch 9/10\n",
            " - 8s - loss: 0.4177 - acc: 0.8277 - val_loss: 0.4846 - val_acc: 0.7835\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "Epoch 10/10\n",
            " - 8s - loss: 0.4141 - acc: 0.8323 - val_loss: 0.4890 - val_acc: 0.7806\n",
            "3127/3127 [==============================] - 0s 148us/step\n",
            "Train on 28150 samples, validate on 3127 samples\n",
            "Epoch 1/10\n",
            " - 9s - loss: 0.5868 - acc: 0.6809 - val_loss: 0.5599 - val_acc: 0.7333\n",
            "Epoch 2/10\n",
            " - 8s - loss: 0.5161 - acc: 0.7701 - val_loss: 0.4937 - val_acc: 0.7829\n",
            "Epoch 3/10\n",
            " - 8s - loss: 0.4911 - acc: 0.7834 - val_loss: 0.5472 - val_acc: 0.7384\n",
            "Epoch 4/10\n",
            " - 8s - loss: 0.4722 - acc: 0.7957 - val_loss: 0.5971 - val_acc: 0.7135\n",
            "\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 5/10\n",
            " - 8s - loss: 0.4377 - acc: 0.8128 - val_loss: 0.4900 - val_acc: 0.7784\n",
            "Epoch 6/10\n",
            " - 8s - loss: 0.4200 - acc: 0.8263 - val_loss: 0.4597 - val_acc: 0.8014\n",
            "Epoch 7/10\n",
            " - 8s - loss: 0.4078 - acc: 0.8309 - val_loss: 0.4685 - val_acc: 0.7950\n",
            "Epoch 8/10\n",
            " - 8s - loss: 0.3945 - acc: 0.8365 - val_loss: 0.4339 - val_acc: 0.8129\n",
            "Epoch 9/10\n",
            " - 8s - loss: 0.3788 - acc: 0.8480 - val_loss: 0.4888 - val_acc: 0.7784\n",
            "Epoch 10/10\n",
            " - 8s - loss: 0.3630 - acc: 0.8507 - val_loss: 0.4108 - val_acc: 0.8260\n",
            "3127/3127 [==============================] - 0s 152us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKgIrCHXJ_Gc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4439cf71-c42f-46e5-8e5e-d3b3b807f26d"
      },
      "source": [
        "np.array(cvscores).mean()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7192434004691955"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwZrmmcPMfKm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sepj7fJ_REvZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}