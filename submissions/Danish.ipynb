{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Danish.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOUvxRK1NKEUruOYZd16eJe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/talhaanwarch/OffenseEval2020/blob/master/submissions/Danish.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uqG7k8lK3xz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "c228c866-caa6-4660-81fc-91921cd0d89c"
      },
      "source": [
        "!pip install focal-loss\n",
        "!pip install keras-tcn==2.8.3"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting focal-loss\n",
            "  Downloading https://files.pythonhosted.org/packages/66/ed/17450291228192ad8595de4514c8ec28a587697b03c707d12d4af5b7f331/focal_loss-0.0.2-py3-none-any.whl\n",
            "Installing collected packages: focal-loss\n",
            "Successfully installed focal-loss-0.0.2\n",
            "Collecting keras-tcn==2.8.3\n",
            "  Downloading https://files.pythonhosted.org/packages/d4/c4/438c86b27ab11a79cc659d8d6878682c4eb80caa0c0b3d620740cef762f5/keras_tcn-2.8.3-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-tcn==2.8.3) (1.17.5)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-tcn==2.8.3) (2.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-tcn==2.8.3) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-tcn==2.8.3) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-tcn==2.8.3) (2.8.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras->keras-tcn==2.8.3) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-tcn==2.8.3) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-tcn==2.8.3) (1.1.0)\n",
            "Installing collected packages: keras-tcn\n",
            "Successfully installed keras-tcn-2.8.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPexfZvANVks",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "c6908f36-b44d-4b52-d513-8d48d3e967bf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6Q3msMuLDpE",
        "colab_type": "text"
      },
      "source": [
        "# Import lib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpTHlh_QLDL7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "outputId": "7b74d87a-e5f0-4adf-f54d-bef398b68f24"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Embedding,CuDNNGRU,CuDNNLSTM,Dense,Dropout,Bidirectional,BatchNormalization,GlobalMaxPooling1D,GlobalAveragePooling1D, MaxPooling1D,SpatialDropout1D,Input,Activation,concatenate,Conv1D\n",
        "from keras.optimizers import RMSprop,Adam\n",
        "from keras.initializers import Constant\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import classification_report,f1_score\n",
        "import keras\n",
        "import numpy as np\n",
        "from focal_loss import BinaryFocalLoss\n",
        "import tensorflow as tf\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Udk8qWz-K4cx",
        "colab_type": "text"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52k7345EK6kb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "783c2fea-3989-43f6-a411-058953d0edb9"
      },
      "source": [
        "cd /content/drive/My Drive/dataset/OffenseEval2020/data/Danish/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/dataset/OffenseEval2020/data/Danish\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnI2RvjGK_Vw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "671e892a-bc2f-4765-e6b8-6558eb399540"
      },
      "source": [
        "ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cc.da.300.vec     offenseval-da-test-v1-nolabels.tsv\n",
            "cc.da.300.vec.gz  offenseval-da-training-v1.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jnd4B-_5LApL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "ecb778ad-0656-4a38-edb0-6f97817ecf4e"
      },
      "source": [
        "train=pd.read_csv( 'offenseval-da-training-v1.tsv',sep=\"\\t\")\n",
        "train.drop(train.tail(n=1).index,inplace=True)\n",
        "train[\"tweet\"]= train[\"tweet\"].str.replace('@USER', \"\") \n",
        "train['tweet']=train['tweet'].str.replace('\\d+', '')\n",
        "train['tweet']=train['tweet'].str.replace('URL', '')\n",
        "train[\"tweet\"]= train[\"tweet\"].str.lower()\n",
        "train=train.sample(frac=1)\n",
        "train.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>subtask_a</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2670</th>\n",
              "      <td>3345</td>\n",
              "      <td>det er godt nok thomas</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>754</th>\n",
              "      <td>500</td>\n",
              "      <td>nej de kan rejse hjem for nogle af alle de pen...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1558</th>\n",
              "      <td>363</td>\n",
              "      <td>hvor ser du at jeg forsvare kommunisme? det gø...</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1582</th>\n",
              "      <td>2977</td>\n",
              "      <td>man(d) får associationer til år</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2682</th>\n",
              "      <td>2381</td>\n",
              "      <td>danmark stormer frem i det store udland hvor e...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id                                              tweet subtask_a\n",
              "2670  3345                            det er godt nok thomas        NOT\n",
              "754    500  nej de kan rejse hjem for nogle af alle de pen...       NOT\n",
              "1558   363  hvor ser du at jeg forsvare kommunisme? det gø...       OFF\n",
              "1582  2977                 man(d) får associationer til år          NOT\n",
              "2682  2381  danmark stormer frem i det store udland hvor e...       NOT"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdwHh_q_LLus",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "55a1eae9-c7d8-42e7-991c-acf90c692a18"
      },
      "source": [
        "test=pd.read_csv( 'offenseval-da-test-v1-nolabels.tsv',sep='\\t')\n",
        "test[\"tweet\"]= test[\"tweet   subtask_a\"].str.replace('@USER', \"\") \n",
        "test['tweet']=test['tweet'].str.replace('\\d+', '')\n",
        "test['tweet']=test['tweet'].str.replace('URL', '')\n",
        "test['tweet']=test['tweet'].str.lower()\n",
        "ids=test['id']\n",
        "test=test['tweet']\n",
        "test.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    der er syriske \"flygtninge\" som rejser til ira...\n",
              "1                               danmark = vitryssland?\n",
              "2    ja tvangsfjernelser af børn på urigtige oplysn...\n",
              "3    han kan ikke svensk og forventer et job. hvis ...\n",
              "4                                    ned med svensken!\n",
              "Name: tweet, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUFczyikLeYO",
        "colab_type": "text"
      },
      "source": [
        "#Label Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFPv0_zdLnlS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels=train['subtask_a']\n",
        "train=train['tweet']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9PjbFwJLiNA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le=LabelEncoder()\n",
        "labels=le.fit_transform(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAv_EEaQLXtY",
        "colab_type": "text"
      },
      "source": [
        "# Tokenize data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QomCkNlRLHPG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "max_words = 10000 #frequency of words to be kept\n",
        "max_len = 200\n",
        "\n",
        "tokenize = Tokenizer(num_words=max_words)\n",
        "tokenize.fit_on_texts(train)\n",
        "sequences = tokenize.texts_to_sequences(train)\n",
        "word_index = tokenize.word_index\n",
        "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og1W2rCOLs4w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dd5508d4-a9e4-448c-b942-3ade31e0158d"
      },
      "source": [
        "len(sequences_matrix),len(labels)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2960, 2960)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4kzu1RxLyGk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b5ca85a-6fea-4929-db6d-a5257237b7fa"
      },
      "source": [
        "num_words = min(max_words, len(word_index)) + 1\n",
        "print(num_words)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9802\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4i7WSY3lMmdp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_sequences = tokenize.texts_to_sequences(test)\n",
        "X_test_sequences = sequence.pad_sequences(test_sequences,maxlen=max_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRZxav1WNle-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "825ed203-4520-4cb1-e785-cd214c9fa282"
      },
      "source": [
        "len(X_test_sequences)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "329"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpzUIu4iL0PO",
        "colab_type": "text"
      },
      "source": [
        "# Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3UFPJAWL10_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed_size=300\n",
        "def get_coefs(word,*arr):\n",
        "    return word, np.asarray(arr, dtype='float32')\n",
        "\n",
        "def build_matrix(embedding_path, word_index):\n",
        "    embedding_index = dict(get_coefs(*o.strip().split(\" \")) for o in open(embedding_path))\n",
        "\n",
        "    nb_words = min(max_words, len(word_index))\n",
        "    embedding_matrix = np.zeros((nb_words + 1, embed_size))\n",
        "    for word, i in word_index.items():\n",
        "        if i >= max_words:\n",
        "            continue\n",
        "        embedding_vector = embedding_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "    return embedding_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTviPXodLzRW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "71ef12b3-94cc-431b-ccde-00b99c12210e"
      },
      "source": [
        "embeddings=build_matrix('cc.da.300.vec', word_index)\n",
        "embeddings.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9802, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8_AdRhffkS3",
        "colab_type": "text"
      },
      "source": [
        "# Base Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8BPz34Tgsr_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_val,y_train,y_val=train_test_split(train,labels,test_size=0.10,stratify=labels,shuffle=True,random_state=2020)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvXD0v5mfm7M",
        "colab_type": "text"
      },
      "source": [
        "# Count Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwPQNqimfo68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vectorizer = CountVectorizer()\n",
        "count_vectorizer.fit(x_train)\n",
        "X_train_cv = count_vectorizer.transform(x_train)\n",
        "X_val_cv  = count_vectorizer.transform(x_val)\n",
        "X_test_cv=  count_vectorizer.transform(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBKYCrdiuD-O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "dd60b6ee-1614-4f6f-9bfa-ea0e0488bb6a"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "def logistic_param_selection(X, y, nfolds):\n",
        "    C= [0.1, 1,3,5,8, 10,12,15]\n",
        "    param_grid = {'C': C}\n",
        "    grid_search = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=nfolds,scoring='f1_macro')\n",
        "    grid_search.fit(X, y)\n",
        "    print(grid_search.best_params_)\n",
        "    return grid_search.best_score_\n",
        "count_vectorizer.fit(train)\n",
        "train_cv = count_vectorizer.transform(train)\n",
        "logistic_param_selection(train_cv,labels,5)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'C': 12}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7197259792344877"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pA6nF9kLuGoI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7DrfvLqf9GB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "ffe8b060-e21f-4372-d6c9-0aa7939b94b8"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "cv_classifier = LogisticRegression(solver='lbfgs',C=10,max_iter=500,class_weight='balance')\n",
        "cv_classifier.fit(X_train_cv, y_train)\n",
        "y_pred = cv_classifier.predict(X_val_cv)\n",
        "print(classification_report(y_val, y_pred))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.98      0.95       258\n",
            "           1       0.71      0.39      0.51        38\n",
            "\n",
            "    accuracy                           0.90       296\n",
            "   macro avg       0.82      0.69      0.73       296\n",
            "weighted avg       0.89      0.90      0.89       296\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJDyK1lahqqG",
        "colab_type": "text"
      },
      "source": [
        "## TF IDF word vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gz1WZZEufmEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "word_vectorizer = TfidfVectorizer(\n",
        "    sublinear_tf=True,\n",
        "    strip_accents='unicode',\n",
        "    analyzer='word',\n",
        "    token_pattern=r'\\w{1,}',\n",
        "    ngram_range=(1, 4),\n",
        "    max_features=20000)\n",
        "word_vectorizer.fit(x_train)\n",
        "train_word_features = word_vectorizer.transform(x_train)\n",
        "test_word_features = word_vectorizer.transform(x_val)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04JmMwoEh4-d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "87058922-307a-45c8-b2fd-3395188f185e"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(solver='lbfgs',max_iter=500)\n",
        "classifier.fit(train_word_features, y_train)\n",
        "y_pred = classifier.predict(test_word_features)\n",
        "print(classification_report(y_val, y_pred))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.93       258\n",
            "           1       1.00      0.05      0.10        38\n",
            "\n",
            "    accuracy                           0.88       296\n",
            "   macro avg       0.94      0.53      0.52       296\n",
            "weighted avg       0.89      0.88      0.83       296\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNSvwaG1ioq0",
        "colab_type": "text"
      },
      "source": [
        "## TF IDF char vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_kqct6jiBq1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "char_vectorizer = TfidfVectorizer(\n",
        "    sublinear_tf=True,\n",
        "    strip_accents='unicode',\n",
        "    analyzer='char',\n",
        "    ngram_range=(1, 6),\n",
        "    max_features=30000)\n",
        "char_vectorizer.fit(x_train)\n",
        "train_char_features = char_vectorizer.transform(x_train)\n",
        "test_char_features = char_vectorizer.transform(x_val)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYhzRPO0iRMb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "6617d5e4-c286-4eea-ddaf-9e492e51fd02"
      },
      "source": [
        "classifier = LogisticRegression(solver='lbfgs',max_iter=500)\n",
        "classifier.fit(train_char_features, y_train)\n",
        "y_pred = classifier.predict(test_char_features)\n",
        "print(classification_report(y_val, y_pred))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.93       258\n",
            "           1       1.00      0.05      0.10        38\n",
            "\n",
            "    accuracy                           0.88       296\n",
            "   macro avg       0.94      0.53      0.52       296\n",
            "weighted avg       0.89      0.88      0.83       296\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6sOo5OtMQnL",
        "colab_type": "text"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G71gBUQ0MNDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_val,y_train,y_val=train_test_split(sequences_matrix,labels,test_size=0.10,stratify=labels,shuffle=True,random_state=2020)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jv2yPgQWL9de",
        "colab_type": "text"
      },
      "source": [
        "##GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXvqlGD0L-sx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_gru():\n",
        "  inp = Input(shape=(max_len,))\n",
        "  x = Embedding(num_words,embed_size,embeddings_initializer=Constant(embeddings),input_length=max_len,trainable=False)(inp)\n",
        "  x = SpatialDropout1D(0.1)(x)\n",
        "  x = Bidirectional(CuDNNLSTM(50, return_sequences=True))(x)\n",
        "  x, x_h, x_c = Bidirectional(CuDNNGRU(50, return_sequences=True, return_state = True))(x)\n",
        "  avg_pool = GlobalAveragePooling1D()(x)\n",
        "  max_pool = GlobalMaxPooling1D()(x)\n",
        "  conc = concatenate([avg_pool, x_h, max_pool])\n",
        "  outp = Dense(1, activation=\"sigmoid\")(conc)    \n",
        "  model = Model(inputs=inp, outputs=outp)\n",
        "  model.compile(loss=BinaryFocalLoss(gamma=2), optimizer=Adam(0.001), metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7t_Ph6qafOQK",
        "colab_type": "text"
      },
      "source": [
        "## GRU attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyKea_xMkrmP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://github.com/zake7749/DeepToxic\n",
        "from keras.layers import Layer,Lambda\n",
        "from keras import initializers\n",
        "from keras.engine import InputSpec, Layer\n",
        "from keras import backend as K\n",
        "\n",
        "class AttentionWeightedAverage(Layer):\n",
        "    \"\"\"\n",
        "    Computes a weighted average of the different channels across timesteps.\n",
        "    Uses 1 parameter pr. channel to compute the attention value for a single timestep.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, return_attention=False, **kwargs):\n",
        "        self.init = initializers.get('uniform')\n",
        "        self.supports_masking = True\n",
        "        self.return_attention = return_attention\n",
        "        super(AttentionWeightedAverage, self).__init__(** kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.input_spec = [InputSpec(ndim=3)]\n",
        "        assert len(input_shape) == 3\n",
        "\n",
        "        self.W = self.add_weight(shape=(input_shape[2], 1),\n",
        "                                 name='{}_W'.format(self.name),\n",
        "                                 initializer=self.init)\n",
        "        self.trainable_weights = [self.W]\n",
        "        super(AttentionWeightedAverage, self).build(input_shape)\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        # computes a probability distribution over the timesteps\n",
        "        # uses 'max trick' for numerical stability\n",
        "        # reshape is done to avoid issue with Tensorflow\n",
        "        # and 1-dimensional weights\n",
        "        logits = K.dot(x, self.W)\n",
        "        x_shape = K.shape(x)\n",
        "        logits = K.reshape(logits, (x_shape[0], x_shape[1]))\n",
        "        ai = K.exp(logits - K.max(logits, axis=-1, keepdims=True))\n",
        "\n",
        "        # masked timesteps have zero weight\n",
        "        if mask is not None:\n",
        "            mask = K.cast(mask, K.floatx())\n",
        "            ai = ai * mask\n",
        "        att_weights = ai / (K.sum(ai, axis=1, keepdims=True) + K.epsilon())\n",
        "        weighted_input = x * K.expand_dims(att_weights)\n",
        "        result = K.sum(weighted_input, axis=1)\n",
        "        if self.return_attention:\n",
        "            return [result, att_weights]\n",
        "        return result\n",
        "\n",
        "    def get_output_shape_for(self, input_shape):\n",
        "        return self.compute_output_shape(input_shape)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        output_len = input_shape[2]\n",
        "        if self.return_attention:\n",
        "            return [(input_shape[0], output_len), (input_shape[0], input_shape[1])]\n",
        "        return (input_shape[0], output_len)\n",
        "\n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        if isinstance(input_mask, list):\n",
        "            return [None] * len(input_mask)\n",
        "        else:\n",
        "            return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hovBxS5jfRbn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_gru_attn():\n",
        "  inp = Input(shape=(max_len,))\n",
        "  x = Embedding(num_words,embed_size,embeddings_initializer=Constant(embeddings),input_length=max_len,trainable=False)(inp)\n",
        "  x = SpatialDropout1D(0.1)(x)\n",
        "  x = Bidirectional(CuDNNLSTM(50, return_sequences=True))(x)\n",
        "  x = Bidirectional(CuDNNGRU(50, return_sequences=True))(x)\n",
        "  avg_pool = GlobalAveragePooling1D()(x)\n",
        "  max_pool = GlobalMaxPooling1D()(x)\n",
        "  last = Lambda(lambda t: t[:, -1])(x)\n",
        "  attn = AttentionWeightedAverage()(x)\n",
        "  conc = concatenate([avg_pool,  max_pool,last,attn])\n",
        "  outp = Dense(1, activation=\"sigmoid\")(conc)    \n",
        "  model = Model(inputs=inp, outputs=outp)\n",
        "  model.compile(loss=BinaryFocalLoss(gamma=2), optimizer=Adam(0.001), metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I34DRPLqTVru",
        "colab_type": "text"
      },
      "source": [
        "##TCN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-euqTedTWjY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tcn import TCN\n",
        "\n",
        "def wave_net_activation(x):\n",
        "    # type: (Layer) -> Layer\n",
        "    \"\"\"This method defines the activation used for WaveNet\n",
        "    described in https://deepmind.com/blog/wavenet-generative-model-raw-audio/\n",
        "    Args:\n",
        "        x: The layer we want to apply the activation to\n",
        "    Returns:\n",
        "        A new layer with the wavenet activation applied\n",
        "    \"\"\"\n",
        "    tanh_out = Activation('tanh')(x)\n",
        "    sigm_out = Activation('sigmoid')(x)\n",
        "    return keras.layers.multiply([tanh_out, sigm_out])\n",
        "\n",
        "def model_tcn(embedding_matrix):\n",
        "    \n",
        "    inp = Input(shape=(max_len,))\n",
        "    x = Embedding(num_words,embed_size,embeddings_initializer=Constant(embeddings),input_length=max_len,trainable=False)(inp)\n",
        "    x = SpatialDropout1D(0.1)(x)\n",
        "    x = TCN(128,dilations = [1, 2, 4], return_sequences=True ,name = 'tnc1')(x)\n",
        "    x = wave_net_activation(x)\n",
        "    x = TCN(64,dilations = [1, 2, 4], return_sequences=True, name = 'tnc2')(x)\n",
        "    x = wave_net_activation(x)\n",
        "    #x = TCN(32,dilations = [1, 2, 4], return_sequences=True, activation = 'wavenet',name = 'tnc3')(x)\n",
        "    avg_pool = GlobalAveragePooling1D()(x)\n",
        "    max_pool = GlobalMaxPooling1D()(x)\n",
        "    \n",
        "    conc = concatenate([avg_pool, max_pool])\n",
        "    conc = Dense(64, activation=\"relu\")(conc)\n",
        "    conc = Dense(32, activation=\"relu\")(conc)\n",
        "\n",
        "    conc = Dropout(0.1)(conc)\n",
        "    outp = Dense(1, activation=\"sigmoid\")(conc)    \n",
        "    model = Model(inputs=inp, outputs=outp)\n",
        "    model.compile(loss=BinaryFocalLoss(gamma=2), optimizer=RMSprop(), metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wLyuzTtMErl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "class_weights = class_weight.compute_class_weight('balanced',np.unique(labels),labels)\n",
        "class_weights=dict(enumerate(class_weights))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erHc_X1QoWaM",
        "colab_type": "text"
      },
      "source": [
        "## VDCNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsZkJw7UoZEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://github.com/mukesh-mehta/VDCNN/blob/master/toxic.ipynb\n",
        "def ConvolutionalBlock(input_shape, num_filters):\n",
        "    model=Sequential()\n",
        "\n",
        "    #1st conv layer\n",
        "    model.add(Conv1D(filters = num_filters, kernel_size = 3, strides = 1, padding = \"same\", input_shape = input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation(\"relu\"))\n",
        "\n",
        "    #2nd conv layer\n",
        "    model.add(Conv1D(filters = num_filters, kernel_size = 3, strides = 1, padding = \"same\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation(\"relu\"))\n",
        "\n",
        "    return model\n",
        "\n",
        "#https://www.tensorflow.org/api_docs/python/tf/nn/top_k\n",
        "def top_kmax(x):\n",
        "    x=tf.transpose(x, [0, 2, 1])\n",
        "    k_max = tf.nn.top_k(x, k=top_k)\n",
        "    return tf.reshape(k_max[0], (-1, num_filters[-1]*top_k))\n",
        "\n",
        "def conv_shape(conv):\n",
        "    return conv.get_shape().as_list()[1:]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnETJkW6onR9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_vdcnn(num_filters, num_classes, sequence_max_length, num_chars, embedding_size, top_k, learning_rate=0.001):\n",
        "    \n",
        "    inputs=Input(shape=(sequence_max_length, ), dtype='int32', name='input')\n",
        "    \n",
        "    embedded_seq = Embedding(num_words,embed_size,embeddings_initializer=Constant(embeddings),input_length=max_len,trainable=False)(inputs)\n",
        "    embedded_seq = BatchNormalization()(embedded_seq)\n",
        "    #1st Layer\n",
        "    conv = Conv1D(filters=64, kernel_size=3, strides=2, padding=\"same\")(embedded_seq)\n",
        "    \n",
        "    #ConvBlocks\n",
        "    for i in range(len(num_filters)):\n",
        "        conv = ConvolutionalBlock(conv_shape(conv), num_filters[i])(conv)\n",
        "        conv = MaxPooling1D(pool_size=3, strides=2, padding=\"same\")(conv)\n",
        "        \n",
        "    def _top_k(x):\n",
        "        x = tf.transpose(x, [0, 2, 1])\n",
        "        k_max = tf.nn.top_k(x, k=top_k)\n",
        "        return tf.reshape(k_max[0], (-1, num_filters[-1] * top_k))\n",
        "    \n",
        "    k_max = Lambda(_top_k, output_shape=(num_filters[-1] * top_k,))(conv)\n",
        "    \n",
        "    #fully connected layers\n",
        "    # in original paper they didn't used dropouts\n",
        "    fc1=Dense(100, activation='relu', kernel_initializer='he_normal')(k_max)\n",
        "    fc1=Dropout(0.3)(fc1)\n",
        "    fc2=Dense(20, activation='relu', kernel_initializer='he_normal')(fc1)\n",
        "    fc2=Dropout(0.3)(fc2)\n",
        "    out=Dense(1, activation='sigmoid')(fc2)\n",
        "    \n",
        "    \n",
        "    model = Model(inputs=inputs, outputs=out)\n",
        "    model.compile(optimizer='rmsprop', loss=BinaryFocalLoss(gamma=2), metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuu9uY96pKYe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_filters = [64, 128, 256, 512]\n",
        "vdcnn_model=model_vdcnn(num_filters=num_filters, num_classes=1,num_chars=69, sequence_max_length=max_len,embedding_size=16,top_k=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d55WTNmBa5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNc6xxspBcTG",
        "colab_type": "text"
      },
      "source": [
        "##KIM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAgtTt9IBfMQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_filters=128\n",
        "def model_kim():\n",
        "  inp = Input(shape=(max_len,))\n",
        "  emb = Embedding(num_words,embed_size,embeddings_initializer=Constant(embeddings),input_length=max_len,trainable=False)(inp)\n",
        "  # Specify each convolution layer and their kernel siz i.e. n-grams \n",
        "  conv1_1 = Conv1D(filters=conv_filters, kernel_size=3)(emb)\n",
        "  btch1_1 = BatchNormalization()(conv1_1)\n",
        "  drp1_1  = Dropout(0.2)(btch1_1)\n",
        "  actv1_1 = Activation('relu')(drp1_1)\n",
        "  glmp1_1 = GlobalMaxPooling1D()(actv1_1)\n",
        "\n",
        "  conv1_2 = Conv1D(filters=conv_filters, kernel_size=4)(emb)\n",
        "  btch1_2 = BatchNormalization()(conv1_2)\n",
        "  drp1_2  = Dropout(0.2)(btch1_2)\n",
        "  actv1_2 = Activation('relu')(drp1_2)\n",
        "  glmp1_2 = GlobalMaxPooling1D()(actv1_2)\n",
        "\n",
        "  conv1_3 = Conv1D(filters=conv_filters, kernel_size=5)(emb)\n",
        "  btch1_3 = BatchNormalization()(conv1_3)\n",
        "  drp1_3  = Dropout(0.2)(btch1_3)\n",
        "  actv1_3 = Activation('relu')(drp1_3)\n",
        "  glmp1_3 = GlobalMaxPooling1D()(actv1_3)\n",
        "\n",
        "  conv1_4 = Conv1D(filters=conv_filters, kernel_size=6)(emb)\n",
        "  btch1_4 = BatchNormalization()(conv1_4)\n",
        "  drp1_4  = Dropout(0.2)(btch1_4)\n",
        "  actv1_4 = Activation('relu')(drp1_4)\n",
        "  glmp1_4 = GlobalMaxPooling1D()(actv1_4)\n",
        "\n",
        "  # Gather all convolution layers\n",
        "  cnct = concatenate([glmp1_1, glmp1_2, glmp1_3, glmp1_4], axis=1)\n",
        "  drp1 = Dropout(0.2)(cnct)\n",
        "\n",
        "  dns1  = Dense(32, activation='relu')(drp1)\n",
        "  btch1 = BatchNormalization()(dns1)\n",
        "  drp2  = Dropout(0.2)(btch1)\n",
        "\n",
        "  out = Dense(1, activation='sigmoid')(drp2)   \n",
        "  model = Model(inputs=inp, outputs=out)\n",
        "  model.compile(loss=BinaryFocalLoss(gamma=2), optimizer=Adam(0.001), metrics=['accuracy'])\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJCuBpqkNx8L",
        "colab_type": "text"
      },
      "source": [
        "# Train model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUygUis5N2yN",
        "colab_type": "text"
      },
      "source": [
        "##GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyLDrkoXMGoi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "32c537bf-a5af-47bf-dfce-95e547c18d63"
      },
      "source": [
        "gru_model=model_gru()\n",
        "gru_model.fit(x_train,y_train,batch_size=64,epochs=10,verbose=2,class_weight=class_weights,validation_data=(x_val,y_val))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2664 samples, validate on 296 samples\n",
            "Epoch 1/10\n",
            " - 9s - loss: 0.1113 - acc: 0.8697 - val_loss: 0.1032 - val_acc: 0.8716\n",
            "Epoch 2/10\n",
            " - 8s - loss: 0.1028 - acc: 0.8686 - val_loss: 0.0991 - val_acc: 0.8716\n",
            "Epoch 3/10\n",
            " - 8s - loss: 0.0927 - acc: 0.8773 - val_loss: 0.0937 - val_acc: 0.8784\n",
            "Epoch 4/10\n",
            " - 8s - loss: 0.0831 - acc: 0.8851 - val_loss: 0.0937 - val_acc: 0.8750\n",
            "Epoch 5/10\n",
            " - 8s - loss: 0.0749 - acc: 0.9054 - val_loss: 0.0978 - val_acc: 0.8818\n",
            "Epoch 6/10\n",
            " - 8s - loss: 0.0717 - acc: 0.9065 - val_loss: 0.0953 - val_acc: 0.8818\n",
            "Epoch 7/10\n",
            " - 8s - loss: 0.0683 - acc: 0.9114 - val_loss: 0.1023 - val_acc: 0.8851\n",
            "Epoch 8/10\n",
            " - 8s - loss: 0.0654 - acc: 0.9182 - val_loss: 0.0977 - val_acc: 0.8750\n",
            "Epoch 9/10\n",
            " - 8s - loss: 0.0627 - acc: 0.9137 - val_loss: 0.1051 - val_acc: 0.8615\n",
            "Epoch 10/10\n",
            " - 8s - loss: 0.0582 - acc: 0.9242 - val_loss: 0.1117 - val_acc: 0.8716\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4ce5a88b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaW-Uq0Kldp4",
        "colab_type": "text"
      },
      "source": [
        "## GRU attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjPFYBWZlf23",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "43551793-ea44-4349-b779-20ca09eeef19"
      },
      "source": [
        "attn_gru_model=model_gru_attn()\n",
        "attn_gru_model.fit(x_train,y_train,batch_size=64,epochs=10,verbose=2,class_weight=class_weights,validation_data=(x_val,y_val))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2664 samples, validate on 296 samples\n",
            "Epoch 1/10\n",
            " - 9s - loss: 0.1158 - acc: 0.8690 - val_loss: 0.1033 - val_acc: 0.8615\n",
            "Epoch 2/10\n",
            " - 8s - loss: 0.1026 - acc: 0.8705 - val_loss: 0.1009 - val_acc: 0.8716\n",
            "Epoch 3/10\n",
            " - 8s - loss: 0.0934 - acc: 0.8727 - val_loss: 0.0984 - val_acc: 0.8682\n",
            "Epoch 4/10\n",
            " - 8s - loss: 0.0860 - acc: 0.8836 - val_loss: 0.0954 - val_acc: 0.8682\n",
            "Epoch 5/10\n",
            " - 8s - loss: 0.0786 - acc: 0.8908 - val_loss: 0.0950 - val_acc: 0.8784\n",
            "Epoch 6/10\n",
            " - 8s - loss: 0.0735 - acc: 0.9005 - val_loss: 0.0946 - val_acc: 0.8784\n",
            "Epoch 7/10\n",
            " - 8s - loss: 0.0678 - acc: 0.9118 - val_loss: 0.0972 - val_acc: 0.8750\n",
            "Epoch 8/10\n",
            " - 8s - loss: 0.0647 - acc: 0.9140 - val_loss: 0.0982 - val_acc: 0.8818\n",
            "Epoch 9/10\n",
            " - 8s - loss: 0.0616 - acc: 0.9174 - val_loss: 0.1017 - val_acc: 0.8784\n",
            "Epoch 10/10\n",
            " - 8s - loss: 0.0545 - acc: 0.9242 - val_loss: 0.1188 - val_acc: 0.8818\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4d46fb08d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlFNurr4T1rh",
        "colab_type": "text"
      },
      "source": [
        "##TCN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKtfxHFBT2wB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "553285d6-7c8c-42c1-f110-f36e42b9f292"
      },
      "source": [
        "tcn_model=model_tcn(embeddings)\n",
        "tcn_model.fit(x_train,y_train,batch_size=64,epochs=10,verbose=2,class_weight=class_weights,validation_data=(x_val,y_val))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2664 samples, validate on 296 samples\n",
            "Epoch 1/10\n",
            " - 8s - loss: 0.1133 - acc: 0.8619 - val_loss: 0.1066 - val_acc: 0.8716\n",
            "Epoch 2/10\n",
            " - 2s - loss: 0.1073 - acc: 0.8690 - val_loss: 0.1034 - val_acc: 0.8716\n",
            "Epoch 3/10\n",
            " - 2s - loss: 0.1004 - acc: 0.8705 - val_loss: 0.0942 - val_acc: 0.8716\n",
            "Epoch 4/10\n",
            " - 2s - loss: 0.0893 - acc: 0.8765 - val_loss: 0.0891 - val_acc: 0.8716\n",
            "Epoch 5/10\n",
            " - 2s - loss: 0.0811 - acc: 0.8874 - val_loss: 0.0828 - val_acc: 0.8784\n",
            "Epoch 6/10\n",
            " - 2s - loss: 0.0713 - acc: 0.9110 - val_loss: 0.0943 - val_acc: 0.9020\n",
            "Epoch 7/10\n",
            " - 2s - loss: 0.0638 - acc: 0.9208 - val_loss: 0.0962 - val_acc: 0.9088\n",
            "Epoch 8/10\n",
            " - 2s - loss: 0.0582 - acc: 0.9313 - val_loss: 0.0991 - val_acc: 0.9054\n",
            "Epoch 9/10\n",
            " - 2s - loss: 0.0525 - acc: 0.9381 - val_loss: 0.0888 - val_acc: 0.8919\n",
            "Epoch 10/10\n",
            " - 2s - loss: 0.0466 - acc: 0.9482 - val_loss: 0.1021 - val_acc: 0.8851\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4ce657bf28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNJpZFJbp5mP",
        "colab_type": "text"
      },
      "source": [
        "##VDCNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lqcj8gZhp7hA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "081b9e77-182c-4ebf-9eb7-8b0465c7f12c"
      },
      "source": [
        "vdcnn_model.fit(x_train,y_train,batch_size=64,epochs=10,verbose=2,class_weight=class_weights,validation_data=(x_val,y_val))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2664 samples, validate on 296 samples\n",
            "Epoch 1/10\n",
            " - 7s - loss: 0.3589 - acc: 0.7774 - val_loss: 0.1094 - val_acc: 0.8716\n",
            "Epoch 2/10\n",
            " - 3s - loss: 0.1555 - acc: 0.8529 - val_loss: 0.1544 - val_acc: 0.8716\n",
            "Epoch 3/10\n",
            " - 3s - loss: 0.1380 - acc: 0.8634 - val_loss: 0.4015 - val_acc: 0.8716\n",
            "Epoch 4/10\n",
            " - 3s - loss: 0.1304 - acc: 0.8690 - val_loss: 0.1124 - val_acc: 0.8716\n",
            "Epoch 5/10\n",
            " - 3s - loss: 0.1207 - acc: 0.8682 - val_loss: 0.1295 - val_acc: 0.8716\n",
            "Epoch 6/10\n",
            " - 3s - loss: 0.1165 - acc: 0.8697 - val_loss: 0.1148 - val_acc: 0.8716\n",
            "Epoch 7/10\n",
            " - 3s - loss: 0.1063 - acc: 0.8679 - val_loss: 0.1371 - val_acc: 0.8615\n",
            "Epoch 8/10\n",
            " - 3s - loss: 0.0979 - acc: 0.8784 - val_loss: 0.1318 - val_acc: 0.8716\n",
            "Epoch 9/10\n",
            " - 3s - loss: 0.0875 - acc: 0.8833 - val_loss: 0.1332 - val_acc: 0.8547\n",
            "Epoch 10/10\n",
            " - 3s - loss: 0.0747 - acc: 0.9028 - val_loss: 0.1853 - val_acc: 0.8953\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4d46d00fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tr_J6FWTCYXB",
        "colab_type": "text"
      },
      "source": [
        "##KIM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgmUF8liCa4M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "d6a71b46-d51f-4102-a49e-b6908464e9ae"
      },
      "source": [
        "kim_model=model_kim()\n",
        "kim_model.fit(x_train,y_train,batch_size=64,epochs=10,verbose=2,class_weight=class_weights,validation_data=(x_val,y_val))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2664 samples, validate on 296 samples\n",
            "Epoch 1/10\n",
            " - 4s - loss: 0.2791 - acc: 0.5728 - val_loss: 0.1482 - val_acc: 0.7061\n",
            "Epoch 2/10\n",
            " - 2s - loss: 0.1577 - acc: 0.7346 - val_loss: 0.1283 - val_acc: 0.8074\n",
            "Epoch 3/10\n",
            " - 2s - loss: 0.1227 - acc: 0.8131 - val_loss: 0.1005 - val_acc: 0.8649\n",
            "Epoch 4/10\n",
            " - 2s - loss: 0.1089 - acc: 0.8382 - val_loss: 0.1347 - val_acc: 0.8514\n",
            "Epoch 5/10\n",
            " - 2s - loss: 0.0892 - acc: 0.8788 - val_loss: 0.0949 - val_acc: 0.8851\n",
            "Epoch 6/10\n",
            " - 2s - loss: 0.0772 - acc: 0.8998 - val_loss: 0.0915 - val_acc: 0.8649\n",
            "Epoch 7/10\n",
            " - 2s - loss: 0.0670 - acc: 0.9182 - val_loss: 0.0821 - val_acc: 0.8581\n",
            "Epoch 8/10\n",
            " - 2s - loss: 0.0534 - acc: 0.9381 - val_loss: 0.0885 - val_acc: 0.8750\n",
            "Epoch 9/10\n",
            " - 2s - loss: 0.0449 - acc: 0.9396 - val_loss: 0.0985 - val_acc: 0.8986\n",
            "Epoch 10/10\n",
            " - 2s - loss: 0.0410 - acc: 0.9482 - val_loss: 0.1004 - val_acc: 0.8953\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4ce3dd3668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRW2JWbBMfkb",
        "colab_type": "text"
      },
      "source": [
        "# Validate Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7BVpvPJOH5x",
        "colab_type": "text"
      },
      "source": [
        "##GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gd85B8kuMWU1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "f23e3141-a34c-411e-fea3-e422feef035f"
      },
      "source": [
        "y_pred = gru_model.predict(x_val, batch_size=64, verbose=1)\n",
        "y_pred_bool = np.argmax(y_pred, axis=1)\n",
        "y_pred = (y_pred > 0.5)\n",
        "\n",
        "print(classification_report(y_val, y_pred))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "296/296 [==============================] - 1s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.93      0.93       258\n",
            "           1       0.50      0.47      0.49        38\n",
            "\n",
            "    accuracy                           0.87       296\n",
            "   macro avg       0.71      0.70      0.71       296\n",
            "weighted avg       0.87      0.87      0.87       296\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQQUnhy-ljKa",
        "colab_type": "text"
      },
      "source": [
        "## GRU attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJvhOCgEllGM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "879b968e-dcaa-46c0-eeb7-1e08fb216caa"
      },
      "source": [
        "y_pred = attn_gru_model.predict(x_val, batch_size=64, verbose=1)\n",
        "y_pred_bool = np.argmax(y_pred, axis=1)\n",
        "y_pred = (y_pred > 0.5)\n",
        "\n",
        "print(classification_report(y_val, y_pred))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "296/296 [==============================] - 1s 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.97      0.93       258\n",
            "           1       0.59      0.26      0.36        38\n",
            "\n",
            "    accuracy                           0.88       296\n",
            "   macro avg       0.74      0.62      0.65       296\n",
            "weighted avg       0.86      0.88      0.86       296\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PmqHy-HWeuQ",
        "colab_type": "text"
      },
      "source": [
        "##TCN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8SxnEBRWf-R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "c0e8541d-6a1f-42fd-936c-18f9bfcc4fd2"
      },
      "source": [
        "y_pred = tcn_model.predict(x_val, batch_size=64, verbose=1)\n",
        "y_pred_bool = np.argmax(y_pred, axis=1)\n",
        "y_pred = (y_pred > 0.5)\n",
        "\n",
        "print(classification_report(y_val, y_pred))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "296/296 [==============================] - 1s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.94      0.93       258\n",
            "           1       0.56      0.53      0.54        38\n",
            "\n",
            "    accuracy                           0.89       296\n",
            "   macro avg       0.74      0.73      0.74       296\n",
            "weighted avg       0.88      0.89      0.88       296\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQlsCQyrqX0j",
        "colab_type": "text"
      },
      "source": [
        "## VDCNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0M7HGbRJqUzn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "35a32f20-9847-4b94-ae78-0abd0f6282b5"
      },
      "source": [
        "y_pred = vdcnn_model.predict(x_val, batch_size=64, verbose=1)\n",
        "y_pred_bool = np.argmax(y_pred, axis=1)\n",
        "y_pred = (y_pred > 0.5)\n",
        "\n",
        "print(classification_report(y_val, y_pred))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "296/296 [==============================] - 1s 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.98      0.94       258\n",
            "           1       0.68      0.34      0.46        38\n",
            "\n",
            "    accuracy                           0.90       296\n",
            "   macro avg       0.80      0.66      0.70       296\n",
            "weighted avg       0.88      0.90      0.88       296\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ix_QKjbbC7ub",
        "colab_type": "text"
      },
      "source": [
        "##KIM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0McQOe5pC8oQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "a7f07b6b-777a-4f63-8a28-1d5e524d3109"
      },
      "source": [
        "y_pred = kim_model.predict(x_val, batch_size=64, verbose=1)\n",
        "y_pred_bool = np.argmax(y_pred, axis=1)\n",
        "y_pred = (y_pred > 0.5)\n",
        "\n",
        "print(classification_report(y_val, y_pred))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "296/296 [==============================] - 0s 1ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.99      0.94       258\n",
            "           1       0.82      0.24      0.37        38\n",
            "\n",
            "    accuracy                           0.90       296\n",
            "   macro avg       0.86      0.61      0.66       296\n",
            "weighted avg       0.89      0.90      0.87       296\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dl57zICXM4c6",
        "colab_type": "text"
      },
      "source": [
        "# Submit file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tLeg_p9M3T6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "4b63dbef-8771-47b9-c094-e37854fce131"
      },
      "source": [
        "y_test_cv = cv_classifier.predict(X_test_cv)\n",
        "y_test_gru = gru_model.predict(X_test_sequences, batch_size=64, verbose=1)\n",
        "y_test_gru_atten = attn_gru_model.predict(X_test_sequences, batch_size=64, verbose=1)\n",
        "y_test_tcn = tcn_model.predict(X_test_sequences, batch_size=64, verbose=1)\n",
        "# # "
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "329/329 [==============================] - 0s 813us/step\n",
            "329/329 [==============================] - 0s 822us/step\n",
            "329/329 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIf7v6eHyu3b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "48204d8c-b9d6-420c-fcd8-7054779ae368"
      },
      "source": [
        "y_test=np.mean((y_test_cv.ravel(),y_test_gru.ravel(),y_test_gru_atten.ravel(),y_test_tcn.ravel()),axis=0)\n",
        "y_test.shape"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(329,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8X-SSSo6zJTV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "9ed5cc57-ec4c-48af-f091-e80a2f452232"
      },
      "source": [
        "y_test[0:10]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.12462883, 0.18853208, 0.16026854, 0.11188069, 0.15853215,\n",
              "       0.10720116, 0.24298399, 0.08039539, 0.18485107, 0.15721201])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHTCw4_jP_tr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test[y_test>0.5]=1\n",
        "y_test[y_test<0.5]=0\n",
        "y_test=y_test.astype('int16').ravel()\n",
        "\n",
        "y_test=le.inverse_transform(y_test)\n",
        "y_test=pd.DataFrame(y_test,columns=['label'])\n",
        "y_test=pd.concat([ids, y_test['label']], axis=1)\n",
        "\n",
        "\n",
        "y_test.to_csv('/content/weighted.csv',index=False,header=None)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tPo96DUz_EZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwKb7_NBWjAv",
        "colab_type": "text"
      },
      "source": [
        "# Reset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0Xi3s2KWlKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "keras.backend.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T39YK5rbQBoT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}