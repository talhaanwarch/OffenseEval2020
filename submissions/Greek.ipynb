{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Greek.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "FwKb7_NBWjAv"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/talhaanwarch/OffenseEval2020/blob/master/submissions/Greek.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uqG7k8lK3xz",
        "colab_type": "code",
        "outputId": "c464ad91-1f92-43e8-f593-be07f16206b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "!pip install focal-loss\n",
        "!pip install keras-tcn==2.8.3"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting focal-loss\n",
            "  Downloading https://files.pythonhosted.org/packages/66/ed/17450291228192ad8595de4514c8ec28a587697b03c707d12d4af5b7f331/focal_loss-0.0.2-py3-none-any.whl\n",
            "Installing collected packages: focal-loss\n",
            "Successfully installed focal-loss-0.0.2\n",
            "Collecting keras-tcn==2.8.3\n",
            "  Downloading https://files.pythonhosted.org/packages/d4/c4/438c86b27ab11a79cc659d8d6878682c4eb80caa0c0b3d620740cef762f5/keras_tcn-2.8.3-py3-none-any.whl\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-tcn==2.8.3) (2.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-tcn==2.8.3) (1.17.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-tcn==2.8.3) (1.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-tcn==2.8.3) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-tcn==2.8.3) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-tcn==2.8.3) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras->keras-tcn==2.8.3) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-tcn==2.8.3) (2.8.0)\n",
            "Installing collected packages: keras-tcn\n",
            "Successfully installed keras-tcn-2.8.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPexfZvANVks",
        "colab_type": "code",
        "outputId": "a04e98e0-0e08-4c50-e87d-661fe4259a5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6Q3msMuLDpE",
        "colab_type": "text"
      },
      "source": [
        "# Import lib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpTHlh_QLDL7",
        "colab_type": "code",
        "outputId": "b18e8681-084b-4e10-a9e4-01f1581ae292",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Embedding,CuDNNGRU,CuDNNLSTM,Dense,Dropout,Bidirectional,BatchNormalization,GlobalMaxPooling1D,Flatten, GlobalAveragePooling1D, MaxPooling1D,SpatialDropout1D,Input,Activation,concatenate,Conv1D\n",
        "from keras.optimizers import RMSprop,Adam,Adadelta\n",
        "from keras.initializers import Constant\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import classification_report,f1_score\n",
        "import keras\n",
        "import collections\n",
        "import numpy as np\n",
        "from focal_loss import BinaryFocalLoss\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Udk8qWz-K4cx",
        "colab_type": "text"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52k7345EK6kb",
        "colab_type": "code",
        "outputId": "3ea51f86-0394-47d7-de65-3df6a2b8b792",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/My Drive/dataset/OffenseEval2020/data/Greek/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/dataset/OffenseEval2020/data/Greek\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnI2RvjGK_Vw",
        "colab_type": "code",
        "outputId": "006f8ee2-eb37-40ac-969b-c7881c39957a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cc.el.300.vec     offenseval-greek-training-v1.tsv  testset_taska.tsv\n",
            "cc.el.300.vec.gz  readme-trainingset-greek.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jnd4B-_5LApL",
        "colab_type": "code",
        "outputId": "8c9762aa-ffe0-4f51-c14c-3d931b1b51ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "train=pd.read_csv( 'offenseval-greek-training-v1.tsv',sep=\"\\t\")\n",
        "train.drop(train.tail(n=1).index,inplace=True)\n",
        "train[\"tweet\"]= train[\"tweet\"].str.replace('@USER', \"\") \n",
        "train['tweet']=train['tweet'].str.replace('\\d+', '')\n",
        "train['tweet']=train['tweet'].str.replace('URL', '')\n",
        "train[\"tweet\"]= train[\"tweet\"].str.lower()\n",
        "train=train.sample(frac=1)\n",
        "print(len(train))\n",
        "train.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8742\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>subtask_a</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1829</th>\n",
              "      <td>522</td>\n",
              "      <td>στο σπιτι μενετε μαζι αρα εχεις οφελος χωρις ...</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6437</th>\n",
              "      <td>3867</td>\n",
              "      <td>αθλητικό με φιόγκο; φιόγκοι παντού! θάνατος στ...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4403</th>\n",
              "      <td>6893</td>\n",
              "      <td>αφού υπάρχει η επιλογή κάποιος να τους δίνει τ...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3643</th>\n",
              "      <td>0</td>\n",
              "      <td>κατι αριστερες π που μας πουλαγαν φεμινισμο τη...</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4216</th>\n",
              "      <td>6084</td>\n",
              "      <td>χαρηκε η κοκοτα η κατια #gntmgr</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id                                              tweet subtask_a\n",
              "1829   522   στο σπιτι μενετε μαζι αρα εχεις οφελος χωρις ...       OFF\n",
              "6437  3867  αθλητικό με φιόγκο; φιόγκοι παντού! θάνατος στ...       NOT\n",
              "4403  6893  αφού υπάρχει η επιλογή κάποιος να τους δίνει τ...       NOT\n",
              "3643     0  κατι αριστερες π που μας πουλαγαν φεμινισμο τη...       OFF\n",
              "4216  6084                    χαρηκε η κοκοτα η κατια #gntmgr       NOT"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdwHh_q_LLus",
        "colab_type": "code",
        "outputId": "fbc8f76b-f1b8-4ce6-f7fd-2ebc35488349",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "test=pd.read_csv( 'testset_taska.tsv',sep='\\t')\n",
        "test[\"tweet\"]= test[\"tweet\"].str.replace('@USER', \"\") \n",
        "test['tweet']=test['tweet'].str.replace('\\d+', '')\n",
        "test['tweet']=test['tweet'].str.replace('URL', '')\n",
        "test['tweet']=test['tweet'].str.lower()\n",
        "ids=test['id']\n",
        "test=test['tweet']\n",
        "test.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     θέλω να των δω από εδώ και εμπρός αν δεν κάνε...\n",
              "1    #survivorgr α και  φορές και με διαφορετικούς....\n",
              "2    και μου έλεγε η γυναίκα μου το πρωί πάρε την τ...\n",
              "3                     κατω τα χερια απο τον #κυρανακης\n",
              "4     μην μας το παιζεις πονοψυχη,κρυφορατσιστρια τ...\n",
              "Name: tweet, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUFczyikLeYO",
        "colab_type": "text"
      },
      "source": [
        "#Label Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFPv0_zdLnlS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels=train['subtask_a']\n",
        "train=train['tweet']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9PjbFwJLiNA",
        "colab_type": "code",
        "outputId": "1dde60d8-5b00-4ef0-8c1a-b27252c511d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "le=LabelEncoder()\n",
        "labels=le.fit_transform(labels)\n",
        "print(len(labels))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8742\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ek_ZUjDef7ZV",
        "colab_type": "text"
      },
      "source": [
        "# Common Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdtjDLnOACbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "class_weights = class_weight.compute_class_weight('balanced',np.unique(labels),labels)\n",
        "class_weights=dict(enumerate(class_weights))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-IToeBciV1m",
        "colab_type": "text"
      },
      "source": [
        "## Cylic learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIYW6ZAniXzU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://www.kaggle.com/hireme/fun-api-keras-f1-metric-cyclical-learning-rate/code\n",
        "from keras.callbacks import Callback\n",
        "class CyclicLR(Callback):\n",
        "    \"\"\"This callback implements a cyclical learning rate policy (CLR).\n",
        "    The method cycles the learning rate between two boundaries with\n",
        "    some constant frequency, as detailed in this paper (https://arxiv.org/abs/1506.01186).\n",
        "    The amplitude of the cycle can be scaled on a per-iteration or \n",
        "    per-cycle basis.\n",
        "    This class has three built-in policies, as put forth in the paper.\n",
        "    \"triangular\":\n",
        "        A basic triangular cycle w/ no amplitude scaling.\n",
        "    \"triangular2\":\n",
        "        A basic triangular cycle that scales initial amplitude by half each cycle.\n",
        "    \"exp_range\":\n",
        "        A cycle that scales initial amplitude by gamma**(cycle iterations) at each \n",
        "        cycle iteration.\n",
        "    For more detail, please see paper.\n",
        "    \n",
        "    # Example\n",
        "        ```python\n",
        "            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
        "                                step_size=2000., mode='triangular')\n",
        "            model.fit(X_train, Y_train, callbacks=[clr])\n",
        "        ```\n",
        "    \n",
        "    Class also supports custom scaling functions:\n",
        "        ```python\n",
        "            clr_fn = lambda x: 0.5*(1+np.sin(x*np.pi/2.))\n",
        "            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
        "                                step_size=2000., scale_fn=clr_fn,\n",
        "                                scale_mode='cycle')\n",
        "            model.fit(X_train, Y_train, callbacks=[clr])\n",
        "        ```    \n",
        "    # Arguments\n",
        "        base_lr: initial learning rate which is the\n",
        "            lower boundary in the cycle.\n",
        "        max_lr: upper boundary in the cycle. Functionally,\n",
        "            it defines the cycle amplitude (max_lr - base_lr).\n",
        "            The lr at any cycle is the sum of base_lr\n",
        "            and some scaling of the amplitude; therefore \n",
        "            max_lr may not actually be reached depending on\n",
        "            scaling function.\n",
        "        step_size: number of training iterations per\n",
        "            half cycle. Authors suggest setting step_size\n",
        "            2-8 x training iterations in epoch.\n",
        "        mode: one of {triangular, triangular2, exp_range}.\n",
        "            Default 'triangular'.\n",
        "            Values correspond to policies detailed above.\n",
        "            If scale_fn is not None, this argument is ignored.\n",
        "        gamma: constant in 'exp_range' scaling function:\n",
        "            gamma**(cycle iterations)\n",
        "        scale_fn: Custom scaling policy defined by a single\n",
        "            argument lambda function, where \n",
        "            0 <= scale_fn(x) <= 1 for all x >= 0.\n",
        "            mode paramater is ignored \n",
        "        scale_mode: {'cycle', 'iterations'}.\n",
        "            Defines whether scale_fn is evaluated on \n",
        "            cycle number or cycle iterations (training\n",
        "            iterations since start of cycle). Default is 'cycle'.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=2000., mode='triangular',\n",
        "                 gamma=1., scale_fn=None, scale_mode='cycle'):\n",
        "        super(CyclicLR, self).__init__()\n",
        "\n",
        "        self.base_lr = base_lr\n",
        "        self.max_lr = max_lr\n",
        "        self.step_size = step_size\n",
        "        self.mode = mode\n",
        "        self.gamma = gamma\n",
        "        if scale_fn == None:\n",
        "            if self.mode == 'triangular':\n",
        "                self.scale_fn = lambda x: 1.\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'triangular2':\n",
        "                self.scale_fn = lambda x: 1/(2.**(x-1))\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'exp_range':\n",
        "                self.scale_fn = lambda x: gamma**(x)\n",
        "                self.scale_mode = 'iterations'\n",
        "        else:\n",
        "            self.scale_fn = scale_fn\n",
        "            self.scale_mode = scale_mode\n",
        "        self.clr_iterations = 0.\n",
        "        self.trn_iterations = 0.\n",
        "        self.history = {}\n",
        "\n",
        "        self._reset()\n",
        "\n",
        "    def _reset(self, new_base_lr=None, new_max_lr=None,\n",
        "               new_step_size=None):\n",
        "        \"\"\"Resets cycle iterations.\n",
        "        Optional boundary/step size adjustment.\n",
        "        \"\"\"\n",
        "        if new_base_lr != None:\n",
        "            self.base_lr = new_base_lr\n",
        "        if new_max_lr != None:\n",
        "            self.max_lr = new_max_lr\n",
        "        if new_step_size != None:\n",
        "            self.step_size = new_step_size\n",
        "        self.clr_iterations = 0.\n",
        "        \n",
        "    def clr(self):\n",
        "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
        "        x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
        "        if self.scale_mode == 'cycle':\n",
        "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(cycle)\n",
        "        else:\n",
        "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(self.clr_iterations)\n",
        "        \n",
        "    def on_train_begin(self, logs={}):\n",
        "        logs = logs or {}\n",
        "\n",
        "        if self.clr_iterations == 0:\n",
        "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
        "        else:\n",
        "            K.set_value(self.model.optimizer.lr, self.clr())        \n",
        "            \n",
        "    def on_batch_end(self, epoch, logs=None):\n",
        "        \n",
        "        logs = logs or {}\n",
        "        self.trn_iterations += 1\n",
        "        self.clr_iterations += 1\n",
        "\n",
        "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
        "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
        "\n",
        "        for k, v in logs.items():\n",
        "            self.history.setdefault(k, []).append(v)\n",
        "        \n",
        "        K.set_value(self.model.optimizer.lr, self.clr())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIcxIjeYjHyo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clr = CyclicLR(base_lr=0.001, max_lr=0.005,\n",
        "                        step_size=4., mode='exp_range',\n",
        "                        gamma=0.99994)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAv_EEaQLXtY",
        "colab_type": "text"
      },
      "source": [
        "# Tokenize data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QomCkNlRLHPG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "max_words = 10000 #frequency of words to be kept\n",
        "max_len = 200\n",
        "\n",
        "tokenize = Tokenizer(num_words=max_words)\n",
        "tokenize.fit_on_texts(train)\n",
        "sequences = tokenize.texts_to_sequences(train)\n",
        "word_index = tokenize.word_index\n",
        "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len,padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og1W2rCOLs4w",
        "colab_type": "code",
        "outputId": "4cf8806c-a07f-4923-d56f-960feb6baf9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(sequences_matrix),len(labels)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8742, 8742)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4kzu1RxLyGk",
        "colab_type": "code",
        "outputId": "869acb59-c8c5-41d9-8ae6-31b52e0dad04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "num_words = min(max_words, len(word_index)) + 1\n",
        "print(num_words)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4i7WSY3lMmdp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_sequences = tokenize.texts_to_sequences(test)\n",
        "X_test_sequences = sequence.pad_sequences(test_sequences,maxlen=max_len,padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRZxav1WNle-",
        "colab_type": "code",
        "outputId": "09c58a9a-d783-4611-d095-0eac74aecfd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(X_test_sequences)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1544"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpzUIu4iL0PO",
        "colab_type": "text"
      },
      "source": [
        "# Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3UFPJAWL10_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed_size=300\n",
        "def get_coefs(word,*arr):\n",
        "    return word, np.asarray(arr, dtype='float32')\n",
        "\n",
        "def build_matrix(embedding_path, word_index):\n",
        "    embedding_index = dict(get_coefs(*o.strip().split(\" \")) for o in open(embedding_path))\n",
        "\n",
        "    nb_words = min(max_words, len(word_index))\n",
        "    embedding_matrix = np.zeros((nb_words + 1, embed_size))\n",
        "    for word, i in word_index.items():\n",
        "        if i >= max_words:\n",
        "            continue\n",
        "        embedding_vector = embedding_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "    return embedding_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTviPXodLzRW",
        "colab_type": "code",
        "outputId": "3fcd3634-332c-4743-c066-34c5f46e1934",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embeddings=build_matrix('cc.el.300.vec', word_index)\n",
        "embeddings.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10001, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8_AdRhffkS3",
        "colab_type": "text"
      },
      "source": [
        "# Base Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaShFhtgJ_Ef",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d118d7b1-474d-4407-b701-4c1b1fc64bfa"
      },
      "source": [
        "train.shape,labels.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8742,), (8742,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvXD0v5mfm7M",
        "colab_type": "text"
      },
      "source": [
        "## Count Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7blhzyaD-xvK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def logistic_param_selection(X, y, func,nfolds):\n",
        "    C= [7,8,9,10,12,15,20,25]\n",
        "    param_grid = {'C': C}\n",
        "    grid_search = GridSearchCV(make_pipeline(func, LogisticRegression(solver='lbfgs',max_iter=500,class_weight=class_weights)),\n",
        "                    param_grid={'logisticregression__C':[10,12,15,20,25]}, cv=nfolds,scoring='f1_macro')\n",
        "    grid_search.fit(X, y)\n",
        "    return grid_search.best_score_,grid_search.best_params_\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHFZoqkGI79e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2b69040c-6652-4884-e792-b7766e7ef59b"
      },
      "source": [
        "cv_score,c=logistic_param_selection(train,labels,CountVectorizer(),5)\n",
        "cv_score"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7618971041206746"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiDB13I898UU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count_vectorizer = CountVectorizer()\n",
        "count_vectorizer.fit(train)\n",
        "X_train_cv = count_vectorizer.transform(train)\n",
        "X_test_cv=  count_vectorizer.transform(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwXHpKqo-cFB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "9331d87e-7e36-4d08-c491-cd0f7a114370"
      },
      "source": [
        "cv_classifier = LogisticRegression(solver='lbfgs',C=c['logisticregression__C'],max_iter=500,class_weight=class_weights)\n",
        "cv_classifier.fit(X_train_cv, labels)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=10,\n",
              "                   class_weight={0: 0.6986892583120204, 1: 1.7582461786001609},\n",
              "                   dual=False, fit_intercept=True, intercept_scaling=1,\n",
              "                   l1_ratio=None, max_iter=500, multi_class='auto', n_jobs=None,\n",
              "                   penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
              "                   verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBx50ckVP6iP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv_test=cv_classifier.predict_proba(X_test_cv)[:,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJDyK1lahqqG",
        "colab_type": "text"
      },
      "source": [
        "## TF IDF word vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gz1WZZEufmEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "word_vectorizer = TfidfVectorizer(\n",
        "    sublinear_tf=True,\n",
        "    strip_accents='unicode',\n",
        "    analyzer='word',\n",
        "    token_pattern=r'\\w{1,}',\n",
        "    ngram_range=(1, 4),\n",
        "    max_features=10000)\n",
        "word_vectorizer.fit(train)\n",
        "train_word_features = word_vectorizer.transform(train)\n",
        "test_word_features = word_vectorizer.transform(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8hxtqPQ_KxI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4192b069-8df9-4895-a8b7-938bab2b76de"
      },
      "source": [
        "tfw_score,c=logistic_param_selection(train,labels,word_vectorizer,5)\n",
        "tfw_score"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7476390254373333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04JmMwoEh4-d",
        "colab_type": "code",
        "outputId": "a8d41f4c-77a5-4dbf-b8d4-8013d20c3ef8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "tfw_classifier = LogisticRegression(solver='lbfgs',C=c['logisticregression__C'],max_iter=500)\n",
        "tfw_classifier.fit(train_word_features, labels)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQRy9oaBQIfV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfw_test = tfw_classifier.predict_proba(test_word_features)[:,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNSvwaG1ioq0",
        "colab_type": "text"
      },
      "source": [
        "## TF IDF char vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_kqct6jiBq1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "char_vectorizer = TfidfVectorizer(\n",
        "    sublinear_tf=True,\n",
        "    strip_accents='unicode',\n",
        "    analyzer='char',\n",
        "    ngram_range=(1, 6),\n",
        "    max_features=30000)\n",
        "char_vectorizer.fit(train)\n",
        "train_char_features = char_vectorizer.transform(train)\n",
        "test_char_features = char_vectorizer.transform(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBU8cBQVCiAI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "25e0d0fd-fa79-4805-e37e-5b2bc5e4b481"
      },
      "source": [
        "tfc_score,c=logistic_param_selection(train,labels,char_vectorizer,5)\n",
        "tfc_score"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8053877583841075"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYhzRPO0iRMb",
        "colab_type": "code",
        "outputId": "114a1456-10b6-4851-a17a-1b9abf4690a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "tfc_classifier = LogisticRegression(solver='lbfgs',C=c['logisticregression__C'],max_iter=500)\n",
        "tfc_classifier.fit(train_char_features, labels)\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpkjinLBXX7j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfc_test = tfc_classifier.predict_proba(test_char_features)[:,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6sOo5OtMQnL",
        "colab_type": "text"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jv2yPgQWL9de",
        "colab_type": "text"
      },
      "source": [
        "##GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXvqlGD0L-sx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_gru():\n",
        "  inp = Input(shape=(max_len,))\n",
        "  x = Embedding(num_words,embed_size,embeddings_initializer=Constant(embeddings),input_length=max_len,trainable=False)(inp)\n",
        "  x = SpatialDropout1D(0.1)(x)\n",
        "  x = Bidirectional(CuDNNLSTM(50, return_sequences=True))(x)\n",
        "  x, x_h, x_c = Bidirectional(CuDNNGRU(50, return_sequences=True, return_state = True))(x)\n",
        "  avg_pool = GlobalAveragePooling1D()(x)\n",
        "  max_pool = GlobalMaxPooling1D()(x)\n",
        "  conc = concatenate([avg_pool, x_h, max_pool])\n",
        "  outp = Dense(1, activation=\"sigmoid\")(conc)    \n",
        "  model = Model(inputs=inp, outputs=outp)\n",
        "  model.compile(loss=BinaryFocalLoss(gamma=2), optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7t_Ph6qafOQK",
        "colab_type": "text"
      },
      "source": [
        "## GRU attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyKea_xMkrmP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://github.com/zake7749/DeepToxic\n",
        "from keras.layers import Layer,Lambda\n",
        "from keras import initializers\n",
        "from keras.engine import InputSpec, Layer\n",
        "from keras import backend as K\n",
        "\n",
        "class AttentionWeightedAverage(Layer):\n",
        "    \"\"\"\n",
        "    Computes a weighted average of the different channels across timesteps.\n",
        "    Uses 1 parameter pr. channel to compute the attention value for a single timestep.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, return_attention=False, **kwargs):\n",
        "        self.init = initializers.get('uniform')\n",
        "        self.supports_masking = True\n",
        "        self.return_attention = return_attention\n",
        "        super(AttentionWeightedAverage, self).__init__(** kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.input_spec = [InputSpec(ndim=3)]\n",
        "        assert len(input_shape) == 3\n",
        "\n",
        "        self.W = self.add_weight(shape=(input_shape[2], 1),\n",
        "                                 name='{}_W'.format(self.name),\n",
        "                                 initializer=self.init)\n",
        "        self.trainable_weights = [self.W]\n",
        "        super(AttentionWeightedAverage, self).build(input_shape)\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        # computes a probability distribution over the timesteps\n",
        "        # uses 'max trick' for numerical stability\n",
        "        # reshape is done to avoid issue with Tensorflow\n",
        "        # and 1-dimensional weights\n",
        "        logits = K.dot(x, self.W)\n",
        "        x_shape = K.shape(x)\n",
        "        logits = K.reshape(logits, (x_shape[0], x_shape[1]))\n",
        "        ai = K.exp(logits - K.max(logits, axis=-1, keepdims=True))\n",
        "\n",
        "        # masked timesteps have zero weight\n",
        "        if mask is not None:\n",
        "            mask = K.cast(mask, K.floatx())\n",
        "            ai = ai * mask\n",
        "        att_weights = ai / (K.sum(ai, axis=1, keepdims=True) + K.epsilon())\n",
        "        weighted_input = x * K.expand_dims(att_weights)\n",
        "        result = K.sum(weighted_input, axis=1)\n",
        "        if self.return_attention:\n",
        "            return [result, att_weights]\n",
        "        return result\n",
        "\n",
        "    def get_output_shape_for(self, input_shape):\n",
        "        return self.compute_output_shape(input_shape)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        output_len = input_shape[2]\n",
        "        if self.return_attention:\n",
        "            return [(input_shape[0], output_len), (input_shape[0], input_shape[1])]\n",
        "        return (input_shape[0], output_len)\n",
        "\n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        if isinstance(input_mask, list):\n",
        "            return [None] * len(input_mask)\n",
        "        else:\n",
        "            return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hovBxS5jfRbn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_gru_attn():\n",
        "  inp = Input(shape=(max_len,))\n",
        "  x = Embedding(num_words,embed_size,embeddings_initializer=Constant(embeddings),input_length=max_len,trainable=False)(inp)\n",
        "  x = SpatialDropout1D(0.1)(x)\n",
        "  x = Bidirectional(CuDNNLSTM(50, return_sequences=True))(x)\n",
        "  x = Bidirectional(CuDNNGRU(50, return_sequences=True))(x)\n",
        "  avg_pool = GlobalAveragePooling1D()(x)\n",
        "  max_pool = GlobalMaxPooling1D()(x)\n",
        "  last = Lambda(lambda t: t[:, -1])(x)\n",
        "  attn = AttentionWeightedAverage()(x)\n",
        "  conc = concatenate([avg_pool,  max_pool,last,attn])\n",
        "  outp = Dense(1, activation=\"sigmoid\")(conc)    \n",
        "  model = Model(inputs=inp, outputs=outp)\n",
        "  model.compile(loss=BinaryFocalLoss(gamma=2), optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I34DRPLqTVru",
        "colab_type": "text"
      },
      "source": [
        "##TCN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-euqTedTWjY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tcn import TCN\n",
        "\n",
        "def wave_net_activation(x):\n",
        "    # type: (Layer) -> Layer\n",
        "    \"\"\"This method defines the activation used for WaveNet\n",
        "    described in https://deepmind.com/blog/wavenet-generative-model-raw-audio/\n",
        "    Args:\n",
        "        x: The layer we want to apply the activation to\n",
        "    Returns:\n",
        "        A new layer with the wavenet activation applied\n",
        "    \"\"\"\n",
        "    tanh_out = Activation('tanh')(x)\n",
        "    sigm_out = Activation('sigmoid')(x)\n",
        "    return keras.layers.multiply([tanh_out, sigm_out])\n",
        "\n",
        "def model_tcn(embedding_matrix):\n",
        "    \n",
        "    inp = Input(shape=(max_len,))\n",
        "    x = Embedding(num_words,embed_size,embeddings_initializer=Constant(embeddings),input_length=max_len,trainable=False)(inp)\n",
        "    x = SpatialDropout1D(0.1)(x)\n",
        "    x = TCN(128,dilations = [1, 2, 4], return_sequences=True ,name = 'tnc1')(x)\n",
        "    x = wave_net_activation(x)\n",
        "    x = TCN(64,dilations = [1, 2, 4], return_sequences=True, name = 'tnc2')(x)\n",
        "    x = wave_net_activation(x)\n",
        "    #x = TCN(32,dilations = [1, 2, 4], return_sequences=True, activation = 'wavenet',name = 'tnc3')(x)\n",
        "    avg_pool = GlobalAveragePooling1D()(x)\n",
        "    max_pool = GlobalMaxPooling1D()(x)\n",
        "    \n",
        "    conc = concatenate([avg_pool, max_pool])\n",
        "    conc = Dense(64, activation=\"relu\")(conc)\n",
        "    conc = Dense(32, activation=\"relu\")(conc)\n",
        "\n",
        "    conc = Dropout(0.1)(conc)\n",
        "    outp = Dense(1, activation=\"sigmoid\")(conc)    \n",
        "    model = Model(inputs=inp, outputs=outp)\n",
        "    model.compile(loss=BinaryFocalLoss(gamma=2), optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wLyuzTtMErl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d55WTNmBa5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNc6xxspBcTG",
        "colab_type": "text"
      },
      "source": [
        "##KIM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAgtTt9IBfMQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_filters=128\n",
        "def model_kim():\n",
        "  inp = Input(shape=(max_len,))\n",
        "  emb = Embedding(num_words,embed_size,embeddings_initializer=Constant(embeddings),input_length=max_len,trainable=False)(inp)\n",
        "  # Specify each convolution layer and their kernel siz i.e. n-grams \n",
        "  conv1_1 = Conv1D(filters=conv_filters, kernel_size=3)(emb)\n",
        "  btch1_1 = BatchNormalization()(conv1_1)\n",
        "  drp1_1  = Dropout(0.2)(btch1_1)\n",
        "  actv1_1 = Activation('relu')(drp1_1)\n",
        "  glmp1_1 = GlobalMaxPooling1D()(actv1_1)\n",
        "\n",
        "  conv1_2 = Conv1D(filters=conv_filters, kernel_size=4)(emb)\n",
        "  btch1_2 = BatchNormalization()(conv1_2)\n",
        "  drp1_2  = Dropout(0.2)(btch1_2)\n",
        "  actv1_2 = Activation('relu')(drp1_2)\n",
        "  glmp1_2 = GlobalMaxPooling1D()(actv1_2)\n",
        "\n",
        "  conv1_3 = Conv1D(filters=conv_filters, kernel_size=5)(emb)\n",
        "  btch1_3 = BatchNormalization()(conv1_3)\n",
        "  drp1_3  = Dropout(0.2)(btch1_3)\n",
        "  actv1_3 = Activation('relu')(drp1_3)\n",
        "  glmp1_3 = GlobalMaxPooling1D()(actv1_3)\n",
        "\n",
        "  conv1_4 = Conv1D(filters=conv_filters, kernel_size=6)(emb)\n",
        "  btch1_4 = BatchNormalization()(conv1_4)\n",
        "  drp1_4  = Dropout(0.2)(btch1_4)\n",
        "  actv1_4 = Activation('relu')(drp1_4)\n",
        "  glmp1_4 = GlobalMaxPooling1D()(actv1_4)\n",
        "\n",
        "  # Gather all convolution layers\n",
        "  cnct = concatenate([glmp1_1, glmp1_2, glmp1_3, glmp1_4], axis=1)\n",
        "  drp1 = Dropout(0.2)(cnct)\n",
        "\n",
        "  dns1  = Dense(32, activation='relu')(drp1)\n",
        "  btch1 = BatchNormalization()(dns1)\n",
        "  drp2  = Dropout(0.2)(btch1)\n",
        "\n",
        "  out = Dense(1, activation='sigmoid')(drp2)   \n",
        "  model = Model(inputs=inp, outputs=out)\n",
        "  model.compile(loss=BinaryFocalLoss(gamma=2), optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJCuBpqkNx8L",
        "colab_type": "text"
      },
      "source": [
        "# Train model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUygUis5N2yN",
        "colab_type": "text"
      },
      "source": [
        "##GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdwYL0fG3kQo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "17b32b14-c087-404a-fdb7-5ea77cbb42fa"
      },
      "source": [
        "kfold = StratifiedKFold(n_splits=5, shuffle=False, random_state=2020)\n",
        "gru_scores = []\n",
        "gru_test=[]\n",
        "for train, val in kfold.split(sequences_matrix, labels):\n",
        "  gru_model=model_gru()\n",
        "  \n",
        "  gru_model.fit(sequences_matrix[train], labels[train],batch_size=64,epochs=10,verbose=2,\n",
        "            validation_data=(sequences_matrix[val],labels[val]),callbacks=[clr,])\n",
        "  y_pred = gru_model.predict(sequences_matrix[val], batch_size=64, verbose=1)\n",
        "\n",
        "  gru_test.append(gru_model.predict(X_test_sequences, batch_size=64, verbose=1).ravel())\n",
        "\n",
        "  y_pred = (y_pred > 0.5)\n",
        "  f1=f1_score(labels[val], y_pred, average='macro')\n",
        "  gru_scores.append(f1)\n",
        "  keras.backend.clear_session()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 6993 samples, validate on 1749 samples\n",
            "Epoch 1/10\n",
            " - 22s - loss: 0.1426 - acc: 0.7309 - val_loss: 0.1365 - val_acc: 0.7399\n",
            "Epoch 2/10\n",
            " - 21s - loss: 0.1211 - acc: 0.7914 - val_loss: 0.1180 - val_acc: 0.8005\n",
            "Epoch 3/10\n",
            " - 22s - loss: 0.1086 - acc: 0.8254 - val_loss: 0.1150 - val_acc: 0.8050\n",
            "Epoch 4/10\n",
            " - 21s - loss: 0.1030 - acc: 0.8413 - val_loss: 0.1111 - val_acc: 0.8250\n",
            "Epoch 5/10\n",
            " - 22s - loss: 0.1022 - acc: 0.8434 - val_loss: 0.1105 - val_acc: 0.8285\n",
            "Epoch 6/10\n",
            " - 22s - loss: 0.0949 - acc: 0.8566 - val_loss: 0.1093 - val_acc: 0.8250\n",
            "Epoch 7/10\n",
            " - 21s - loss: 0.0918 - acc: 0.8614 - val_loss: 0.1108 - val_acc: 0.8239\n",
            "Epoch 8/10\n",
            " - 21s - loss: 0.0857 - acc: 0.8704 - val_loss: 0.1141 - val_acc: 0.8268\n",
            "Epoch 9/10\n",
            " - 21s - loss: 0.0819 - acc: 0.8736 - val_loss: 0.1187 - val_acc: 0.8222\n",
            "Epoch 10/10\n",
            " - 22s - loss: 0.0762 - acc: 0.8816 - val_loss: 0.1206 - val_acc: 0.8159\n",
            "1749/1749 [==============================] - 2s 1ms/step\n",
            "1544/1544 [==============================] - 2s 1ms/step\n",
            "Train on 6993 samples, validate on 1749 samples\n",
            "Epoch 1/10\n",
            " - 22s - loss: 0.1458 - acc: 0.7139 - val_loss: 0.1356 - val_acc: 0.7399\n",
            "Epoch 2/10\n",
            " - 21s - loss: 0.1229 - acc: 0.7819 - val_loss: 0.1167 - val_acc: 0.8062\n",
            "Epoch 3/10\n",
            " - 21s - loss: 0.1114 - acc: 0.8191 - val_loss: 0.1077 - val_acc: 0.8359\n",
            "Epoch 4/10\n",
            " - 21s - loss: 0.1052 - acc: 0.8334 - val_loss: 0.1038 - val_acc: 0.8496\n",
            "Epoch 5/10\n",
            " - 21s - loss: 0.1018 - acc: 0.8417 - val_loss: 0.1032 - val_acc: 0.8473\n",
            "Epoch 6/10\n",
            " - 21s - loss: 0.0982 - acc: 0.8481 - val_loss: 0.1043 - val_acc: 0.8473\n",
            "Epoch 7/10\n",
            " - 21s - loss: 0.0932 - acc: 0.8569 - val_loss: 0.1009 - val_acc: 0.8582\n",
            "Epoch 8/10\n",
            " - 21s - loss: 0.0907 - acc: 0.8606 - val_loss: 0.1026 - val_acc: 0.8525\n",
            "Epoch 9/10\n",
            " - 21s - loss: 0.0857 - acc: 0.8621 - val_loss: 0.1050 - val_acc: 0.8451\n",
            "Epoch 10/10\n",
            " - 21s - loss: 0.0794 - acc: 0.8805 - val_loss: 0.1095 - val_acc: 0.8456\n",
            "1749/1749 [==============================] - 2s 1ms/step\n",
            "1544/1544 [==============================] - 2s 1ms/step\n",
            "Train on 6994 samples, validate on 1748 samples\n",
            "Epoch 1/10\n",
            " - 22s - loss: 0.1431 - acc: 0.7253 - val_loss: 0.1280 - val_acc: 0.7786\n",
            "Epoch 2/10\n",
            " - 22s - loss: 0.1222 - acc: 0.7924 - val_loss: 0.1160 - val_acc: 0.7941\n",
            "Epoch 3/10\n",
            " - 21s - loss: 0.1090 - acc: 0.8263 - val_loss: 0.1094 - val_acc: 0.8261\n",
            "Epoch 4/10\n",
            " - 21s - loss: 0.1030 - acc: 0.8390 - val_loss: 0.1113 - val_acc: 0.8295\n",
            "Epoch 5/10\n",
            " - 21s - loss: 0.0983 - acc: 0.8484 - val_loss: 0.1053 - val_acc: 0.8347\n",
            "Epoch 6/10\n",
            " - 21s - loss: 0.0947 - acc: 0.8539 - val_loss: 0.1076 - val_acc: 0.8335\n",
            "Epoch 7/10\n",
            " - 21s - loss: 0.0905 - acc: 0.8593 - val_loss: 0.1105 - val_acc: 0.8364\n",
            "Epoch 8/10\n",
            " - 21s - loss: 0.0873 - acc: 0.8626 - val_loss: 0.1141 - val_acc: 0.8295\n",
            "Epoch 9/10\n",
            " - 21s - loss: 0.0828 - acc: 0.8730 - val_loss: 0.1114 - val_acc: 0.8398\n",
            "Epoch 10/10\n",
            " - 21s - loss: 0.0772 - acc: 0.8813 - val_loss: 0.1192 - val_acc: 0.8312\n",
            "1748/1748 [==============================] - 2s 1ms/step\n",
            "1544/1544 [==============================] - 2s 1ms/step\n",
            "Train on 6994 samples, validate on 1748 samples\n",
            "Epoch 1/10\n",
            " - 22s - loss: 0.1447 - acc: 0.7245 - val_loss: 0.1307 - val_acc: 0.7471\n",
            "Epoch 2/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-56ac51cbe0a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   gru_model.fit(sequences_matrix[train], labels[train],batch_size=64,epochs=10,verbose=2,\n\u001b[0;32m----> 8\u001b[0;31m             validation_data=(sequences_matrix[val],labels[val]),callbacks=[clr,])\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgru_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucuevMTN4VPS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "214afa52-f2a8-455c-e6b4-cb94060c6b72"
      },
      "source": [
        "len(gru_test),gru_test[0].shape,gru_scores"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, (1544,), [0.7615447019531065, 0.7915209790209792, 0.7875017256264282])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKKs8iWX570n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaW-Uq0Kldp4",
        "colab_type": "text"
      },
      "source": [
        "## GRU attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XULscbNL6FiP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5470e203-b2a6-4aae-e8bb-d0d2be939e9b"
      },
      "source": [
        "kfold = StratifiedKFold(n_splits=5, shuffle=False, random_state=2020)\n",
        "atten_scores = []\n",
        "atten_test=[]\n",
        "for train, val in kfold.split(sequences_matrix, labels):\n",
        "  attn_gru_model=model_gru_attn()\n",
        "  \n",
        "  attn_gru_model.fit(sequences_matrix[train], labels[train],batch_size=64,epochs=10,verbose=2,\n",
        "            validation_data=(sequences_matrix[val],labels[val]),callbacks=[clr,])\n",
        "  y_pred = attn_gru_model.predict(sequences_matrix[val], batch_size=64, verbose=1)\n",
        "\n",
        "  atten_test.append(attn_gru_model.predict(X_test_sequences, batch_size=64, verbose=1).ravel())\n",
        "\n",
        "  y_pred = (y_pred > 0.5)\n",
        "  f1=f1_score(labels[val], y_pred, average='macro')\n",
        "  atten_scores.append(f1)\n",
        "  keras.backend.clear_session()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 6993 samples, validate on 1749 samples\n",
            "Epoch 1/10\n",
            " - 23s - loss: 0.1447 - acc: 0.7297 - val_loss: 0.1310 - val_acc: 0.7519\n",
            "Epoch 2/10\n",
            " - 22s - loss: 0.1171 - acc: 0.8084 - val_loss: 0.1250 - val_acc: 0.7804\n",
            "Epoch 3/10\n",
            " - 22s - loss: 0.1073 - acc: 0.8350 - val_loss: 0.1106 - val_acc: 0.8216\n",
            "Epoch 4/10\n",
            " - 22s - loss: 0.1012 - acc: 0.8483 - val_loss: 0.1087 - val_acc: 0.8239\n",
            "Epoch 5/10\n",
            " - 22s - loss: 0.0953 - acc: 0.8573 - val_loss: 0.1180 - val_acc: 0.8193\n",
            "Epoch 6/10\n",
            " - 22s - loss: 0.0907 - acc: 0.8657 - val_loss: 0.1172 - val_acc: 0.8130\n",
            "Epoch 7/10\n",
            " - 22s - loss: 0.0889 - acc: 0.8674 - val_loss: 0.1144 - val_acc: 0.8107\n",
            "Epoch 8/10\n",
            " - 22s - loss: 0.0808 - acc: 0.8820 - val_loss: 0.1151 - val_acc: 0.8222\n",
            "Epoch 9/10\n",
            " - 22s - loss: 0.0739 - acc: 0.8906 - val_loss: 0.1173 - val_acc: 0.8210\n",
            "Epoch 10/10\n",
            " - 22s - loss: 0.0676 - acc: 0.9015 - val_loss: 0.1303 - val_acc: 0.7987\n",
            "1749/1749 [==============================] - 2s 1ms/step\n",
            "1544/1544 [==============================] - 2s 1ms/step\n",
            "Train on 6993 samples, validate on 1749 samples\n",
            "Epoch 1/10\n",
            " - 22s - loss: 0.1428 - acc: 0.7254 - val_loss: 0.1553 - val_acc: 0.7050\n",
            "Epoch 2/10\n",
            " - 22s - loss: 0.1198 - acc: 0.7988 - val_loss: 0.1094 - val_acc: 0.8330\n",
            "Epoch 3/10\n",
            " - 22s - loss: 0.1074 - acc: 0.8304 - val_loss: 0.1078 - val_acc: 0.8348\n",
            "Epoch 4/10\n",
            " - 22s - loss: 0.1057 - acc: 0.8347 - val_loss: 0.1077 - val_acc: 0.8388\n",
            "Epoch 5/10\n",
            " - 22s - loss: 0.0979 - acc: 0.8483 - val_loss: 0.1053 - val_acc: 0.8393\n",
            "Epoch 6/10\n",
            " - 22s - loss: 0.0947 - acc: 0.8539 - val_loss: 0.1023 - val_acc: 0.8542\n",
            "Epoch 7/10\n",
            " - 22s - loss: 0.0878 - acc: 0.8641 - val_loss: 0.1046 - val_acc: 0.8456\n",
            "Epoch 8/10\n",
            " - 22s - loss: 0.0838 - acc: 0.8680 - val_loss: 0.1112 - val_acc: 0.8445\n",
            "Epoch 9/10\n",
            " - 22s - loss: 0.0777 - acc: 0.8802 - val_loss: 0.1217 - val_acc: 0.8411\n",
            "Epoch 10/10\n",
            " - 22s - loss: 0.0719 - acc: 0.8890 - val_loss: 0.1261 - val_acc: 0.8422\n",
            "1749/1749 [==============================] - 2s 1ms/step\n",
            "1544/1544 [==============================] - 2s 1ms/step\n",
            "Train on 6994 samples, validate on 1748 samples\n",
            "Epoch 1/10\n",
            " - 23s - loss: 0.1462 - acc: 0.7195 - val_loss: 0.1286 - val_acc: 0.7454\n",
            "Epoch 2/10\n",
            " - 22s - loss: 0.1184 - acc: 0.8007 - val_loss: 0.1151 - val_acc: 0.8146\n",
            "Epoch 3/10\n",
            " - 22s - loss: 0.1064 - acc: 0.8359 - val_loss: 0.1069 - val_acc: 0.8324\n",
            "Epoch 4/10\n",
            " - 22s - loss: 0.1013 - acc: 0.8457 - val_loss: 0.1060 - val_acc: 0.8415\n",
            "Epoch 5/10\n",
            " - 22s - loss: 0.0972 - acc: 0.8473 - val_loss: 0.1061 - val_acc: 0.8432\n",
            "Epoch 6/10\n",
            " - 22s - loss: 0.0943 - acc: 0.8570 - val_loss: 0.1055 - val_acc: 0.8421\n",
            "Epoch 7/10\n",
            " - 22s - loss: 0.0910 - acc: 0.8627 - val_loss: 0.1072 - val_acc: 0.8364\n",
            "Epoch 8/10\n",
            " - 22s - loss: 0.0847 - acc: 0.8699 - val_loss: 0.1106 - val_acc: 0.8455\n",
            "Epoch 9/10\n",
            " - 22s - loss: 0.0813 - acc: 0.8809 - val_loss: 0.1101 - val_acc: 0.8421\n",
            "Epoch 10/10\n",
            " - 22s - loss: 0.0736 - acc: 0.8900 - val_loss: 0.1194 - val_acc: 0.8255\n",
            "1748/1748 [==============================] - 2s 1ms/step\n",
            "1544/1544 [==============================] - 2s 1ms/step\n",
            "Train on 6994 samples, validate on 1748 samples\n",
            "Epoch 1/10\n",
            " - 23s - loss: 0.1478 - acc: 0.7166 - val_loss: 0.1305 - val_acc: 0.7551\n",
            "Epoch 2/10\n",
            " - 22s - loss: 0.1173 - acc: 0.8010 - val_loss: 0.1092 - val_acc: 0.8370\n",
            "Epoch 3/10\n",
            " - 22s - loss: 0.1067 - acc: 0.8334 - val_loss: 0.1052 - val_acc: 0.8432\n",
            "Epoch 4/10\n",
            " - 22s - loss: 0.1033 - acc: 0.8410 - val_loss: 0.1047 - val_acc: 0.8444\n",
            "Epoch 5/10\n",
            " - 22s - loss: 0.0996 - acc: 0.8517 - val_loss: 0.1052 - val_acc: 0.8392\n",
            "Epoch 6/10\n",
            " - 22s - loss: 0.0937 - acc: 0.8589 - val_loss: 0.1025 - val_acc: 0.8495\n",
            "Epoch 7/10\n",
            " - 22s - loss: 0.0899 - acc: 0.8686 - val_loss: 0.1045 - val_acc: 0.8421\n",
            "Epoch 8/10\n",
            " - 22s - loss: 0.0824 - acc: 0.8762 - val_loss: 0.1056 - val_acc: 0.8421\n",
            "Epoch 9/10\n",
            " - 22s - loss: 0.0759 - acc: 0.8878 - val_loss: 0.1133 - val_acc: 0.8330\n",
            "Epoch 10/10\n",
            " - 22s - loss: 0.0695 - acc: 0.8963 - val_loss: 0.1216 - val_acc: 0.8295\n",
            "1748/1748 [==============================] - 2s 1ms/step\n",
            "1544/1544 [==============================] - 2s 1ms/step\n",
            "Train on 6994 samples, validate on 1748 samples\n",
            "Epoch 1/10\n",
            " - 22s - loss: 0.1456 - acc: 0.7202 - val_loss: 0.1266 - val_acc: 0.7740\n",
            "Epoch 2/10\n",
            " - 22s - loss: 0.1195 - acc: 0.7975 - val_loss: 0.1087 - val_acc: 0.8324\n",
            "Epoch 3/10\n",
            " - 22s - loss: 0.1060 - acc: 0.8340 - val_loss: 0.1080 - val_acc: 0.8307\n",
            "Epoch 4/10\n",
            " - 22s - loss: 0.1008 - acc: 0.8452 - val_loss: 0.1035 - val_acc: 0.8364\n",
            "Epoch 5/10\n",
            " - 22s - loss: 0.0975 - acc: 0.8517 - val_loss: 0.1042 - val_acc: 0.8352\n",
            "Epoch 6/10\n",
            " - 22s - loss: 0.0946 - acc: 0.8519 - val_loss: 0.1099 - val_acc: 0.8370\n",
            "Epoch 7/10\n",
            " - 22s - loss: 0.0902 - acc: 0.8633 - val_loss: 0.1083 - val_acc: 0.8347\n",
            "Epoch 8/10\n",
            " - 22s - loss: 0.0836 - acc: 0.8706 - val_loss: 0.1071 - val_acc: 0.8387\n",
            "Epoch 9/10\n",
            " - 22s - loss: 0.0773 - acc: 0.8779 - val_loss: 0.1141 - val_acc: 0.8421\n",
            "Epoch 10/10\n",
            " - 22s - loss: 0.0705 - acc: 0.8910 - val_loss: 0.1187 - val_acc: 0.8324\n",
            "1748/1748 [==============================] - 2s 1ms/step\n",
            "1544/1544 [==============================] - 2s 1ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vo1Ec10_FbH4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "11cf3e44-c23f-466d-a628-25fd78c02923"
      },
      "source": [
        "atten_scores \n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7580867236273789,\n",
              " 0.7878859782333587,\n",
              " 0.7814354159569282,\n",
              " 0.7843497671707436,\n",
              " 0.7720983774773584]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlFNurr4T1rh",
        "colab_type": "text"
      },
      "source": [
        "##TCN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKtfxHFBT2wB",
        "colab_type": "code",
        "outputId": "cea8e2d6-4526-49d4-b1ce-0791af879c27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "kfold = StratifiedKFold(n_splits=5, shuffle=False)\n",
        "tcn_scores = []\n",
        "tcn_test=[]\n",
        "for train, val in kfold.split(sequences_matrix, labels):\n",
        "  model=model_tcn(embeddings)\n",
        "  \n",
        "  model.fit(sequences_matrix[train], labels[train],batch_size=64,epochs=10,verbose=2,\n",
        "            validation_data=(sequences_matrix[val],labels[val]),callbacks=[clr,])\n",
        "  y_pred = model.predict(sequences_matrix[val], batch_size=64, verbose=1)\n",
        "\n",
        "  tcn_test.append(model.predict(X_test_sequences, batch_size=64, verbose=1).ravel())\n",
        "\n",
        "  y_pred = (y_pred > 0.5)\n",
        "  f1=f1_score(labels[val], y_pred, average='macro')\n",
        "  tcn_scores.append(f1)\n",
        "  keras.backend.clear_session()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 6993 samples, validate on 1749 samples\n",
            "Epoch 1/10\n",
            " - 11s - loss: 0.1507 - acc: 0.7109 - val_loss: 0.1294 - val_acc: 0.7530\n",
            "Epoch 2/10\n",
            " - 7s - loss: 0.1178 - acc: 0.8125 - val_loss: 0.1191 - val_acc: 0.8022\n",
            "Epoch 3/10\n",
            " - 7s - loss: 0.1119 - acc: 0.8335 - val_loss: 0.1150 - val_acc: 0.8142\n",
            "Epoch 4/10\n",
            " - 6s - loss: 0.1076 - acc: 0.8451 - val_loss: 0.1179 - val_acc: 0.8067\n",
            "Epoch 5/10\n",
            " - 6s - loss: 0.1090 - acc: 0.8400 - val_loss: 0.1315 - val_acc: 0.8027\n",
            "Epoch 6/10\n",
            " - 7s - loss: 0.1040 - acc: 0.8563 - val_loss: 0.1125 - val_acc: 0.8239\n",
            "Epoch 7/10\n",
            " - 7s - loss: 0.1021 - acc: 0.8574 - val_loss: 0.1129 - val_acc: 0.8205\n",
            "Epoch 8/10\n",
            " - 6s - loss: 0.0992 - acc: 0.8593 - val_loss: 0.1154 - val_acc: 0.8210\n",
            "Epoch 9/10\n",
            " - 6s - loss: 0.0991 - acc: 0.8646 - val_loss: 0.1175 - val_acc: 0.8136\n",
            "Epoch 10/10\n",
            " - 6s - loss: 0.0934 - acc: 0.8703 - val_loss: 0.1172 - val_acc: 0.8262\n",
            "1749/1749 [==============================] - 1s 437us/step\n",
            "1544/1544 [==============================] - 1s 469us/step\n",
            "Train on 6993 samples, validate on 1749 samples\n",
            "Epoch 1/10\n",
            " - 8s - loss: 0.1509 - acc: 0.7086 - val_loss: 0.1277 - val_acc: 0.7736\n",
            "Epoch 2/10\n",
            " - 7s - loss: 0.1261 - acc: 0.7662 - val_loss: 0.1158 - val_acc: 0.8176\n",
            "Epoch 3/10\n",
            " - 7s - loss: 0.1199 - acc: 0.8047 - val_loss: 0.1188 - val_acc: 0.8348\n",
            "Epoch 4/10\n",
            " - 7s - loss: 0.1215 - acc: 0.7975 - val_loss: 0.1136 - val_acc: 0.8159\n",
            "Epoch 5/10\n",
            " - 7s - loss: 0.1156 - acc: 0.8210 - val_loss: 0.1055 - val_acc: 0.8508\n",
            "Epoch 6/10\n",
            " - 7s - loss: 0.1126 - acc: 0.8278 - val_loss: 0.1035 - val_acc: 0.8559\n",
            "Epoch 7/10\n",
            " - 7s - loss: 0.1109 - acc: 0.8357 - val_loss: 0.1070 - val_acc: 0.8479\n",
            "Epoch 8/10\n",
            " - 6s - loss: 0.1084 - acc: 0.8477 - val_loss: 0.1031 - val_acc: 0.8616\n",
            "Epoch 9/10\n",
            " - 7s - loss: 0.1103 - acc: 0.8381 - val_loss: 0.1060 - val_acc: 0.8405\n",
            "Epoch 10/10\n",
            " - 7s - loss: 0.1093 - acc: 0.8478 - val_loss: 0.1073 - val_acc: 0.8542\n",
            "1749/1749 [==============================] - 1s 439us/step\n",
            "1544/1544 [==============================] - 0s 300us/step\n",
            "Train on 6994 samples, validate on 1748 samples\n",
            "Epoch 1/10\n",
            " - 10s - loss: 0.1518 - acc: 0.7095 - val_loss: 0.1325 - val_acc: 0.7254\n",
            "Epoch 2/10\n",
            " - 7s - loss: 0.1214 - acc: 0.7944 - val_loss: 0.1270 - val_acc: 0.7380\n",
            "Epoch 3/10\n",
            " - 7s - loss: 0.1100 - acc: 0.8374 - val_loss: 0.1119 - val_acc: 0.8370\n",
            "Epoch 4/10\n",
            " - 7s - loss: 0.1076 - acc: 0.8426 - val_loss: 0.1059 - val_acc: 0.8490\n",
            "Epoch 5/10\n",
            " - 6s - loss: 0.1021 - acc: 0.8540 - val_loss: 0.1306 - val_acc: 0.8101\n",
            "Epoch 6/10\n",
            " - 6s - loss: 0.1014 - acc: 0.8564 - val_loss: 0.1166 - val_acc: 0.8152\n",
            "Epoch 7/10\n",
            " - 6s - loss: 0.1017 - acc: 0.8537 - val_loss: 0.1071 - val_acc: 0.8387\n",
            "Epoch 8/10\n",
            " - 6s - loss: 0.0989 - acc: 0.8607 - val_loss: 0.1068 - val_acc: 0.8421\n",
            "Epoch 9/10\n",
            " - 6s - loss: 0.0962 - acc: 0.8605 - val_loss: 0.1381 - val_acc: 0.7557\n",
            "Epoch 10/10\n",
            " - 6s - loss: 0.0969 - acc: 0.8620 - val_loss: 0.1058 - val_acc: 0.8375\n",
            "1748/1748 [==============================] - 1s 436us/step\n",
            "1544/1544 [==============================] - 0s 293us/step\n",
            "Train on 6994 samples, validate on 1748 samples\n",
            "Epoch 1/10\n",
            " - 8s - loss: 0.1540 - acc: 0.7073 - val_loss: 0.1406 - val_acc: 0.7157\n",
            "Epoch 2/10\n",
            " - 7s - loss: 0.1240 - acc: 0.7784 - val_loss: 0.1183 - val_acc: 0.7946\n",
            "Epoch 3/10\n",
            " - 7s - loss: 0.1137 - acc: 0.8234 - val_loss: 0.1400 - val_acc: 0.7809\n",
            "Epoch 4/10\n",
            " - 7s - loss: 0.1084 - acc: 0.8394 - val_loss: 0.1080 - val_acc: 0.8347\n",
            "Epoch 5/10\n",
            " - 6s - loss: 0.1053 - acc: 0.8472 - val_loss: 0.1067 - val_acc: 0.8370\n",
            "Epoch 6/10\n",
            " - 6s - loss: 0.1043 - acc: 0.8534 - val_loss: 0.1088 - val_acc: 0.8301\n",
            "Epoch 7/10\n",
            " - 6s - loss: 0.1009 - acc: 0.8563 - val_loss: 0.1052 - val_acc: 0.8444\n",
            "Epoch 8/10\n",
            " - 6s - loss: 0.0964 - acc: 0.8613 - val_loss: 0.1218 - val_acc: 0.8209\n",
            "Epoch 9/10\n",
            " - 6s - loss: 0.0965 - acc: 0.8602 - val_loss: 0.1057 - val_acc: 0.8392\n",
            "Epoch 10/10\n",
            " - 7s - loss: 0.0950 - acc: 0.8663 - val_loss: 0.1105 - val_acc: 0.8415\n",
            "1748/1748 [==============================] - 1s 438us/step\n",
            "1544/1544 [==============================] - 0s 294us/step\n",
            "Train on 6994 samples, validate on 1748 samples\n",
            "Epoch 1/10\n",
            " - 8s - loss: 0.1518 - acc: 0.7100 - val_loss: 0.1196 - val_acc: 0.7946\n",
            "Epoch 2/10\n",
            " - 6s - loss: 0.1199 - acc: 0.8023 - val_loss: 0.1185 - val_acc: 0.8101\n",
            "Epoch 3/10\n",
            " - 6s - loss: 0.1167 - acc: 0.8113 - val_loss: 0.1221 - val_acc: 0.8021\n",
            "Epoch 4/10\n",
            " - 6s - loss: 0.1141 - acc: 0.8236 - val_loss: 0.1071 - val_acc: 0.8450\n",
            "Epoch 5/10\n",
            " - 6s - loss: 0.1090 - acc: 0.8397 - val_loss: 0.1070 - val_acc: 0.8364\n",
            "Epoch 6/10\n",
            " - 6s - loss: 0.1034 - acc: 0.8520 - val_loss: 0.1049 - val_acc: 0.8473\n",
            "Epoch 7/10\n",
            " - 6s - loss: 0.1018 - acc: 0.8550 - val_loss: 0.1043 - val_acc: 0.8444\n",
            "Epoch 8/10\n",
            " - 6s - loss: 0.1007 - acc: 0.8536 - val_loss: 0.1081 - val_acc: 0.8375\n",
            "Epoch 9/10\n",
            " - 6s - loss: 0.0965 - acc: 0.8622 - val_loss: 0.1054 - val_acc: 0.8432\n",
            "Epoch 10/10\n",
            " - 6s - loss: 0.0949 - acc: 0.8622 - val_loss: 0.1030 - val_acc: 0.8490\n",
            "1748/1748 [==============================] - 1s 435us/step\n",
            "1544/1544 [==============================] - 0s 290us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tr_J6FWTCYXB",
        "colab_type": "text"
      },
      "source": [
        "##KIM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgmUF8liCa4M",
        "colab_type": "code",
        "outputId": "fce0713e-255e-41e7-ee64-15f04fdf0cae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "kfold = StratifiedKFold(n_splits=5, shuffle=False)\n",
        "kim_scores = []\n",
        "kim_test=[]\n",
        "for train, val in kfold.split(sequences_matrix, labels):\n",
        "  model=model_kim()\n",
        "  \n",
        "  model.fit(sequences_matrix[train], labels[train],batch_size=64,epochs=10,verbose=2,\n",
        "            validation_data=(sequences_matrix[val],labels[val]),callbacks=[clr,])\n",
        "  y_pred = model.predict(sequences_matrix[val], batch_size=64, verbose=1)\n",
        "\n",
        "  kim_test.append(model.predict(X_test_sequences, batch_size=64, verbose=1).ravel())\n",
        "\n",
        "  y_pred = (y_pred > 0.5)\n",
        "  f1=f1_score(labels[val], y_pred, average='macro')\n",
        "  kim_scores.append(f1)\n",
        "  keras.backend.clear_session()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 6993 samples, validate on 1749 samples\n",
            "Epoch 1/10\n",
            " - 7s - loss: 0.2148 - acc: 0.6429 - val_loss: 0.1439 - val_acc: 0.7136\n",
            "Epoch 2/10\n",
            " - 5s - loss: 0.1575 - acc: 0.7104 - val_loss: 0.1649 - val_acc: 0.7233\n",
            "Epoch 3/10\n",
            " - 5s - loss: 0.1341 - acc: 0.7632 - val_loss: 0.1280 - val_acc: 0.7581\n",
            "Epoch 4/10\n",
            " - 5s - loss: 0.1135 - acc: 0.8147 - val_loss: 0.1291 - val_acc: 0.7719\n",
            "Epoch 5/10\n",
            " - 5s - loss: 0.1032 - acc: 0.8355 - val_loss: 0.1288 - val_acc: 0.7690\n",
            "Epoch 6/10\n",
            " - 5s - loss: 0.0933 - acc: 0.8534 - val_loss: 0.1202 - val_acc: 0.7965\n",
            "Epoch 7/10\n",
            " - 5s - loss: 0.0839 - acc: 0.8653 - val_loss: 0.1566 - val_acc: 0.7822\n",
            "Epoch 8/10\n",
            " - 5s - loss: 0.0798 - acc: 0.8712 - val_loss: 0.1245 - val_acc: 0.8045\n",
            "Epoch 9/10\n",
            " - 5s - loss: 0.0719 - acc: 0.8879 - val_loss: 0.1197 - val_acc: 0.8056\n",
            "Epoch 10/10\n",
            " - 5s - loss: 0.0627 - acc: 0.9063 - val_loss: 0.1323 - val_acc: 0.8102\n",
            "1749/1749 [==============================] - 1s 345us/step\n",
            "1544/1544 [==============================] - 0s 232us/step\n",
            "Train on 6993 samples, validate on 1749 samples\n",
            "Epoch 1/10\n",
            " - 7s - loss: 0.2542 - acc: 0.6359 - val_loss: 0.1496 - val_acc: 0.7273\n",
            "Epoch 2/10\n",
            " - 5s - loss: 0.1646 - acc: 0.7111 - val_loss: 0.1482 - val_acc: 0.7490\n",
            "Epoch 3/10\n",
            " - 5s - loss: 0.1408 - acc: 0.7546 - val_loss: 0.1275 - val_acc: 0.7747\n",
            "Epoch 4/10\n",
            " - 5s - loss: 0.1254 - acc: 0.7879 - val_loss: 0.1355 - val_acc: 0.7662\n",
            "Epoch 5/10\n",
            " - 5s - loss: 0.1112 - acc: 0.8170 - val_loss: 0.1448 - val_acc: 0.7541\n",
            "Epoch 6/10\n",
            " - 5s - loss: 0.1008 - acc: 0.8354 - val_loss: 0.1382 - val_acc: 0.7753\n",
            "Epoch 7/10\n",
            " - 5s - loss: 0.0893 - acc: 0.8543 - val_loss: 0.1151 - val_acc: 0.8113\n",
            "Epoch 8/10\n",
            " - 5s - loss: 0.0828 - acc: 0.8703 - val_loss: 0.1284 - val_acc: 0.8170\n",
            "Epoch 9/10\n",
            " - 5s - loss: 0.0735 - acc: 0.8846 - val_loss: 0.1431 - val_acc: 0.7976\n",
            "Epoch 10/10\n",
            " - 5s - loss: 0.0704 - acc: 0.8922 - val_loss: 0.1545 - val_acc: 0.8073\n",
            "1749/1749 [==============================] - 1s 330us/step\n",
            "1544/1544 [==============================] - 0s 209us/step\n",
            "Train on 6994 samples, validate on 1748 samples\n",
            "Epoch 1/10\n",
            " - 7s - loss: 0.2249 - acc: 0.6440 - val_loss: 0.1496 - val_acc: 0.7254\n",
            "Epoch 2/10\n",
            " - 5s - loss: 0.1577 - acc: 0.7212 - val_loss: 0.1599 - val_acc: 0.7248\n",
            "Epoch 3/10\n",
            " - 5s - loss: 0.1387 - acc: 0.7568 - val_loss: 0.1244 - val_acc: 0.7717\n",
            "Epoch 4/10\n",
            " - 5s - loss: 0.1201 - acc: 0.7980 - val_loss: 0.1588 - val_acc: 0.7426\n",
            "Epoch 5/10\n",
            " - 5s - loss: 0.1093 - acc: 0.8220 - val_loss: 0.1167 - val_acc: 0.8095\n",
            "Epoch 6/10\n",
            " - 5s - loss: 0.0951 - acc: 0.8479 - val_loss: 0.1466 - val_acc: 0.7077\n",
            "Epoch 7/10\n",
            " - 5s - loss: 0.0873 - acc: 0.8616 - val_loss: 0.1188 - val_acc: 0.8061\n",
            "Epoch 8/10\n",
            " - 5s - loss: 0.0815 - acc: 0.8717 - val_loss: 0.1296 - val_acc: 0.8015\n",
            "Epoch 9/10\n",
            " - 5s - loss: 0.0744 - acc: 0.8825 - val_loss: 0.1192 - val_acc: 0.8158\n",
            "Epoch 10/10\n",
            " - 5s - loss: 0.0669 - acc: 0.8966 - val_loss: 0.1328 - val_acc: 0.7981\n",
            "1748/1748 [==============================] - 1s 339us/step\n",
            "1544/1544 [==============================] - 0s 209us/step\n",
            "Train on 6994 samples, validate on 1748 samples\n",
            "Epoch 1/10\n",
            " - 7s - loss: 0.2638 - acc: 0.6250 - val_loss: 0.1463 - val_acc: 0.7157\n",
            "Epoch 2/10\n",
            " - 5s - loss: 0.1762 - acc: 0.6953 - val_loss: 0.1369 - val_acc: 0.7471\n",
            "Epoch 3/10\n",
            " - 5s - loss: 0.1449 - acc: 0.7502 - val_loss: 0.1455 - val_acc: 0.7500\n",
            "Epoch 4/10\n",
            " - 5s - loss: 0.1276 - acc: 0.7881 - val_loss: 0.1194 - val_acc: 0.7958\n",
            "Epoch 5/10\n",
            " - 5s - loss: 0.1088 - acc: 0.8186 - val_loss: 0.1155 - val_acc: 0.8089\n",
            "Epoch 6/10\n",
            " - 5s - loss: 0.0981 - acc: 0.8430 - val_loss: 0.1145 - val_acc: 0.8084\n",
            "Epoch 7/10\n",
            " - 5s - loss: 0.0897 - acc: 0.8566 - val_loss: 0.1151 - val_acc: 0.8095\n",
            "Epoch 8/10\n",
            " - 5s - loss: 0.0799 - acc: 0.8726 - val_loss: 0.1151 - val_acc: 0.8204\n",
            "Epoch 9/10\n",
            " - 5s - loss: 0.0749 - acc: 0.8855 - val_loss: 0.1220 - val_acc: 0.8135\n",
            "Epoch 10/10\n",
            " - 5s - loss: 0.0687 - acc: 0.8926 - val_loss: 0.1232 - val_acc: 0.8084\n",
            "1748/1748 [==============================] - 1s 350us/step\n",
            "1544/1544 [==============================] - 0s 207us/step\n",
            "Train on 6994 samples, validate on 1748 samples\n",
            "Epoch 1/10\n",
            " - 7s - loss: 0.2469 - acc: 0.6321 - val_loss: 0.1378 - val_acc: 0.7460\n",
            "Epoch 2/10\n",
            " - 5s - loss: 0.1633 - acc: 0.7056 - val_loss: 0.1368 - val_acc: 0.7506\n",
            "Epoch 3/10\n",
            " - 5s - loss: 0.1430 - acc: 0.7462 - val_loss: 0.1246 - val_acc: 0.7775\n",
            "Epoch 4/10\n",
            " - 5s - loss: 0.1274 - acc: 0.7840 - val_loss: 0.1304 - val_acc: 0.7609\n",
            "Epoch 5/10\n",
            " - 5s - loss: 0.1061 - acc: 0.8176 - val_loss: 0.1233 - val_acc: 0.7906\n",
            "Epoch 6/10\n",
            " - 5s - loss: 0.1000 - acc: 0.8409 - val_loss: 0.1232 - val_acc: 0.7878\n",
            "Epoch 7/10\n",
            " - 5s - loss: 0.0850 - acc: 0.8639 - val_loss: 0.1236 - val_acc: 0.7981\n",
            "Epoch 8/10\n",
            " - 5s - loss: 0.0801 - acc: 0.8739 - val_loss: 0.1458 - val_acc: 0.7803\n",
            "Epoch 9/10\n",
            " - 5s - loss: 0.0704 - acc: 0.8896 - val_loss: 0.1309 - val_acc: 0.8101\n",
            "Epoch 10/10\n",
            " - 5s - loss: 0.0648 - acc: 0.9022 - val_loss: 0.1609 - val_acc: 0.7981\n",
            "1748/1748 [==============================] - 1s 348us/step\n",
            "1544/1544 [==============================] - 0s 210us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bXDiFxJH5Ny",
        "colab_type": "text"
      },
      "source": [
        "#**Result**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXd8VkdPhAq2",
        "colab_type": "text"
      },
      "source": [
        "# Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnC41n_HRKQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gru_scores=np.average(np.array(gru_scores))\n",
        "atten_scores=np.average(np.array(atten_scores))\n",
        "tcn_scores=np.average(np.array(tcn_scores))\n",
        "kim_scores=np.average(np.array(kim_scores))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBp341Qog_uv",
        "colab_type": "code",
        "outputId": "845742d1-da23-4b76-da8d-58a82c6441d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "print('f1 score of count vec' ,cv_score)\n",
        "print('f1 score of word tfidf' ,tfw_score)\n",
        "print('f1 score of char tfidf' ,tfc_score)\n",
        "\n",
        "print('f1 score of RNN' ,gru_scores)\n",
        "print('f1 score of gated attention',atten_scores )\n",
        "print('f1 score of tcn',tcn_scores)\n",
        "print('f1 score of kim',kim_scores)\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1 score of count vec 0.7618971041206746\n",
            "f1 score of word tfidf 0.7476390254373333\n",
            "f1 score of char tfidf 0.8053877583841075\n",
            "f1 score of RNN 0.7816380941894702\n",
            "f1 score of gated attention 0.7767712524931536\n",
            "f1 score of tcn 0.7964015195898784\n",
            "f1 score of kim 0.7297346242775561\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipijYwvjJPyx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kim_test=np.mean(np.array(kim_test),axis=0)\n",
        "gru_test=np.mean(np.array(gru_test),axis=0)\n",
        "atten_test=np.mean(np.array(atten_test),axis=0)\n",
        "tcn_test=np.mean(np.array(tcn_test),axis=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAMx_NI2jltK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e1cca332-6bf8-4e23-e8db-cc29684f15c0"
      },
      "source": [
        "kim_test"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.33937392"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZ8CR7s1Qe18",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "e632e862-f179-477b-c0fc-9b024c434edc"
      },
      "source": [
        "print(cv_test[0:5])\n",
        "print(tfw_test[0:5])\n",
        "print(gru_test[0:5])\n",
        "print(atten_test[0:5])\n",
        "print(tfc_test[0:5])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4.54433136e-05 6.51318748e-01 7.38298486e-02 2.38964797e-01\n",
            " 9.54859876e-01]\n",
            "[0.14990879 0.56336977 0.07306603 0.29280732 0.79145125]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-e734a28798bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfw_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgru_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matten_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfc_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DW1OugTMEpZg",
        "colab_type": "text"
      },
      "source": [
        "# Ensemble"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6VT0aVcUIhm",
        "colab_type": "text"
      },
      "source": [
        "we will choose only those, having f1 greater than 0.7. Once they are selected, we will decode labels, and keep label according to mod"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wmQlS5LkZLi",
        "colab_type": "code",
        "outputId": "cae14603-7c50-49d0-b676-82997cf869f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "wt=gru_scores+atten_scores+cv_score+tfw_score+tfc_score\n",
        "wt"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.8733332346247393"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkCLYtxOcXCA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#i am bit changing the distribution in order to give more weightage to ml than dl\n",
        "y_test=gru_scores/wt * gru_test + atten_scores/wt * atten_test + cv_score/wt * cv_test + tfw_score/wt *tfw_test + tfc_score/wt *tfc_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzRAIebNSpMz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c10ae633-caa2-4102-e7bd-4bc7a707fc0c"
      },
      "source": [
        "y_test[0:5]"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.13661135, 0.41287787, 0.13734198, 0.22489777, 0.75703537])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9Pu0LvuZIf8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode(y_test):\n",
        "  y_test[y_test>0.5]=1\n",
        "  y_test[y_test<0.5]=0\n",
        "  y_test=y_test.astype('int16').ravel()\n",
        "\n",
        "  y_test=le.inverse_transform(y_test)\n",
        "  y_test=pd.DataFrame(y_test,columns=['label'])\n",
        "  y_test=pd.concat([ids, y_test['label']], axis=1)\n",
        "  return y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PgV77IYZRGP",
        "colab_type": "code",
        "outputId": "a5cb12aa-ba57-485d-91ff-95a44b3441ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "y_test=decode(y_test)\n",
        "y_test.head()\n",
        "\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2707</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2251</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9814</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8949</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6913</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id label\n",
              "0  2707   NOT\n",
              "1  2251   NOT\n",
              "2  9814   NOT\n",
              "3  8949   NOT\n",
              "4  6913   OFF"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8avMmBQvb_IR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dl57zICXM4c6",
        "colab_type": "text"
      },
      "source": [
        "# Submit file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LkCxvtfEnpl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHTCw4_jP_tr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test.to_csv('/content/weighted.csv',index=False,header=None)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tPo96DUz_EZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwKb7_NBWjAv",
        "colab_type": "text"
      },
      "source": [
        "# Reset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0Xi3s2KWlKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import keras\n",
        "# keras.backend.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T39YK5rbQBoT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}