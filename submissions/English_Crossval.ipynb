{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "English Crossval.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "FwKb7_NBWjAv"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/talhaanwarch/OffenseEval2020/blob/master/submissions/English_Crossval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRdg5W5ZgMhM",
        "colab_type": "code",
        "outputId": "20f0b2c5-4126-4cf2-c766-252463d26f90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uqG7k8lK3xz",
        "colab_type": "code",
        "outputId": "9e8853c3-94e0-4c51-9b21-8ee373303457",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "source": [
        "!pip install focal-loss\n",
        "!pip install keras-tcn==2.8.3"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting focal-loss\n",
            "  Downloading https://files.pythonhosted.org/packages/66/ed/17450291228192ad8595de4514c8ec28a587697b03c707d12d4af5b7f331/focal_loss-0.0.2-py3-none-any.whl\n",
            "Installing collected packages: focal-loss\n",
            "Successfully installed focal-loss-0.0.2\n",
            "Collecting keras-tcn==2.8.3\n",
            "  Downloading https://files.pythonhosted.org/packages/d4/c4/438c86b27ab11a79cc659d8d6878682c4eb80caa0c0b3d620740cef762f5/keras_tcn-2.8.3-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-tcn==2.8.3) (1.17.5)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-tcn==2.8.3) (2.2.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-tcn==2.8.3) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-tcn==2.8.3) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-tcn==2.8.3) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-tcn==2.8.3) (1.1.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-tcn==2.8.3) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras->keras-tcn==2.8.3) (1.0.8)\n",
            "Installing collected packages: keras-tcn\n",
            "Successfully installed keras-tcn-2.8.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPexfZvANVks",
        "colab_type": "code",
        "outputId": "94322377-0cc2-4b6d-c6df-b1739de45c62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "#Setup Kaggle DIR; copy json file ; chmod\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!ls ~/.kaggle"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7aFF3cjfahc",
        "colab_type": "code",
        "outputId": "576e2396-702d-4c22-a060-8771e615eed9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "#Install kaggle packages\n",
        "!pip install -q kaggle\n",
        "!pip install -q kaggle-cli"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 81kB 3.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.3MB 8.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 72.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 9.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 75.3MB/s \n",
            "\u001b[?25h  Building wheel for kaggle-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6RX82v8fh7a",
        "colab_type": "code",
        "outputId": "c7964880-2af7-4e85-b8cc-c7ab8a5ffec4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "source": [
        "#List Kaggle DataSets\n",
        "#!kaggle datasets list\n",
        "\n",
        "#List Kaggle Competitions\n",
        "\n",
        "!kaggle competitions list"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "ref                                                                deadline             category             reward  teamCount  userHasEntered  \n",
            "-----------------------------------------------------------------  -------------------  ---------------  ----------  ---------  --------------  \n",
            "digit-recognizer                                                   2030-01-01 00:00:00  Getting Started   Knowledge       2357           False  \n",
            "titanic                                                            2030-01-01 00:00:00  Getting Started   Knowledge      16555           False  \n",
            "house-prices-advanced-regression-techniques                        2030-01-01 00:00:00  Getting Started   Knowledge       4702           False  \n",
            "connectx                                                           2030-01-01 00:00:00  Getting Started   Knowledge        478           False  \n",
            "competitive-data-science-predict-future-sales                      2020-12-31 23:59:00  Playground            Kudos       5839           False  \n",
            "abstraction-and-reasoning-challenge                                2020-05-27 23:59:00  Research            $20,000        288           False  \n",
            "liverpool-ion-switching                                            2020-05-25 23:59:00  Research            $25,000        341           False  \n",
            "flower-classification-with-tpus                                    2020-05-11 23:59:00  Playground           Prizes        264           False  \n",
            "march-madness-analytics-2020                                       2020-04-06 23:59:00  Analytics           $25,000          0           False  \n",
            "deepfake-detection-challenge                                       2020-03-31 23:59:00  Featured         $1,000,000       1970           False  \n",
            "cat-in-the-dat-ii                                                  2020-03-31 23:59:00  Playground             Swag        764           False  \n",
            "imagenet-object-localization-challenge                             2020-03-26 23:59:00  Research          Knowledge         67           False  \n",
            "ds4g-environmental-insights-explorer                               2020-03-24 23:59:00  Analytics           $25,000          0           False  \n",
            "nlp-getting-started                                                2020-03-23 23:59:00  Getting Started     $10,000       3416            True  \n",
            "google-cloud-ncaa-march-madness-2020-division-1-womens-tournament  2020-03-20 15:00:00  Featured            $25,000        242           False  \n",
            "google-cloud-ncaa-march-madness-2020-division-1-mens-tournament    2020-03-19 15:00:00  Featured            $25,000        449           False  \n",
            "bengaliai-cv19                                                     2020-03-16 23:59:00  Research            $10,000       1705            True  \n",
            "google-quest-challenge                                             2020-02-10 23:59:00  Featured            $25,000       1571            True  \n",
            "tensorflow2-question-answering                                     2020-01-22 23:59:00  Featured            $50,000       1233           False  \n",
            "data-science-bowl-2019                                             2020-01-22 23:59:00  Featured           $160,000       3497           False  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vfsl78Mzfllo",
        "colab_type": "code",
        "outputId": "e55d90bb-afb0-4b28-fc3b-dd2a24bf6566",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "!kaggle competitions list -s nlp-getting-started\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "ref                             deadline             category          reward  teamCount  userHasEntered  \n",
            "------------------------------  -------------------  ---------------  -------  ---------  --------------  \n",
            "nlp-getting-started             2020-03-23 23:59:00  Getting Started  $10,000       3416            True  \n",
            "getting-started                 2012-02-26 00:00:00  Featured         $10,000          0           False  \n",
            "acm-sf-chapter-hackathon-small  2012-09-30 01:00:00  Research            $600         96           False  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpnA5-9Bf26F",
        "colab_type": "code",
        "outputId": "6e10725e-0b51-4922-9877-58c5a9cfb57b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "source": [
        "!kaggle competitions download -c nlp-getting-started"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/22.2k [00:00<?, ?B/s]\n",
            "100% 22.2k/22.2k [00:00<00:00, 8.51MB/s]\n",
            "Downloading train.csv to /content\n",
            "  0% 0.00/965k [00:00<?, ?B/s]\n",
            "100% 965k/965k [00:00<00:00, 64.3MB/s]\n",
            "Downloading test.csv to /content\n",
            "  0% 0.00/411k [00:00<?, ?B/s]\n",
            "100% 411k/411k [00:00<00:00, 136MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6Q3msMuLDpE",
        "colab_type": "text"
      },
      "source": [
        "# Import lib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpTHlh_QLDL7",
        "colab_type": "code",
        "outputId": "5a6c8b58-5747-45f2-9e81-396160e73e30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Embedding,CuDNNGRU,CuDNNLSTM,Dense,Dropout,Bidirectional,BatchNormalization,GlobalMaxPooling1D,Flatten, GlobalAveragePooling1D, MaxPooling1D,SpatialDropout1D,Input,Activation,concatenate,Conv1D\n",
        "from keras.optimizers import RMSprop,Adam,Adadelta\n",
        "from keras.initializers import Constant\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import classification_report,f1_score\n",
        "import keras\n",
        "import collections\n",
        "import numpy as np\n",
        "from focal_loss import BinaryFocalLoss\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from keras import backend as K\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Udk8qWz-K4cx",
        "colab_type": "text"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMbpcevIl7g9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
        "stop = stopwords.words('english')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jnd4B-_5LApL",
        "colab_type": "code",
        "outputId": "ad4732ff-58e8-4a26-c5b7-04739aaed73e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "train=pd.read_csv( '/content/train.csv')\n",
        "train.head()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YY8MVlxhggiD",
        "colab_type": "code",
        "outputId": "bea1558c-7d32-4912-f8d1-9a63d716adc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        }
      },
      "source": [
        "\n",
        "train['text']=train['text'].str.replace('\\d+', '')\n",
        "train[\"text\"]= train[\"text\"].str.lower()\n",
        "train[\"text\"] = train[\"text\"].str.replace('[^\\w\\s]','')\n",
        "train[\"text\"] = train[\"text\"].apply(lambda x : [lemmatizer.lemmatize(y) for y in w_tokenizer.tokenize(x)])\n",
        "train[\"text\"] = train[\"text\"].apply(lambda x: [item for item in x if item not in stop])\n",
        "train[\"text\"] = train[\"text\"].apply(lambda x : \" \".join(x))\n",
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-e925bb50c496>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\d+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[^\\w\\s]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlemmatizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mw_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1069\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4728\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"getitem\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4729\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4730\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4731\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4732\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'text'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdwHh_q_LLus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test=pd.read_csv( '/content/test.csv')\n",
        "test['text']=test['text'].str.replace('\\d+', '')\n",
        "test[\"text\"]= test[\"text\"].str.lower()\n",
        "test[\"text\"] = test[\"text\"].str.replace('[^\\w\\s]','')\n",
        "test[\"text\"] = test[\"text\"].apply(lambda x : [lemmatizer.lemmatize(y) for y in w_tokenizer.tokenize(x)])\n",
        "test[\"text\"] = test[\"text\"].apply(lambda x: [item for item in x if item not in stop])\n",
        "test[\"text\"] = test[\"text\"].apply(lambda x : \" \".join(x))\n",
        "test=test[\"text\"] \n",
        "test.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUFczyikLeYO",
        "colab_type": "text"
      },
      "source": [
        "#Label Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFPv0_zdLnlS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels=train['target']\n",
        "train=train['text']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9PjbFwJLiNA",
        "colab_type": "code",
        "outputId": "067e81c2-b674-4ccc-eb7d-2cab43005536",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "le=LabelEncoder()\n",
        "labels=le.fit_transform(labels)\n",
        "print(len(labels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7613\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ek_ZUjDef7ZV",
        "colab_type": "text"
      },
      "source": [
        "# Common Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdtjDLnOACbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "class_weights = class_weight.compute_class_weight('balanced',np.unique(labels),labels)\n",
        "class_weights=dict(enumerate(class_weights))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-IToeBciV1m",
        "colab_type": "text"
      },
      "source": [
        "## Cylic learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIYW6ZAniXzU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://www.kaggle.com/hireme/fun-api-keras-f1-metric-cyclical-learning-rate/code\n",
        "from keras.callbacks import Callback\n",
        "class CyclicLR(Callback):\n",
        "    \"\"\"This callback implements a cyclical learning rate policy (CLR).\n",
        "    The method cycles the learning rate between two boundaries with\n",
        "    some constant frequency, as detailed in this paper (https://arxiv.org/abs/1506.01186).\n",
        "    The amplitude of the cycle can be scaled on a per-iteration or \n",
        "    per-cycle basis.\n",
        "    This class has three built-in policies, as put forth in the paper.\n",
        "    \"triangular\":\n",
        "        A basic triangular cycle w/ no amplitude scaling.\n",
        "    \"triangular2\":\n",
        "        A basic triangular cycle that scales initial amplitude by half each cycle.\n",
        "    \"exp_range\":\n",
        "        A cycle that scales initial amplitude by gamma**(cycle iterations) at each \n",
        "        cycle iteration.\n",
        "    For more detail, please see paper.\n",
        "    \n",
        "    # Example\n",
        "        ```python\n",
        "            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
        "                                step_size=2000., mode='triangular')\n",
        "            model.fit(X_train, Y_train, callbacks=[clr])\n",
        "        ```\n",
        "    \n",
        "    Class also supports custom scaling functions:\n",
        "        ```python\n",
        "            clr_fn = lambda x: 0.5*(1+np.sin(x*np.pi/2.))\n",
        "            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
        "                                step_size=2000., scale_fn=clr_fn,\n",
        "                                scale_mode='cycle')\n",
        "            model.fit(X_train, Y_train, callbacks=[clr])\n",
        "        ```    \n",
        "    # Arguments\n",
        "        base_lr: initial learning rate which is the\n",
        "            lower boundary in the cycle.\n",
        "        max_lr: upper boundary in the cycle. Functionally,\n",
        "            it defines the cycle amplitude (max_lr - base_lr).\n",
        "            The lr at any cycle is the sum of base_lr\n",
        "            and some scaling of the amplitude; therefore \n",
        "            max_lr may not actually be reached depending on\n",
        "            scaling function.\n",
        "        step_size: number of training iterations per\n",
        "            half cycle. Authors suggest setting step_size\n",
        "            2-8 x training iterations in epoch.\n",
        "        mode: one of {triangular, triangular2, exp_range}.\n",
        "            Default 'triangular'.\n",
        "            Values correspond to policies detailed above.\n",
        "            If scale_fn is not None, this argument is ignored.\n",
        "        gamma: constant in 'exp_range' scaling function:\n",
        "            gamma**(cycle iterations)\n",
        "        scale_fn: Custom scaling policy defined by a single\n",
        "            argument lambda function, where \n",
        "            0 <= scale_fn(x) <= 1 for all x >= 0.\n",
        "            mode paramater is ignored \n",
        "        scale_mode: {'cycle', 'iterations'}.\n",
        "            Defines whether scale_fn is evaluated on \n",
        "            cycle number or cycle iterations (training\n",
        "            iterations since start of cycle). Default is 'cycle'.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=2000., mode='triangular',\n",
        "                 gamma=1., scale_fn=None, scale_mode='cycle'):\n",
        "        super(CyclicLR, self).__init__()\n",
        "\n",
        "        self.base_lr = base_lr\n",
        "        self.max_lr = max_lr\n",
        "        self.step_size = step_size\n",
        "        self.mode = mode\n",
        "        self.gamma = gamma\n",
        "        if scale_fn == None:\n",
        "            if self.mode == 'triangular':\n",
        "                self.scale_fn = lambda x: 1.\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'triangular2':\n",
        "                self.scale_fn = lambda x: 1/(2.**(x-1))\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'exp_range':\n",
        "                self.scale_fn = lambda x: gamma**(x)\n",
        "                self.scale_mode = 'iterations'\n",
        "        else:\n",
        "            self.scale_fn = scale_fn\n",
        "            self.scale_mode = scale_mode\n",
        "        self.clr_iterations = 0.\n",
        "        self.trn_iterations = 0.\n",
        "        self.history = {}\n",
        "\n",
        "        self._reset()\n",
        "\n",
        "    def _reset(self, new_base_lr=None, new_max_lr=None,\n",
        "               new_step_size=None):\n",
        "        \"\"\"Resets cycle iterations.\n",
        "        Optional boundary/step size adjustment.\n",
        "        \"\"\"\n",
        "        if new_base_lr != None:\n",
        "            self.base_lr = new_base_lr\n",
        "        if new_max_lr != None:\n",
        "            self.max_lr = new_max_lr\n",
        "        if new_step_size != None:\n",
        "            self.step_size = new_step_size\n",
        "        self.clr_iterations = 0.\n",
        "        \n",
        "    def clr(self):\n",
        "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
        "        x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
        "        if self.scale_mode == 'cycle':\n",
        "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(cycle)\n",
        "        else:\n",
        "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(self.clr_iterations)\n",
        "        \n",
        "    def on_train_begin(self, logs={}):\n",
        "        logs = logs or {}\n",
        "\n",
        "        if self.clr_iterations == 0:\n",
        "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
        "        else:\n",
        "            K.set_value(self.model.optimizer.lr, self.clr())        \n",
        "            \n",
        "    def on_batch_end(self, epoch, logs=None):\n",
        "        \n",
        "        logs = logs or {}\n",
        "        self.trn_iterations += 1\n",
        "        self.clr_iterations += 1\n",
        "\n",
        "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
        "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
        "\n",
        "        for k, v in logs.items():\n",
        "            self.history.setdefault(k, []).append(v)\n",
        "        \n",
        "        K.set_value(self.model.optimizer.lr, self.clr())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIcxIjeYjHyo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clr = CyclicLR(base_lr=0.001, max_lr=0.005,\n",
        "                        step_size=4., mode='exp_range',\n",
        "                        gamma=0.99994)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAv_EEaQLXtY",
        "colab_type": "text"
      },
      "source": [
        "# Tokenize data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QomCkNlRLHPG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "max_words = 10000 #frequency of words to be kept\n",
        "max_len = 200\n",
        "\n",
        "tokenize = Tokenizer(num_words=max_words)\n",
        "tokenize.fit_on_texts(train)\n",
        "sequences = tokenize.texts_to_sequences(train)\n",
        "word_index = tokenize.word_index\n",
        "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len,padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og1W2rCOLs4w",
        "colab_type": "code",
        "outputId": "8cf0f2fa-0b01-42a5-b445-5c289cdb11b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "len(sequences_matrix),len(labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 7613)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4kzu1RxLyGk",
        "colab_type": "code",
        "outputId": "361a4e6f-4683-4606-8fce-7c565e11d886",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "num_words = min(max_words, len(word_index)) + 1\n",
        "print(num_words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4i7WSY3lMmdp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_sequences = tokenize.texts_to_sequences(test)\n",
        "X_test_sequences = sequence.pad_sequences(test_sequences,maxlen=max_len,padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRZxav1WNle-",
        "colab_type": "code",
        "outputId": "f4abf513-f39b-4beb-ca39-5b7b769eee83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "len(X_test_sequences)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3263"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpzUIu4iL0PO",
        "colab_type": "text"
      },
      "source": [
        "# Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UASiPIPlnZKP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_path1 = \"drive/My Drive/dataset/OLID/wiki-news-300d-1M.vec\"\n",
        "embedding_path2 = \"drive/My Drive/dataset/OLID/glove/glove.840B.300d.txt\"\n",
        "embed_size = 300"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3UFPJAWL10_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_coefs(word,*arr):\n",
        "    return word, np.asarray(arr, dtype='float32')\n",
        "\n",
        "def build_matrix(embedding_path, word_index):\n",
        "    embedding_index = dict(get_coefs(*o.strip().split(\" \")) for o in open(embedding_path))\n",
        "\n",
        "    nb_words = min(max_words, len(word_index))\n",
        "    embedding_matrix = np.zeros((nb_words + 1, embed_size))\n",
        "    for word, i in word_index.items():\n",
        "        if i >= max_words:\n",
        "            continue\n",
        "        embedding_vector = embedding_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "    return embedding_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTviPXodLzRW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fasttext=build_matrix(embedding_path1, word_index)\n",
        "glove_emb=build_matrix(embedding_path2, word_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWgNaYzPnf2C",
        "colab_type": "code",
        "outputId": "62b2815d-a14c-4142-9f06-f1ebab029e82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "embeddings=np.mean((fasttext,glove_emb),axis=0)\n",
        "embeddings.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10001, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8_AdRhffkS3",
        "colab_type": "text"
      },
      "source": [
        "# Base Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaShFhtgJ_Ef",
        "colab_type": "code",
        "outputId": "8998f7dc-dfec-4c56-b82e-c3128cf28cc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "train.shape,labels.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((7613,), (7613,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvXD0v5mfm7M",
        "colab_type": "text"
      },
      "source": [
        "## Count Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7blhzyaD-xvK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def logistic_param_selection(X, y, func,nfolds):\n",
        "    C= [7,8,9,10,12,15,20,25]\n",
        "    param_grid = {'C': C}\n",
        "    grid_search = GridSearchCV(make_pipeline(func, LogisticRegression(solver='lbfgs',max_iter=500,class_weight=class_weights)),\n",
        "                    param_grid={'logisticregression__C':C}, cv=nfolds,scoring='f1_macro')\n",
        "    grid_search.fit(X, y)\n",
        "    return grid_search.best_score_,grid_search.best_params_\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHFZoqkGI79e",
        "colab_type": "code",
        "outputId": "305d02e8-5b60-4136-bc1c-dfff32c1b272",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "cv_score,c=logistic_param_selection(train,labels,CountVectorizer(),5)\n",
        "cv_score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6789070385269321"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiDB13I898UU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count_vectorizer = CountVectorizer()\n",
        "count_vectorizer.fit(train)\n",
        "X_train_cv = count_vectorizer.transform(train)\n",
        "X_test_cv=  count_vectorizer.transform(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwXHpKqo-cFB",
        "colab_type": "code",
        "outputId": "6c56058c-f9d6-4bb3-9bd2-2b10361aef0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "cv_classifier = LogisticRegression(solver='lbfgs',C=c['logisticregression__C'],max_iter=500,class_weight=class_weights)\n",
        "cv_classifier.fit(X_train_cv, labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=7,\n",
              "                   class_weight={0: 0.8766697374481806, 1: 1.1637114032405993},\n",
              "                   dual=False, fit_intercept=True, intercept_scaling=1,\n",
              "                   l1_ratio=None, max_iter=500, multi_class='auto', n_jobs=None,\n",
              "                   penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
              "                   verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBx50ckVP6iP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv_test=cv_classifier.predict_proba(X_test_cv)[:,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJDyK1lahqqG",
        "colab_type": "text"
      },
      "source": [
        "## TF IDF word vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gz1WZZEufmEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "word_vectorizer = TfidfVectorizer(\n",
        "    sublinear_tf=True,\n",
        "    strip_accents='unicode',\n",
        "    analyzer='word',\n",
        "    token_pattern=r'\\w{1,}',\n",
        "    ngram_range=(1, 4),\n",
        "    max_features=10000)\n",
        "word_vectorizer.fit(pd.concat([train, test]))\n",
        "train_word_features = word_vectorizer.transform(train)\n",
        "test_word_features = word_vectorizer.transform(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8hxtqPQ_KxI",
        "colab_type": "code",
        "outputId": "e2449e2e-4835-407c-8e31-be1d77dfd0bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "tfw_score,c=logistic_param_selection(train,labels,word_vectorizer,5)\n",
        "tfw_score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6814031008661787"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04JmMwoEh4-d",
        "colab_type": "code",
        "outputId": "d7c72ee9-6745-4cfd-e7be-49d6aea7571e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "source": [
        "tfw_classifier = LogisticRegression(solver='lbfgs',C=c['logisticregression__C'],max_iter=500)\n",
        "tfw_classifier.fit(train_word_features, labels)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=7, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQRy9oaBQIfV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfw_test = tfw_classifier.predict_proba(test_word_features)[:,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNSvwaG1ioq0",
        "colab_type": "text"
      },
      "source": [
        "## TF IDF char vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_kqct6jiBq1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "char_vectorizer = TfidfVectorizer(\n",
        "    sublinear_tf=True,\n",
        "    strip_accents='unicode',\n",
        "    analyzer='char',\n",
        "    ngram_range=(1, 6),\n",
        "    max_features=30000)\n",
        "char_vectorizer.fit(train)\n",
        "train_char_features = char_vectorizer.transform(train)\n",
        "test_char_features = char_vectorizer.transform(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBU8cBQVCiAI",
        "colab_type": "code",
        "outputId": "2ac8b886-d976-43fe-f944-e6728a531f88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "tfc_score,c=logistic_param_selection(train,labels,char_vectorizer,5)\n",
        "tfc_score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6909844962829798"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYhzRPO0iRMb",
        "colab_type": "code",
        "outputId": "d2f35356-fa57-4350-d1cd-253ef17e7f52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "source": [
        "tfc_classifier = LogisticRegression(solver='lbfgs',C=c['logisticregression__C'],max_iter=500)\n",
        "tfc_classifier.fit(train_char_features, labels)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=7, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpkjinLBXX7j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfc_test = tfc_classifier.predict_proba(test_char_features)[:,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6sOo5OtMQnL",
        "colab_type": "text"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jv2yPgQWL9de",
        "colab_type": "text"
      },
      "source": [
        "##GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXvqlGD0L-sx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_gru():\n",
        "  inp = Input(shape=(max_len,))\n",
        "  x = Embedding(num_words,embed_size,embeddings_initializer=Constant(embeddings),input_length=max_len,trainable=False)(inp)\n",
        "  x = SpatialDropout1D(0.1)(x)\n",
        "  x = Bidirectional(CuDNNLSTM(50, return_sequences=True))(x)\n",
        "  x, x_h, x_c = Bidirectional(CuDNNGRU(50, return_sequences=True, return_state = True))(x)\n",
        "  avg_pool = GlobalAveragePooling1D()(x)\n",
        "  max_pool = GlobalMaxPooling1D()(x)\n",
        "  conc = concatenate([avg_pool, x_h, max_pool])\n",
        "  outp = Dense(1, activation=\"sigmoid\")(conc)    \n",
        "  model = Model(inputs=inp, outputs=outp)\n",
        "  model.compile(loss=BinaryFocalLoss(gamma=2), optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7t_Ph6qafOQK",
        "colab_type": "text"
      },
      "source": [
        "## GRU attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyKea_xMkrmP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://github.com/zake7749/DeepToxic\n",
        "from keras.layers import Layer,Lambda\n",
        "from keras import initializers\n",
        "from keras.engine import InputSpec, Layer\n",
        "from keras import backend as K\n",
        "\n",
        "class AttentionWeightedAverage(Layer):\n",
        "    \"\"\"\n",
        "    Computes a weighted average of the different channels across timesteps.\n",
        "    Uses 1 parameter pr. channel to compute the attention value for a single timestep.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, return_attention=False, **kwargs):\n",
        "        self.init = initializers.get('uniform')\n",
        "        self.supports_masking = True\n",
        "        self.return_attention = return_attention\n",
        "        super(AttentionWeightedAverage, self).__init__(** kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.input_spec = [InputSpec(ndim=3)]\n",
        "        assert len(input_shape) == 3\n",
        "\n",
        "        self.W = self.add_weight(shape=(input_shape[2], 1),\n",
        "                                 name='{}_W'.format(self.name),\n",
        "                                 initializer=self.init)\n",
        "        self.trainable_weights = [self.W]\n",
        "        super(AttentionWeightedAverage, self).build(input_shape)\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        # computes a probability distribution over the timesteps\n",
        "        # uses 'max trick' for numerical stability\n",
        "        # reshape is done to avoid issue with Tensorflow\n",
        "        # and 1-dimensional weights\n",
        "        logits = K.dot(x, self.W)\n",
        "        x_shape = K.shape(x)\n",
        "        logits = K.reshape(logits, (x_shape[0], x_shape[1]))\n",
        "        ai = K.exp(logits - K.max(logits, axis=-1, keepdims=True))\n",
        "\n",
        "        # masked timesteps have zero weight\n",
        "        if mask is not None:\n",
        "            mask = K.cast(mask, K.floatx())\n",
        "            ai = ai * mask\n",
        "        att_weights = ai / (K.sum(ai, axis=1, keepdims=True) + K.epsilon())\n",
        "        weighted_input = x * K.expand_dims(att_weights)\n",
        "        result = K.sum(weighted_input, axis=1)\n",
        "        if self.return_attention:\n",
        "            return [result, att_weights]\n",
        "        return result\n",
        "\n",
        "    def get_output_shape_for(self, input_shape):\n",
        "        return self.compute_output_shape(input_shape)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        output_len = input_shape[2]\n",
        "        if self.return_attention:\n",
        "            return [(input_shape[0], output_len), (input_shape[0], input_shape[1])]\n",
        "        return (input_shape[0], output_len)\n",
        "\n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        if isinstance(input_mask, list):\n",
        "            return [None] * len(input_mask)\n",
        "        else:\n",
        "            return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hovBxS5jfRbn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_gru_attn():\n",
        "  inp = Input(shape=(max_len,))\n",
        "  x = Embedding(num_words,embed_size,embeddings_initializer=Constant(embeddings),input_length=max_len,trainable=False)(inp)\n",
        "  x = SpatialDropout1D(0.1)(x)\n",
        "  x = Bidirectional(CuDNNLSTM(50, return_sequences=True))(x)\n",
        "  x = Bidirectional(CuDNNGRU(50, return_sequences=True))(x)\n",
        "  avg_pool = GlobalAveragePooling1D()(x)\n",
        "  max_pool = GlobalMaxPooling1D()(x)\n",
        "  last = Lambda(lambda t: t[:, -1])(x)\n",
        "  attn = AttentionWeightedAverage()(x)\n",
        "  conc = concatenate([avg_pool,  max_pool,last,attn])\n",
        "  outp = Dense(1, activation=\"sigmoid\")(conc)    \n",
        "  model = Model(inputs=inp, outputs=outp)\n",
        "  model.compile(loss=BinaryFocalLoss(gamma=2), optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I34DRPLqTVru",
        "colab_type": "text"
      },
      "source": [
        "##TCN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-euqTedTWjY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tcn import TCN\n",
        "\n",
        "def wave_net_activation(x):\n",
        "    # type: (Layer) -> Layer\n",
        "    \"\"\"This method defines the activation used for WaveNet\n",
        "    described in https://deepmind.com/blog/wavenet-generative-model-raw-audio/\n",
        "    Args:\n",
        "        x: The layer we want to apply the activation to\n",
        "    Returns:\n",
        "        A new layer with the wavenet activation applied\n",
        "    \"\"\"\n",
        "    tanh_out = Activation('tanh')(x)\n",
        "    sigm_out = Activation('sigmoid')(x)\n",
        "    return keras.layers.multiply([tanh_out, sigm_out])\n",
        "\n",
        "def model_tcn(embedding_matrix):\n",
        "    \n",
        "    inp = Input(shape=(max_len,))\n",
        "    x = Embedding(num_words,embed_size,embeddings_initializer=Constant(embeddings),input_length=max_len,trainable=False)(inp)\n",
        "    x = SpatialDropout1D(0.1)(x)\n",
        "    x = TCN(128,dilations = [1, 2, 4], return_sequences=True ,name = 'tnc1')(x)\n",
        "    x = wave_net_activation(x)\n",
        "    x = TCN(64,dilations = [1, 2, 4], return_sequences=True, name = 'tnc2')(x)\n",
        "    x = wave_net_activation(x)\n",
        "    #x = TCN(32,dilations = [1, 2, 4], return_sequences=True, activation = 'wavenet',name = 'tnc3')(x)\n",
        "    avg_pool = GlobalAveragePooling1D()(x)\n",
        "    max_pool = GlobalMaxPooling1D()(x)\n",
        "    \n",
        "    conc = concatenate([avg_pool, max_pool])\n",
        "    conc = Dense(64, activation=\"relu\")(conc)\n",
        "    conc = Dense(32, activation=\"relu\")(conc)\n",
        "\n",
        "    conc = Dropout(0.1)(conc)\n",
        "    outp = Dense(1, activation=\"sigmoid\")(conc)    \n",
        "    model = Model(inputs=inp, outputs=outp)\n",
        "    model.compile(loss=BinaryFocalLoss(gamma=2), optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wLyuzTtMErl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d55WTNmBa5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNc6xxspBcTG",
        "colab_type": "text"
      },
      "source": [
        "##KIM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAgtTt9IBfMQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_filters=128\n",
        "def model_kim():\n",
        "  inp = Input(shape=(max_len,))\n",
        "  emb = Embedding(num_words,embed_size,embeddings_initializer=Constant(embeddings),input_length=max_len,trainable=False)(inp)\n",
        "  # Specify each convolution layer and their kernel siz i.e. n-grams \n",
        "  conv1_1 = Conv1D(filters=conv_filters, kernel_size=3)(emb)\n",
        "  btch1_1 = BatchNormalization()(conv1_1)\n",
        "  drp1_1  = Dropout(0.2)(btch1_1)\n",
        "  actv1_1 = Activation('relu')(drp1_1)\n",
        "  glmp1_1 = GlobalMaxPooling1D()(actv1_1)\n",
        "\n",
        "  conv1_2 = Conv1D(filters=conv_filters, kernel_size=4)(emb)\n",
        "  btch1_2 = BatchNormalization()(conv1_2)\n",
        "  drp1_2  = Dropout(0.2)(btch1_2)\n",
        "  actv1_2 = Activation('relu')(drp1_2)\n",
        "  glmp1_2 = GlobalMaxPooling1D()(actv1_2)\n",
        "\n",
        "  conv1_3 = Conv1D(filters=conv_filters, kernel_size=5)(emb)\n",
        "  btch1_3 = BatchNormalization()(conv1_3)\n",
        "  drp1_3  = Dropout(0.2)(btch1_3)\n",
        "  actv1_3 = Activation('relu')(drp1_3)\n",
        "  glmp1_3 = GlobalMaxPooling1D()(actv1_3)\n",
        "\n",
        "  conv1_4 = Conv1D(filters=conv_filters, kernel_size=6)(emb)\n",
        "  btch1_4 = BatchNormalization()(conv1_4)\n",
        "  drp1_4  = Dropout(0.2)(btch1_4)\n",
        "  actv1_4 = Activation('relu')(drp1_4)\n",
        "  glmp1_4 = GlobalMaxPooling1D()(actv1_4)\n",
        "\n",
        "  # Gather all convolution layers\n",
        "  cnct = concatenate([glmp1_1, glmp1_2, glmp1_3, glmp1_4], axis=1)\n",
        "  drp1 = Dropout(0.2)(cnct)\n",
        "\n",
        "  dns1  = Dense(32, activation='relu')(drp1)\n",
        "  btch1 = BatchNormalization()(dns1)\n",
        "  drp2  = Dropout(0.2)(btch1)\n",
        "\n",
        "  out = Dense(1, activation='sigmoid')(drp2)   \n",
        "  model = Model(inputs=inp, outputs=out)\n",
        "  model.compile(loss=BinaryFocalLoss(gamma=2), optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJCuBpqkNx8L",
        "colab_type": "text"
      },
      "source": [
        "# Train model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUygUis5N2yN",
        "colab_type": "text"
      },
      "source": [
        "##GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdwYL0fG3kQo",
        "colab_type": "code",
        "outputId": "89accc3d-9f2c-4ee8-e100-6f4bdc69be63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "kfold = StratifiedKFold(n_splits=5, shuffle=False, random_state=2020)\n",
        "gru_scores = []\n",
        "gru_test=[]\n",
        "for train, val in kfold.split(sequences_matrix, labels):\n",
        "  gru_model=model_gru()\n",
        "  \n",
        "  gru_model.fit(sequences_matrix[train], labels[train],batch_size=64,epochs=10,verbose=2,\n",
        "            validation_data=(sequences_matrix[val],labels[val]),callbacks=[clr,])\n",
        "  y_pred = gru_model.predict(sequences_matrix[val], batch_size=64, verbose=1)\n",
        "\n",
        "  gru_test.append(gru_model.predict(X_test_sequences, batch_size=64, verbose=1).ravel())\n",
        "\n",
        "  y_pred = (y_pred > 0.5)\n",
        "  f1=f1_score(labels[val], y_pred, average='macro')\n",
        "  gru_scores.append(f1)\n",
        "  keras.backend.clear_session()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 6090 samples, validate on 1523 samples\n",
            "Epoch 1/10\n",
            " - 11s - loss: 0.1270 - acc: 0.7690 - val_loss: 0.1402 - val_acc: 0.7295\n",
            "Epoch 2/10\n",
            " - 3s - loss: 0.1103 - acc: 0.8136 - val_loss: 0.1270 - val_acc: 0.7800\n",
            "Epoch 3/10\n",
            " - 3s - loss: 0.1067 - acc: 0.8233 - val_loss: 0.1372 - val_acc: 0.7748\n",
            "Epoch 4/10\n",
            " - 3s - loss: 0.0951 - acc: 0.8407 - val_loss: 0.1250 - val_acc: 0.7899\n",
            "Epoch 5/10\n",
            " - 3s - loss: 0.0869 - acc: 0.8517 - val_loss: 0.1531 - val_acc: 0.7485\n",
            "Epoch 6/10\n",
            " - 3s - loss: 0.0765 - acc: 0.8750 - val_loss: 0.1431 - val_acc: 0.7584\n",
            "Epoch 7/10\n",
            " - 3s - loss: 0.0687 - acc: 0.8880 - val_loss: 0.1539 - val_acc: 0.7748\n",
            "Epoch 8/10\n",
            " - 3s - loss: 0.0612 - acc: 0.9053 - val_loss: 0.1786 - val_acc: 0.7643\n",
            "Epoch 9/10\n",
            " - 3s - loss: 0.0526 - acc: 0.9182 - val_loss: 0.1840 - val_acc: 0.7617\n",
            "Epoch 10/10\n",
            " - 3s - loss: 0.0464 - acc: 0.9299 - val_loss: 0.2406 - val_acc: 0.7610\n",
            "1523/1523 [==============================] - 0s 306us/step\n",
            "3263/3263 [==============================] - 1s 218us/step\n",
            "Train on 6090 samples, validate on 1523 samples\n",
            "Epoch 1/10\n",
            " - 4s - loss: 0.1253 - acc: 0.7754 - val_loss: 0.1317 - val_acc: 0.7459\n",
            "Epoch 2/10\n",
            " - 3s - loss: 0.1106 - acc: 0.8097 - val_loss: 0.1464 - val_acc: 0.7065\n",
            "Epoch 3/10\n",
            " - 3s - loss: 0.0999 - acc: 0.8317 - val_loss: 0.1480 - val_acc: 0.7170\n",
            "Epoch 4/10\n",
            " - 3s - loss: 0.0933 - acc: 0.8448 - val_loss: 0.1548 - val_acc: 0.6815\n",
            "Epoch 5/10\n",
            " - 3s - loss: 0.0863 - acc: 0.8548 - val_loss: 0.2165 - val_acc: 0.6415\n",
            "Epoch 6/10\n",
            " - 3s - loss: 0.0761 - acc: 0.8749 - val_loss: 0.2077 - val_acc: 0.6559\n",
            "Epoch 7/10\n",
            " - 3s - loss: 0.0642 - acc: 0.8961 - val_loss: 0.2158 - val_acc: 0.6888\n",
            "Epoch 8/10\n",
            " - 3s - loss: 0.0561 - acc: 0.9144 - val_loss: 0.2452 - val_acc: 0.6579\n",
            "Epoch 9/10\n",
            " - 3s - loss: 0.0467 - acc: 0.9299 - val_loss: 0.2625 - val_acc: 0.6730\n",
            "Epoch 10/10\n",
            " - 3s - loss: 0.0393 - acc: 0.9420 - val_loss: 0.2955 - val_acc: 0.6848\n",
            "1523/1523 [==============================] - 1s 330us/step\n",
            "3263/3263 [==============================] - 1s 217us/step\n",
            "Train on 6090 samples, validate on 1523 samples\n",
            "Epoch 1/10\n",
            " - 4s - loss: 0.1200 - acc: 0.7818 - val_loss: 0.1293 - val_acc: 0.7643\n",
            "Epoch 2/10\n",
            " - 3s - loss: 0.1048 - acc: 0.8215 - val_loss: 0.1269 - val_acc: 0.7748\n",
            "Epoch 3/10\n",
            " - 3s - loss: 0.0984 - acc: 0.8319 - val_loss: 0.1583 - val_acc: 0.7078\n",
            "Epoch 4/10\n",
            " - 3s - loss: 0.0911 - acc: 0.8450 - val_loss: 0.1552 - val_acc: 0.7406\n",
            "Epoch 5/10\n",
            " - 3s - loss: 0.0815 - acc: 0.8629 - val_loss: 0.1556 - val_acc: 0.7236\n",
            "Epoch 6/10\n",
            " - 3s - loss: 0.0697 - acc: 0.8869 - val_loss: 0.1786 - val_acc: 0.6980\n",
            "Epoch 7/10\n",
            " - 3s - loss: 0.0617 - acc: 0.9010 - val_loss: 0.1941 - val_acc: 0.7223\n",
            "Epoch 8/10\n",
            " - 3s - loss: 0.0525 - acc: 0.9179 - val_loss: 0.2629 - val_acc: 0.7078\n",
            "Epoch 9/10\n",
            " - 3s - loss: 0.0452 - acc: 0.9312 - val_loss: 0.2389 - val_acc: 0.7308\n",
            "Epoch 10/10\n",
            " - 3s - loss: 0.0355 - acc: 0.9516 - val_loss: 0.2569 - val_acc: 0.7032\n",
            "1523/1523 [==============================] - 0s 315us/step\n",
            "3263/3263 [==============================] - 1s 213us/step\n",
            "Train on 6091 samples, validate on 1522 samples\n",
            "Epoch 1/10\n",
            " - 4s - loss: 0.1214 - acc: 0.7831 - val_loss: 0.1331 - val_acc: 0.7838\n",
            "Epoch 2/10\n",
            " - 3s - loss: 0.1085 - acc: 0.8153 - val_loss: 0.1316 - val_acc: 0.7635\n",
            "Epoch 3/10\n",
            " - 3s - loss: 0.1009 - acc: 0.8340 - val_loss: 0.1363 - val_acc: 0.7858\n",
            "Epoch 4/10\n",
            " - 3s - loss: 0.0952 - acc: 0.8385 - val_loss: 0.1417 - val_acc: 0.7661\n",
            "Epoch 5/10\n",
            " - 3s - loss: 0.0877 - acc: 0.8534 - val_loss: 0.1411 - val_acc: 0.7497\n",
            "Epoch 6/10\n",
            " - 3s - loss: 0.0753 - acc: 0.8765 - val_loss: 0.1741 - val_acc: 0.7418\n",
            "Epoch 7/10\n",
            " - 3s - loss: 0.0643 - acc: 0.8939 - val_loss: 0.1728 - val_acc: 0.7300\n",
            "Epoch 8/10\n",
            " - 3s - loss: 0.0571 - acc: 0.9089 - val_loss: 0.2121 - val_acc: 0.7260\n",
            "Epoch 9/10\n",
            " - 3s - loss: 0.0495 - acc: 0.9304 - val_loss: 0.2500 - val_acc: 0.7162\n",
            "Epoch 10/10\n",
            " - 3s - loss: 0.0448 - acc: 0.9350 - val_loss: 0.2342 - val_acc: 0.7181\n",
            "1522/1522 [==============================] - 0s 313us/step\n",
            "3263/3263 [==============================] - 1s 214us/step\n",
            "Train on 6091 samples, validate on 1522 samples\n",
            "Epoch 1/10\n",
            " - 4s - loss: 0.1277 - acc: 0.7718 - val_loss: 0.1107 - val_acc: 0.8147\n",
            "Epoch 2/10\n",
            " - 3s - loss: 0.1126 - acc: 0.8069 - val_loss: 0.1072 - val_acc: 0.8167\n",
            "Epoch 3/10\n",
            " - 3s - loss: 0.1058 - acc: 0.8196 - val_loss: 0.1083 - val_acc: 0.8233\n",
            "Epoch 4/10\n",
            " - 3s - loss: 0.1021 - acc: 0.8302 - val_loss: 0.1068 - val_acc: 0.8279\n",
            "Epoch 5/10\n",
            " - 3s - loss: 0.0881 - acc: 0.8554 - val_loss: 0.1164 - val_acc: 0.8213\n",
            "Epoch 6/10\n",
            " - 3s - loss: 0.0812 - acc: 0.8646 - val_loss: 0.1294 - val_acc: 0.7976\n",
            "Epoch 7/10\n",
            " - 3s - loss: 0.0707 - acc: 0.8874 - val_loss: 0.1243 - val_acc: 0.7989\n",
            "Epoch 8/10\n",
            " - 3s - loss: 0.0594 - acc: 0.9077 - val_loss: 0.1373 - val_acc: 0.7924\n",
            "Epoch 9/10\n",
            " - 3s - loss: 0.0567 - acc: 0.9146 - val_loss: 0.1787 - val_acc: 0.7438\n",
            "Epoch 10/10\n",
            " - 3s - loss: 0.0440 - acc: 0.9388 - val_loss: 0.1695 - val_acc: 0.7911\n",
            "1522/1522 [==============================] - 0s 309us/step\n",
            "3263/3263 [==============================] - 1s 212us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucuevMTN4VPS",
        "colab_type": "code",
        "outputId": "d6f5be79-ce7e-4d8b-93b8-f89f79344f75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "len(gru_test),gru_test[0].shape,gru_scores"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5,\n",
              " (3263,),\n",
              " [0.738907727666629,\n",
              "  0.6714840379637619,\n",
              "  0.7020580791030875,\n",
              "  0.7051829957967655,\n",
              "  0.7869304524683695])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKKs8iWX570n",
        "colab_type": "code",
        "outputId": "e69ca0e8-8fd2-465a-8986-37cfd2a635ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "np.mean(np.array(gru_test),axis=0).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3263,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaW-Uq0Kldp4",
        "colab_type": "text"
      },
      "source": [
        "## GRU attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XULscbNL6FiP",
        "colab_type": "code",
        "outputId": "495da656-d0a7-4ab2-8fac-e4c0e17e8bcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "kfold = StratifiedKFold(n_splits=5, shuffle=False, random_state=2020)\n",
        "atten_scores = []\n",
        "atten_test=[]\n",
        "for train, val in kfold.split(sequences_matrix, labels):\n",
        "  attn_gru_model=model_gru_attn()\n",
        "  \n",
        "  attn_gru_model.fit(sequences_matrix[train], labels[train],batch_size=64,epochs=10,verbose=2,\n",
        "            validation_data=(sequences_matrix[val],labels[val]),callbacks=[clr,])\n",
        "  y_pred = attn_gru_model.predict(sequences_matrix[val], batch_size=64, verbose=1)\n",
        "\n",
        "  atten_test.append(attn_gru_model.predict(X_test_sequences, batch_size=64, verbose=1).ravel())\n",
        "\n",
        "  y_pred = (y_pred > 0.5)\n",
        "  f1=f1_score(labels[val], y_pred, average='macro')\n",
        "  atten_scores.append(f1)\n",
        "  keras.backend.clear_session()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 6090 samples, validate on 1523 samples\n",
            "Epoch 1/10\n",
            " - 4s - loss: 0.1275 - acc: 0.7680 - val_loss: 0.1218 - val_acc: 0.7932\n",
            "Epoch 2/10\n",
            " - 4s - loss: 0.1101 - acc: 0.8131 - val_loss: 0.1285 - val_acc: 0.7859\n",
            "Epoch 3/10\n",
            " - 3s - loss: 0.1027 - acc: 0.8287 - val_loss: 0.1249 - val_acc: 0.7965\n",
            "Epoch 4/10\n",
            " - 3s - loss: 0.0964 - acc: 0.8383 - val_loss: 0.1274 - val_acc: 0.7853\n",
            "Epoch 5/10\n",
            " - 3s - loss: 0.0903 - acc: 0.8527 - val_loss: 0.1315 - val_acc: 0.7715\n",
            "Epoch 6/10\n",
            " - 3s - loss: 0.0789 - acc: 0.8693 - val_loss: 0.1662 - val_acc: 0.7636\n",
            "Epoch 7/10\n",
            " - 3s - loss: 0.0726 - acc: 0.8821 - val_loss: 0.1580 - val_acc: 0.7577\n",
            "Epoch 8/10\n",
            " - 3s - loss: 0.0648 - acc: 0.8969 - val_loss: 0.1758 - val_acc: 0.7643\n",
            "Epoch 9/10\n",
            " - 3s - loss: 0.0555 - acc: 0.9125 - val_loss: 0.1817 - val_acc: 0.7682\n",
            "Epoch 10/10\n",
            " - 3s - loss: 0.0464 - acc: 0.9315 - val_loss: 0.2008 - val_acc: 0.7814\n",
            "1523/1523 [==============================] - 0s 318us/step\n",
            "3263/3263 [==============================] - 1s 217us/step\n",
            "Train on 6090 samples, validate on 1523 samples\n",
            "Epoch 1/10\n",
            " - 4s - loss: 0.1246 - acc: 0.7778 - val_loss: 0.1267 - val_acc: 0.7617\n",
            "Epoch 2/10\n",
            " - 3s - loss: 0.1082 - acc: 0.8189 - val_loss: 0.1288 - val_acc: 0.7676\n",
            "Epoch 3/10\n",
            " - 3s - loss: 0.0995 - acc: 0.8310 - val_loss: 0.1467 - val_acc: 0.7387\n",
            "Epoch 4/10\n",
            " - 3s - loss: 0.0921 - acc: 0.8491 - val_loss: 0.1532 - val_acc: 0.6960\n",
            "Epoch 5/10\n",
            " - 3s - loss: 0.0815 - acc: 0.8688 - val_loss: 0.1791 - val_acc: 0.7177\n",
            "Epoch 6/10\n",
            " - 3s - loss: 0.0725 - acc: 0.8819 - val_loss: 0.1892 - val_acc: 0.6907\n",
            "Epoch 7/10\n",
            " - 3s - loss: 0.0653 - acc: 0.8967 - val_loss: 0.2268 - val_acc: 0.6500\n",
            "Epoch 8/10\n",
            " - 3s - loss: 0.0557 - acc: 0.9174 - val_loss: 0.2375 - val_acc: 0.6868\n",
            "Epoch 9/10\n",
            " - 3s - loss: 0.0479 - acc: 0.9281 - val_loss: 0.2857 - val_acc: 0.6855\n",
            "Epoch 10/10\n",
            " - 3s - loss: 0.0413 - acc: 0.9401 - val_loss: 0.2997 - val_acc: 0.6605\n",
            "1523/1523 [==============================] - 0s 321us/step\n",
            "3263/3263 [==============================] - 1s 217us/step\n",
            "Train on 6090 samples, validate on 1523 samples\n",
            "Epoch 1/10\n",
            " - 4s - loss: 0.1204 - acc: 0.7872 - val_loss: 0.1324 - val_acc: 0.7584\n",
            "Epoch 2/10\n",
            " - 3s - loss: 0.1053 - acc: 0.8235 - val_loss: 0.1322 - val_acc: 0.7544\n",
            "Epoch 3/10\n",
            " - 3s - loss: 0.0971 - acc: 0.8361 - val_loss: 0.1409 - val_acc: 0.7538\n",
            "Epoch 4/10\n",
            " - 3s - loss: 0.0912 - acc: 0.8460 - val_loss: 0.1566 - val_acc: 0.7393\n",
            "Epoch 5/10\n",
            " - 3s - loss: 0.0824 - acc: 0.8621 - val_loss: 0.1843 - val_acc: 0.6907\n",
            "Epoch 6/10\n",
            " - 3s - loss: 0.0727 - acc: 0.8791 - val_loss: 0.1874 - val_acc: 0.7039\n",
            "Epoch 7/10\n",
            " - 3s - loss: 0.0655 - acc: 0.8956 - val_loss: 0.1949 - val_acc: 0.7262\n",
            "Epoch 8/10\n",
            " - 3s - loss: 0.0557 - acc: 0.9099 - val_loss: 0.2091 - val_acc: 0.7203\n",
            "Epoch 9/10\n",
            " - 3s - loss: 0.0456 - acc: 0.9307 - val_loss: 0.2281 - val_acc: 0.7045\n",
            "Epoch 10/10\n",
            " - 3s - loss: 0.0416 - acc: 0.9376 - val_loss: 0.3057 - val_acc: 0.6829\n",
            "1523/1523 [==============================] - 1s 329us/step\n",
            "3263/3263 [==============================] - 1s 215us/step\n",
            "Train on 6091 samples, validate on 1522 samples\n",
            "Epoch 1/10\n",
            " - 4s - loss: 0.1240 - acc: 0.7751 - val_loss: 0.1282 - val_acc: 0.7641\n",
            "Epoch 2/10\n",
            " - 3s - loss: 0.1106 - acc: 0.8158 - val_loss: 0.1355 - val_acc: 0.7306\n",
            "Epoch 3/10\n",
            " - 3s - loss: 0.1031 - acc: 0.8268 - val_loss: 0.1429 - val_acc: 0.7457\n",
            "Epoch 4/10\n",
            " - 3s - loss: 0.0934 - acc: 0.8409 - val_loss: 0.1369 - val_acc: 0.7687\n",
            "Epoch 5/10\n",
            " - 3s - loss: 0.0874 - acc: 0.8521 - val_loss: 0.1540 - val_acc: 0.7234\n",
            "Epoch 6/10\n",
            " - 3s - loss: 0.0775 - acc: 0.8665 - val_loss: 0.1588 - val_acc: 0.7378\n",
            "Epoch 7/10\n",
            " - 3s - loss: 0.0667 - acc: 0.8938 - val_loss: 0.1966 - val_acc: 0.7392\n",
            "Epoch 8/10\n",
            " - 3s - loss: 0.0591 - acc: 0.9058 - val_loss: 0.2102 - val_acc: 0.7477\n",
            "Epoch 9/10\n",
            " - 3s - loss: 0.0519 - acc: 0.9204 - val_loss: 0.2243 - val_acc: 0.7234\n",
            "Epoch 10/10\n",
            " - 3s - loss: 0.0449 - acc: 0.9329 - val_loss: 0.2441 - val_acc: 0.7148\n",
            "1522/1522 [==============================] - 1s 340us/step\n",
            "3263/3263 [==============================] - 1s 221us/step\n",
            "Train on 6091 samples, validate on 1522 samples\n",
            "Epoch 1/10\n",
            " - 4s - loss: 0.1270 - acc: 0.7729 - val_loss: 0.1180 - val_acc: 0.8095\n",
            "Epoch 2/10\n",
            " - 3s - loss: 0.1113 - acc: 0.8142 - val_loss: 0.1177 - val_acc: 0.7924\n",
            "Epoch 3/10\n",
            " - 3s - loss: 0.1049 - acc: 0.8189 - val_loss: 0.1068 - val_acc: 0.8252\n",
            "Epoch 4/10\n",
            " - 3s - loss: 0.0982 - acc: 0.8345 - val_loss: 0.1109 - val_acc: 0.8187\n",
            "Epoch 5/10\n",
            " - 3s - loss: 0.0887 - acc: 0.8542 - val_loss: 0.1248 - val_acc: 0.7957\n",
            "Epoch 6/10\n",
            " - 3s - loss: 0.0800 - acc: 0.8680 - val_loss: 0.1437 - val_acc: 0.7845\n",
            "Epoch 7/10\n",
            " - 3s - loss: 0.0716 - acc: 0.8823 - val_loss: 0.1397 - val_acc: 0.7858\n",
            "Epoch 8/10\n",
            " - 3s - loss: 0.0640 - acc: 0.9010 - val_loss: 0.1788 - val_acc: 0.7779\n",
            "Epoch 9/10\n",
            " - 3s - loss: 0.0554 - acc: 0.9148 - val_loss: 0.1755 - val_acc: 0.7832\n",
            "Epoch 10/10\n",
            " - 3s - loss: 0.0457 - acc: 0.9307 - val_loss: 0.1943 - val_acc: 0.7740\n",
            "1522/1522 [==============================] - 0s 328us/step\n",
            "3263/3263 [==============================] - 1s 224us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vo1Ec10_FbH4",
        "colab_type": "code",
        "outputId": "109121c7-40aa-4290-eefc-de5bc01a1013",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "source": [
        "atten_scores \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7705815856030116,\n",
              " 0.6561528770341645,\n",
              " 0.6828430812478308,\n",
              " 0.7113317542586943,\n",
              " 0.7709183253788654]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlFNurr4T1rh",
        "colab_type": "text"
      },
      "source": [
        "##TCN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKtfxHFBT2wB",
        "colab_type": "code",
        "outputId": "8779fa1f-e5b5-4996-dc20-882357c8edaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "kfold = StratifiedKFold(n_splits=5, shuffle=False)\n",
        "tcn_scores = []\n",
        "tcn_test=[]\n",
        "for train, val in kfold.split(sequences_matrix, labels):\n",
        "  model=model_tcn(embeddings)\n",
        "  \n",
        "  model.fit(sequences_matrix[train], labels[train],batch_size=64,epochs=10,verbose=2,\n",
        "            validation_data=(sequences_matrix[val],labels[val]),callbacks=[clr,])\n",
        "  y_pred = model.predict(sequences_matrix[val], batch_size=64, verbose=1)\n",
        "\n",
        "  tcn_test.append(model.predict(X_test_sequences, batch_size=64, verbose=1).ravel())\n",
        "\n",
        "  y_pred = (y_pred > 0.5)\n",
        "  f1=f1_score(labels[val], y_pred, average='macro')\n",
        "  tcn_scores.append(f1)\n",
        "  keras.backend.clear_session()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 6090 samples, validate on 1523 samples\n",
            "Epoch 1/10\n",
            " - 7s - loss: 0.1506 - acc: 0.6734 - val_loss: 0.1387 - val_acc: 0.7433\n",
            "Epoch 2/10\n",
            " - 3s - loss: 0.1262 - acc: 0.7785 - val_loss: 0.1324 - val_acc: 0.7695\n",
            "Epoch 3/10\n",
            " - 3s - loss: 0.1191 - acc: 0.8023 - val_loss: 0.1439 - val_acc: 0.7216\n",
            "Epoch 4/10\n",
            " - 3s - loss: 0.1190 - acc: 0.7995 - val_loss: 0.1335 - val_acc: 0.7433\n",
            "Epoch 5/10\n",
            " - 3s - loss: 0.1130 - acc: 0.8153 - val_loss: 0.1286 - val_acc: 0.7617\n",
            "Epoch 6/10\n",
            " - 3s - loss: 0.1091 - acc: 0.8238 - val_loss: 0.1246 - val_acc: 0.7643\n",
            "Epoch 7/10\n",
            " - 3s - loss: 0.1084 - acc: 0.8271 - val_loss: 0.1304 - val_acc: 0.7584\n",
            "Epoch 8/10\n",
            " - 3s - loss: 0.1036 - acc: 0.8355 - val_loss: 0.1494 - val_acc: 0.7479\n",
            "Epoch 9/10\n",
            " - 3s - loss: 0.0963 - acc: 0.8486 - val_loss: 0.1398 - val_acc: 0.7505\n",
            "Epoch 10/10\n",
            " - 3s - loss: 0.0966 - acc: 0.8504 - val_loss: 0.1340 - val_acc: 0.7722\n",
            "1523/1523 [==============================] - 0s 263us/step\n",
            "3263/3263 [==============================] - 1s 219us/step\n",
            "Train on 6090 samples, validate on 1523 samples\n",
            "Epoch 1/10\n",
            " - 4s - loss: 0.1359 - acc: 0.7466 - val_loss: 0.1446 - val_acc: 0.7426\n",
            "Epoch 2/10\n",
            " - 3s - loss: 0.1206 - acc: 0.7966 - val_loss: 0.1427 - val_acc: 0.7571\n",
            "Epoch 3/10\n",
            " - 3s - loss: 0.1166 - acc: 0.7934 - val_loss: 0.1481 - val_acc: 0.7026\n",
            "Epoch 4/10\n",
            " - 3s - loss: 0.1113 - acc: 0.8212 - val_loss: 0.1468 - val_acc: 0.7367\n",
            "Epoch 5/10\n",
            " - 3s - loss: 0.1060 - acc: 0.8315 - val_loss: 0.1493 - val_acc: 0.7249\n",
            "Epoch 6/10\n",
            " - 3s - loss: 0.1010 - acc: 0.8401 - val_loss: 0.1659 - val_acc: 0.7065\n",
            "Epoch 7/10\n",
            " - 3s - loss: 0.0915 - acc: 0.8603 - val_loss: 0.1879 - val_acc: 0.7216\n",
            "Epoch 8/10\n",
            " - 3s - loss: 0.0926 - acc: 0.8601 - val_loss: 0.1741 - val_acc: 0.7065\n",
            "Epoch 9/10\n",
            " - 3s - loss: 0.0896 - acc: 0.8591 - val_loss: 0.1600 - val_acc: 0.7190\n",
            "Epoch 10/10\n",
            " - 3s - loss: 0.0845 - acc: 0.8709 - val_loss: 0.1900 - val_acc: 0.6855\n",
            "1523/1523 [==============================] - 0s 279us/step\n",
            "3263/3263 [==============================] - 0s 129us/step\n",
            "Train on 6090 samples, validate on 1523 samples\n",
            "Epoch 1/10\n",
            " - 4s - loss: 0.1472 - acc: 0.6918 - val_loss: 0.1337 - val_acc: 0.7715\n",
            "Epoch 2/10\n",
            " - 3s - loss: 0.1212 - acc: 0.7928 - val_loss: 0.1351 - val_acc: 0.7531\n",
            "Epoch 3/10\n",
            " - 3s - loss: 0.1122 - acc: 0.8092 - val_loss: 0.1369 - val_acc: 0.7387\n",
            "Epoch 4/10\n",
            " - 3s - loss: 0.1036 - acc: 0.8287 - val_loss: 0.1388 - val_acc: 0.7603\n",
            "Epoch 5/10\n",
            " - 3s - loss: 0.1028 - acc: 0.8269 - val_loss: 0.1444 - val_acc: 0.7426\n",
            "Epoch 6/10\n",
            " - 3s - loss: 0.1002 - acc: 0.8332 - val_loss: 0.1428 - val_acc: 0.7295\n",
            "Epoch 7/10\n",
            " - 3s - loss: 0.0977 - acc: 0.8424 - val_loss: 0.1743 - val_acc: 0.6770\n",
            "Epoch 8/10\n",
            " - 3s - loss: 0.0896 - acc: 0.8568 - val_loss: 0.1434 - val_acc: 0.7308\n",
            "Epoch 9/10\n",
            " - 3s - loss: 0.0851 - acc: 0.8617 - val_loss: 0.2221 - val_acc: 0.6829\n",
            "Epoch 10/10\n",
            " - 3s - loss: 0.0840 - acc: 0.8650 - val_loss: 0.1746 - val_acc: 0.7334\n",
            "1523/1523 [==============================] - 0s 276us/step\n",
            "3263/3263 [==============================] - 0s 130us/step\n",
            "Train on 6091 samples, validate on 1522 samples\n",
            "Epoch 1/10\n",
            " - 6s - loss: 0.1609 - acc: 0.6322 - val_loss: 0.1455 - val_acc: 0.7148\n",
            "Epoch 2/10\n",
            " - 3s - loss: 0.1262 - acc: 0.7843 - val_loss: 0.1341 - val_acc: 0.7510\n",
            "Epoch 3/10\n",
            " - 3s - loss: 0.1188 - acc: 0.7992 - val_loss: 0.1298 - val_acc: 0.7562\n",
            "Epoch 4/10\n",
            " - 3s - loss: 0.1145 - acc: 0.8030 - val_loss: 0.1343 - val_acc: 0.7602\n",
            "Epoch 5/10\n",
            " - 3s - loss: 0.1072 - acc: 0.8212 - val_loss: 0.1401 - val_acc: 0.7602\n",
            "Epoch 6/10\n",
            " - 3s - loss: 0.1044 - acc: 0.8266 - val_loss: 0.1432 - val_acc: 0.7530\n",
            "Epoch 7/10\n",
            " - 3s - loss: 0.1016 - acc: 0.8312 - val_loss: 0.1442 - val_acc: 0.7365\n",
            "Epoch 8/10\n",
            " - 3s - loss: 0.0972 - acc: 0.8403 - val_loss: 0.1476 - val_acc: 0.7484\n",
            "Epoch 9/10\n",
            " - 3s - loss: 0.1029 - acc: 0.8273 - val_loss: 0.1542 - val_acc: 0.7464\n",
            "Epoch 10/10\n",
            " - 3s - loss: 0.0969 - acc: 0.8416 - val_loss: 0.1737 - val_acc: 0.7556\n",
            "1522/1522 [==============================] - 0s 283us/step\n",
            "3263/3263 [==============================] - 0s 129us/step\n",
            "Train on 6091 samples, validate on 1522 samples\n",
            "Epoch 1/10\n",
            " - 4s - loss: 0.1461 - acc: 0.6987 - val_loss: 0.1241 - val_acc: 0.7884\n",
            "Epoch 2/10\n",
            " - 3s - loss: 0.1251 - acc: 0.7926 - val_loss: 0.1143 - val_acc: 0.8206\n",
            "Epoch 3/10\n",
            " - 3s - loss: 0.1201 - acc: 0.7986 - val_loss: 0.1120 - val_acc: 0.8226\n",
            "Epoch 4/10\n",
            " - 3s - loss: 0.1181 - acc: 0.7959 - val_loss: 0.1479 - val_acc: 0.6432\n",
            "Epoch 5/10\n",
            " - 3s - loss: 0.1139 - acc: 0.8058 - val_loss: 0.1153 - val_acc: 0.8154\n",
            "Epoch 6/10\n",
            " - 3s - loss: 0.1120 - acc: 0.8235 - val_loss: 0.1575 - val_acc: 0.7615\n",
            "Epoch 7/10\n",
            " - 3s - loss: 0.1057 - acc: 0.8311 - val_loss: 0.1240 - val_acc: 0.7858\n",
            "Epoch 8/10\n",
            " - 3s - loss: 0.1020 - acc: 0.8409 - val_loss: 0.1210 - val_acc: 0.8081\n",
            "Epoch 9/10\n",
            " - 3s - loss: 0.0971 - acc: 0.8468 - val_loss: 0.1184 - val_acc: 0.7845\n",
            "Epoch 10/10\n",
            " - 3s - loss: 0.1011 - acc: 0.8362 - val_loss: 0.1348 - val_acc: 0.7779\n",
            "1522/1522 [==============================] - 0s 262us/step\n",
            "3263/3263 [==============================] - 0s 129us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tr_J6FWTCYXB",
        "colab_type": "text"
      },
      "source": [
        "##KIM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgmUF8liCa4M",
        "colab_type": "code",
        "outputId": "5b1ddd00-1343-4a65-d378-a9d20ae66c28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "kfold = StratifiedKFold(n_splits=5, shuffle=False)\n",
        "kim_scores = []\n",
        "kim_test=[]\n",
        "for train, val in kfold.split(sequences_matrix, labels):\n",
        "  model=model_kim()\n",
        "  \n",
        "  model.fit(sequences_matrix[train], labels[train],batch_size=64,epochs=10,verbose=2,\n",
        "            validation_data=(sequences_matrix[val],labels[val]),callbacks=[clr,])\n",
        "  y_pred = model.predict(sequences_matrix[val], batch_size=64, verbose=1)\n",
        "\n",
        "  kim_test.append(model.predict(X_test_sequences, batch_size=64, verbose=1).ravel())\n",
        "\n",
        "  y_pred = (y_pred > 0.5)\n",
        "  f1=f1_score(labels[val], y_pred, average='macro')\n",
        "  kim_scores.append(f1)\n",
        "  keras.backend.clear_session()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 6090 samples, validate on 1523 samples\n",
            "Epoch 1/10\n",
            " - 4s - loss: 0.1708 - acc: 0.7342 - val_loss: 0.1666 - val_acc: 0.7249\n",
            "Epoch 2/10\n",
            " - 2s - loss: 0.1156 - acc: 0.8067 - val_loss: 0.1269 - val_acc: 0.7827\n",
            "Epoch 3/10\n",
            " - 2s - loss: 0.0943 - acc: 0.8440 - val_loss: 0.1302 - val_acc: 0.7617\n",
            "Epoch 4/10\n",
            " - 2s - loss: 0.0830 - acc: 0.8663 - val_loss: 0.1466 - val_acc: 0.7610\n",
            "Epoch 5/10\n",
            " - 2s - loss: 0.0722 - acc: 0.8954 - val_loss: 0.1527 - val_acc: 0.7413\n",
            "Epoch 6/10\n",
            " - 2s - loss: 0.0636 - acc: 0.9128 - val_loss: 0.1798 - val_acc: 0.7374\n",
            "Epoch 7/10\n",
            " - 2s - loss: 0.0539 - acc: 0.9289 - val_loss: 0.1951 - val_acc: 0.7111\n",
            "Epoch 8/10\n",
            " - 2s - loss: 0.0488 - acc: 0.9348 - val_loss: 0.1653 - val_acc: 0.7643\n",
            "Epoch 9/10\n",
            " - 2s - loss: 0.0426 - acc: 0.9415 - val_loss: 0.1757 - val_acc: 0.7636\n",
            "Epoch 10/10\n",
            " - 2s - loss: 0.0388 - acc: 0.9471 - val_loss: 0.2623 - val_acc: 0.7466\n",
            "1523/1523 [==============================] - 0s 236us/step\n",
            "3263/3263 [==============================] - 0s 122us/step\n",
            "Train on 6090 samples, validate on 1523 samples\n",
            "Epoch 1/10\n",
            " - 4s - loss: 0.1888 - acc: 0.7278 - val_loss: 0.1311 - val_acc: 0.7557\n",
            "Epoch 2/10\n",
            " - 2s - loss: 0.1168 - acc: 0.7987 - val_loss: 0.1380 - val_acc: 0.7531\n",
            "Epoch 3/10\n",
            " - 2s - loss: 0.1015 - acc: 0.8294 - val_loss: 0.1385 - val_acc: 0.7367\n",
            "Epoch 4/10\n",
            " - 2s - loss: 0.0835 - acc: 0.8665 - val_loss: 0.1742 - val_acc: 0.7321\n",
            "Epoch 5/10\n",
            " - 2s - loss: 0.0749 - acc: 0.8854 - val_loss: 0.1564 - val_acc: 0.7301\n",
            "Epoch 6/10\n",
            " - 2s - loss: 0.0663 - acc: 0.9069 - val_loss: 0.1762 - val_acc: 0.7065\n",
            "Epoch 7/10\n",
            " - 2s - loss: 0.0584 - acc: 0.9228 - val_loss: 0.1751 - val_acc: 0.7085\n",
            "Epoch 8/10\n",
            " - 2s - loss: 0.0510 - acc: 0.9332 - val_loss: 0.1890 - val_acc: 0.7137\n",
            "Epoch 9/10\n",
            " - 2s - loss: 0.0453 - acc: 0.9435 - val_loss: 0.1910 - val_acc: 0.7118\n",
            "Epoch 10/10\n",
            " - 2s - loss: 0.0405 - acc: 0.9461 - val_loss: 0.2021 - val_acc: 0.6953\n",
            "1523/1523 [==============================] - 0s 235us/step\n",
            "3263/3263 [==============================] - 0s 106us/step\n",
            "Train on 6090 samples, validate on 1523 samples\n",
            "Epoch 1/10\n",
            " - 4s - loss: 0.1710 - acc: 0.7427 - val_loss: 0.1325 - val_acc: 0.7682\n",
            "Epoch 2/10\n",
            " - 2s - loss: 0.1107 - acc: 0.8144 - val_loss: 0.1536 - val_acc: 0.7682\n",
            "Epoch 3/10\n",
            " - 2s - loss: 0.0957 - acc: 0.8452 - val_loss: 0.1444 - val_acc: 0.7643\n",
            "Epoch 4/10\n",
            " - 2s - loss: 0.0791 - acc: 0.8770 - val_loss: 0.1608 - val_acc: 0.7045\n",
            "Epoch 5/10\n",
            " - 2s - loss: 0.0661 - acc: 0.9018 - val_loss: 0.1565 - val_acc: 0.7459\n",
            "Epoch 6/10\n",
            " - 2s - loss: 0.0585 - acc: 0.9169 - val_loss: 0.1748 - val_acc: 0.7393\n",
            "Epoch 7/10\n",
            " - 2s - loss: 0.0509 - acc: 0.9302 - val_loss: 0.2021 - val_acc: 0.6986\n",
            "Epoch 8/10\n",
            " - 2s - loss: 0.0486 - acc: 0.9368 - val_loss: 0.1866 - val_acc: 0.7216\n",
            "Epoch 9/10\n",
            " - 2s - loss: 0.0404 - acc: 0.9473 - val_loss: 0.2477 - val_acc: 0.7216\n",
            "Epoch 10/10\n",
            " - 2s - loss: 0.0352 - acc: 0.9560 - val_loss: 0.2088 - val_acc: 0.7177\n",
            "1523/1523 [==============================] - 0s 243us/step\n",
            "3263/3263 [==============================] - 0s 104us/step\n",
            "Train on 6091 samples, validate on 1522 samples\n",
            "Epoch 1/10\n",
            " - 4s - loss: 0.1854 - acc: 0.7312 - val_loss: 0.1349 - val_acc: 0.7484\n",
            "Epoch 2/10\n",
            " - 2s - loss: 0.1215 - acc: 0.7969 - val_loss: 0.1280 - val_acc: 0.7431\n",
            "Epoch 3/10\n",
            " - 2s - loss: 0.1012 - acc: 0.8255 - val_loss: 0.1338 - val_acc: 0.7484\n",
            "Epoch 4/10\n",
            " - 2s - loss: 0.0891 - acc: 0.8529 - val_loss: 0.1591 - val_acc: 0.7332\n",
            "Epoch 5/10\n",
            " - 2s - loss: 0.0762 - acc: 0.8833 - val_loss: 0.1418 - val_acc: 0.7615\n",
            "Epoch 6/10\n",
            " - 2s - loss: 0.0653 - acc: 0.9046 - val_loss: 0.1853 - val_acc: 0.7254\n",
            "Epoch 7/10\n",
            " - 2s - loss: 0.0559 - acc: 0.9238 - val_loss: 0.1762 - val_acc: 0.7359\n",
            "Epoch 8/10\n",
            " - 2s - loss: 0.0543 - acc: 0.9222 - val_loss: 0.1871 - val_acc: 0.7254\n",
            "Epoch 9/10\n",
            " - 2s - loss: 0.0452 - acc: 0.9432 - val_loss: 0.1847 - val_acc: 0.7457\n",
            "Epoch 10/10\n",
            " - 2s - loss: 0.0420 - acc: 0.9435 - val_loss: 0.2156 - val_acc: 0.7254\n",
            "1522/1522 [==============================] - 0s 237us/step\n",
            "3263/3263 [==============================] - 0s 106us/step\n",
            "Train on 6091 samples, validate on 1522 samples\n",
            "Epoch 1/10\n",
            " - 4s - loss: 0.1730 - acc: 0.7257 - val_loss: 0.1125 - val_acc: 0.7943\n",
            "Epoch 2/10\n",
            " - 2s - loss: 0.1224 - acc: 0.7956 - val_loss: 0.1328 - val_acc: 0.7714\n",
            "Epoch 3/10\n",
            " - 2s - loss: 0.1039 - acc: 0.8291 - val_loss: 0.1092 - val_acc: 0.8180\n",
            "Epoch 4/10\n",
            " - 2s - loss: 0.0889 - acc: 0.8577 - val_loss: 0.1159 - val_acc: 0.7996\n",
            "Epoch 5/10\n",
            " - 2s - loss: 0.0725 - acc: 0.8875 - val_loss: 0.1277 - val_acc: 0.8029\n",
            "Epoch 6/10\n",
            " - 2s - loss: 0.0675 - acc: 0.9089 - val_loss: 0.1254 - val_acc: 0.7878\n",
            "Epoch 7/10\n",
            " - 2s - loss: 0.0577 - acc: 0.9245 - val_loss: 0.1364 - val_acc: 0.7963\n",
            "Epoch 8/10\n",
            " - 2s - loss: 0.0561 - acc: 0.9223 - val_loss: 0.1298 - val_acc: 0.8035\n",
            "Epoch 9/10\n",
            " - 2s - loss: 0.0451 - acc: 0.9414 - val_loss: 0.1343 - val_acc: 0.8075\n",
            "Epoch 10/10\n",
            " - 2s - loss: 0.0382 - acc: 0.9488 - val_loss: 0.1523 - val_acc: 0.7878\n",
            "1522/1522 [==============================] - 0s 243us/step\n",
            "3263/3263 [==============================] - 0s 105us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bXDiFxJH5Ny",
        "colab_type": "text"
      },
      "source": [
        "#**Result**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXd8VkdPhAq2",
        "colab_type": "text"
      },
      "source": [
        "# Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnC41n_HRKQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gru_scores=np.average(np.array(gru_scores))\n",
        "atten_scores=np.average(np.array(atten_scores))\n",
        "tcn_scores=np.average(np.array(tcn_scores))\n",
        "kim_scores=np.average(np.array(kim_scores))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBp341Qog_uv",
        "colab_type": "code",
        "outputId": "7c2249d9-715b-4e37-a666-8af04a90f1a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "print('f1 score of count vec' ,cv_score)\n",
        "print('f1 score of word tfidf' ,tfw_score)\n",
        "print('f1 score of char tfidf' ,tfc_score)\n",
        "\n",
        "print('f1 score of RNN' ,gru_scores)\n",
        "print('f1 score of gated attention',atten_scores )\n",
        "print('f1 score of tcn',tcn_scores)\n",
        "print('f1 score of kim',kim_scores)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1 score of count vec 0.6789070385269321\n",
            "f1 score of word tfidf 0.6814031008661787\n",
            "f1 score of char tfidf 0.6909844962829798\n",
            "f1 score of RNN 0.7209126585997228\n",
            "f1 score of gated attention 0.7183655247045133\n",
            "f1 score of tcn 0.7401977975331973\n",
            "f1 score of kim 0.720860230243704\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipijYwvjJPyx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kim_test_avg=np.mean(np.array(kim_test),axis=0)\n",
        "gru_test_avg=np.mean(np.array(gru_test),axis=0)\n",
        "atten_test_avg=np.mean(np.array(atten_test),axis=0)\n",
        "tcn_test_avg=np.mean(np.array(tcn_test),axis=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAMx_NI2jltK",
        "colab_type": "code",
        "outputId": "d75822c0-f9f8-463c-d5e0-a97fdd22309e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "kim_test[0].shape,cv_test.shape,kim_test_avg.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3263,), (3263,), (3263,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZ8CR7s1Qe18",
        "colab_type": "code",
        "outputId": "55e71f86-17c9-4cfa-b4db-2e81d54d9805",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "print(cv_test[5:15].round())\n",
        "print(tfw_test[5:15].round())\n",
        "print(tfc_test[5:15].round())\n",
        "print(gru_test_avg[5:15].round())\n",
        "print(atten_test_avg[5:15].round())\n",
        "print(kim_test_avg[5:15].round())\n",
        "print(tcn_test_avg[5:15].round())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DW1OugTMEpZg",
        "colab_type": "text"
      },
      "source": [
        "# Ensemble"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6VT0aVcUIhm",
        "colab_type": "text"
      },
      "source": [
        "we will choose only those, having f1 greater than 0.7. Once they are selected, we will decode labels, and keep label according to mod"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wmQlS5LkZLi",
        "colab_type": "code",
        "outputId": "2efc8a7c-283d-4d96-e254-da481ea34fc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "wt=gru_scores+atten_scores+cv_score+tfw_score+tfc_score+tcn_scores+kim_scores\n",
        "wt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.9516308467572285"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkCLYtxOcXCA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#i am bit changing the distribution in order to give more weightage to ml than dl\n",
        "y_test=gru_scores/wt * gru_test_avg + atten_scores/wt * atten_test_avg + cv_score/wt * cv_test + tfw_score/wt *tfw_test + tfc_score/wt *tfc_test +kim_scores/wt * kim_test_avg + tcn_scores/wt *tcn_test_avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzRAIebNSpMz",
        "colab_type": "code",
        "outputId": "cac069ca-707f-4c48-fd64-dd474a8df38a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "y_test[5:15].round()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9Pu0LvuZIf8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode(y_test):\n",
        "  y_test[y_test>0.5]=1\n",
        "  y_test[y_test<0.5]=0\n",
        "  y_test=y_test.astype('int16').ravel()\n",
        "\n",
        "  y_test=le.inverse_transform(y_test)\n",
        "  y_test=pd.DataFrame(y_test,columns=['label'])\n",
        "  y_test=pd.concat([ids, y_test['label']], axis=1)\n",
        "  return y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PgV77IYZRGP",
        "colab_type": "code",
        "outputId": "68576a72-f275-48a0-fb8d-e4720af49a0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_test[y_test>0.5]=1\n",
        "y_test[y_test<0.5]=0\n",
        "y_test=y_test.astype('int16').ravel()\n",
        "\n",
        "y_test=pd.DataFrame(y_test,columns=['label'])\n",
        "y_test=pd.concat([ids, y_test['label']], axis=1)\n",
        "y_test.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-0652df213048>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ids' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8avMmBQvb_IR",
        "colab_type": "code",
        "outputId": "5da31791-3747-4c25-b9bb-9906be421cd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_test.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label\n",
              "0      1\n",
              "1      1\n",
              "2      1\n",
              "3      1\n",
              "4      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dl57zICXM4c6",
        "colab_type": "text"
      },
      "source": [
        "# Submit file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LkCxvtfEnpl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHTCw4_jP_tr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test.to_csv('/content/disaster.csv',index=False,header=None)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tPo96DUz_EZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwKb7_NBWjAv",
        "colab_type": "text"
      },
      "source": [
        "# Reset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0Xi3s2KWlKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import keras\n",
        "# keras.backend.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T39YK5rbQBoT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}