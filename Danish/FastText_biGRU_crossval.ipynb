{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of biGRU.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/talhaanwarch/OffenseEval2020/blob/master/Danish/FastText_biGRU_crossval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_tja7FDUpcC",
        "colab_type": "text"
      },
      "source": [
        "# Danish Language\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8yyBcABHgE8",
        "colab_type": "code",
        "outputId": "8fc833b5-955d-4fc7-b701-55db588218b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzpBLLtl6MXy",
        "colab_type": "code",
        "outputId": "fb91d1be-98bb-49cd-fbbe-04d45ef871ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "!pip install focal-loss\n",
        "!pip install keras-radam"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting focal-loss\n",
            "  Downloading https://files.pythonhosted.org/packages/66/ed/17450291228192ad8595de4514c8ec28a587697b03c707d12d4af5b7f331/focal_loss-0.0.2-py3-none-any.whl\n",
            "Installing collected packages: focal-loss\n",
            "Successfully installed focal-loss-0.0.2\n",
            "Collecting keras-radam\n",
            "  Downloading https://files.pythonhosted.org/packages/46/8d/b83ccaa94253fbc920b21981f038393041d92236bb541751b98a66a2ac1d/keras-radam-0.15.0.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-radam) (1.17.5)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-radam) (2.2.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-radam) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-radam) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-radam) (2.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-radam) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-radam) (1.0.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-radam) (1.12.0)\n",
            "Building wheels for collected packages: keras-radam\n",
            "  Building wheel for keras-radam (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-radam: filename=keras_radam-0.15.0-cp36-none-any.whl size=14685 sha256=77b214071291d5338149bcb6f5e86d8e80f801cac7d86d72b0c57bb1df0e5edb\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/a0/c0/670b0a118e8f078539fafec7bd02eba0af921f745660c7f83f\n",
            "Successfully built keras-radam\n",
            "Installing collected packages: keras-radam\n",
            "Successfully installed keras-radam-0.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0Yzi-0oHqTD",
        "colab_type": "code",
        "outputId": "4cc89981-159a-408a-87b3-b55179a00c04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/My Drive/dataset/OffenseEval2020/data/Danish/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/dataset/OffenseEval2020/data/Danish\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fN7zvpdTOdo",
        "colab_type": "code",
        "outputId": "8d23536c-1fd0-43df-eacd-81c3f4e02deb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cc.da.300.vec  cc.da.300.vec.gz  offenseval-da-training-v1.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04n7RsXqIBlz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "train=pd.read_csv( 'offenseval-da-training-v1.tsv',sep=\"\\t\")\n",
        "train.drop(train.tail(n=1).index,inplace=True)\n",
        "#train['tweet']=train['tweet'].str.lower()\n",
        "train=train.sample(frac=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqmIsFmsIFPY",
        "colab_type": "code",
        "outputId": "17009844-8732-4696-fafc-c0a83ffe9eac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>subtask_a</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1562</th>\n",
              "      <td>2185</td>\n",
              "      <td>Försöker ni ens? URL#Medal_table</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2675</th>\n",
              "      <td>2939</td>\n",
              "      <td>Var det virkelig sådan at Mohammad skulle fore...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>267</th>\n",
              "      <td>1241</td>\n",
              "      <td>Sniffe kokain af bagerens røvhul hørtes ut som...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2863</th>\n",
              "      <td>1881</td>\n",
              "      <td>Sådan et sveskn kors burde forbydes. Føj!</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253</th>\n",
              "      <td>853</td>\n",
              "      <td>nu har \"flygtningene\" så gjort det i flere år ...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id                                              tweet subtask_a\n",
              "1562  2185                   Försöker ni ens? URL#Medal_table       NOT\n",
              "2675  2939  Var det virkelig sådan at Mohammad skulle fore...       NOT\n",
              "267   1241  Sniffe kokain af bagerens røvhul hørtes ut som...       NOT\n",
              "2863  1881          Sådan et sveskn kors burde forbydes. Føj!       NOT\n",
              "253    853  nu har \"flygtningene\" så gjort det i flere år ...       NOT"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ptkGujpIwMH",
        "colab_type": "code",
        "outputId": "97d45bb5-9134-4378-caf3-a09f6f9a6391",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "train.tail()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>subtask_a</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2038</th>\n",
              "      <td>1540</td>\n",
              "      <td>Altså. Nu er de ikke dømt endnu!</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2181</th>\n",
              "      <td>1699</td>\n",
              "      <td>Åh, den kære bagedyst!</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>370</th>\n",
              "      <td>1171</td>\n",
              "      <td>Hahah lol</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>459</th>\n",
              "      <td>1400</td>\n",
              "      <td>Nej bestemt ikke. Troede de var flytninge ford...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>238</th>\n",
              "      <td>1683</td>\n",
              "      <td>Så kan det være de halvvikinger derovre kan læ...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id                                              tweet subtask_a\n",
              "2038  1540                   Altså. Nu er de ikke dømt endnu!       NOT\n",
              "2181  1699                             Åh, den kære bagedyst!       NOT\n",
              "370   1171                                          Hahah lol       NOT\n",
              "459   1400  Nej bestemt ikke. Troede de var flytninge ford...       NOT\n",
              "238   1683  Så kan det være de halvvikinger derovre kan læ...       NOT"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TYe8X52IGha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels=train['subtask_a']\n",
        "train=train['tweet']\n",
        "labels=pd.factorize(labels)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVmlJvlfIP9k",
        "colab_type": "code",
        "outputId": "17a27881-c4a6-4dde-8986-7bf14ec3d61f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import collections\n",
        "collections.Counter(labels)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 2576, 1: 384})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRZItSB-IogR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "outputId": "44c3c18b-c823-43df-b231-0e999d794a69"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "max_words = 10000 #frequency of words to be kept\n",
        "max_len = 200\n",
        "\n",
        "tokenize = Tokenizer(num_words=max_words)\n",
        "tokenize.fit_on_texts(train)\n",
        "sequences = tokenize.texts_to_sequences(train)\n",
        "word_index = tokenize.word_index\n",
        "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsBKuk1UOu4W",
        "colab_type": "code",
        "outputId": "fc69bd9a-a7e8-439e-e62c-b35ae7b7b119",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(sequences_matrix),len(labels)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2960, 2960)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_CbYz9jJ1Bc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding,CuDNNGRU,GRU,Dense,Dropout,Bidirectional,GlobalMaxPool1D,GlobalAveragePooling1D, SpatialDropout1D\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.initializers import Constant\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import classification_report,f1_score\n",
        "import keras\n",
        "from keras_radam import RAdam\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from focal_loss import BinaryFocalLoss\n",
        "import tensorflow as tf\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUpgHo7nCE3C",
        "colab_type": "code",
        "outputId": "9f3cbfc1-0137-4a74-832a-8ce070bb46a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "num_words = min(max_words, len(word_index)) + 1\n",
        "print(num_words)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9970\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NdNYG_SM_s98",
        "colab": {}
      },
      "source": [
        "# !wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.el.300.vec.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OAAtXRaw_sNX",
        "colab": {}
      },
      "source": [
        "# import gzip\n",
        "# import shutil\n",
        "# with gzip.open('cc.el.300.vec.gz', 'rb') as f_in:\n",
        "#     with open('cc.el.300.vec', 'wb') as f_out:\n",
        "#         shutil.copyfileobj(f_in, f_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hohu_6rE-Z6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed_size=300\n",
        "def get_coefs(word,*arr):\n",
        "    return word, np.asarray(arr, dtype='float32')\n",
        "\n",
        "def build_matrix(embedding_path, word_index):\n",
        "    embedding_index = dict(get_coefs(*o.strip().split(\" \")) for o in open(embedding_path))\n",
        "\n",
        "    nb_words = min(max_words, len(word_index))\n",
        "    embedding_matrix = np.zeros((nb_words + 1, embed_size))\n",
        "    for word, i in word_index.items():\n",
        "        if i >= max_words:\n",
        "            continue\n",
        "        embedding_vector = embedding_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "    return embedding_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faZVMLbw-cN-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings=build_matrix('cc.da.300.vec', word_index)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "et7AvsISBjZP",
        "colab_type": "code",
        "outputId": "44e6a691-233d-4f35-e2cf-e367999b5a63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embeddings.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9970, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPExMeUk6Zrx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTLZ31tIJ4Js",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_func():\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(num_words,embed_size,embeddings_initializer=Constant(embeddings),input_length=max_len,trainable=False))\n",
        "  model.add(Bidirectional(CuDNNGRU(100, return_sequences = True)))\n",
        "  #model.add(Bidirectional(CuDNNGRU(32, return_sequences = True)))\n",
        "  model.add(GlobalMaxPool1D())\n",
        "  model.add(Dense(100, activation=\"relu\"))\n",
        "  model.add(Dense(50, activation=\"relu\"))\n",
        "  #model.add(Dense(10, activation=\"relu\"))\n",
        "\n",
        "  model.add(Dropout(0.05))\n",
        "  model.add(Dense(1, activation=\"sigmoid\"))\n",
        "  model.compile(loss=BinaryFocalLoss(gamma=2), optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9qM_Y38hWEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "class_weights = class_weight.compute_class_weight('balanced',np.unique(labels),labels)\n",
        "class_weights=dict(enumerate(class_weights))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHE3OFWz3DTk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ReduceLROnPlateau\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
        "                              patience=2, min_lr=0.000001, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-6ga8jGg5Pj",
        "colab_type": "code",
        "outputId": "de15c56b-f217-4a29-8a3d-88cd4d28c86a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "kfold = StratifiedKFold(n_splits=10, shuffle=False, random_state=2020)\n",
        "cvscores = []\n",
        "\n",
        "for train, test in kfold.split(sequences_matrix, labels):\n",
        "  model=model_func()\n",
        "  \n",
        "  model.fit(sequences_matrix[train], labels[train],batch_size=64,epochs=10,verbose=2,\n",
        "            validation_data=(sequences_matrix[test],labels[test]),callbacks=[reduce_lr])\n",
        "  y_pred = model.predict(sequences_matrix[test], batch_size=64, verbose=1)\n",
        "  y_pred_bool = np.argmax(y_pred, axis=1)\n",
        "  y_pred = (y_pred > 0.5)\n",
        "  f1=f1_score(labels[test], y_pred, average='macro')\n",
        "  cvscores.append(f1)\n",
        "  keras.backend.clear_session()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 2664 samples, validate on 296 samples\n",
            "Epoch 1/10\n",
            " - 16s - loss: 0.1133 - acc: 0.8525 - val_loss: 0.0996 - val_acc: 0.8716\n",
            "Epoch 2/10\n",
            " - 1s - loss: 0.0939 - acc: 0.8701 - val_loss: 0.0901 - val_acc: 0.8716\n",
            "Epoch 3/10\n",
            " - 1s - loss: 0.0766 - acc: 0.8878 - val_loss: 0.0794 - val_acc: 0.9020\n",
            "Epoch 4/10\n",
            " - 1s - loss: 0.0633 - acc: 0.9122 - val_loss: 0.0792 - val_acc: 0.9122\n",
            "Epoch 5/10\n",
            " - 1s - loss: 0.0571 - acc: 0.9155 - val_loss: 0.0970 - val_acc: 0.9054\n",
            "Epoch 6/10\n",
            " - 1s - loss: 0.0426 - acc: 0.9429 - val_loss: 0.0919 - val_acc: 0.9223\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 7/10\n",
            " - 1s - loss: 0.0302 - acc: 0.9610 - val_loss: 0.0910 - val_acc: 0.9189\n",
            "Epoch 8/10\n",
            " - 1s - loss: 0.0267 - acc: 0.9707 - val_loss: 0.1012 - val_acc: 0.9122\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 9/10\n",
            " - 1s - loss: 0.0240 - acc: 0.9745 - val_loss: 0.0986 - val_acc: 0.9122\n",
            "Epoch 10/10\n",
            " - 1s - loss: 0.0230 - acc: 0.9756 - val_loss: 0.1014 - val_acc: 0.9122\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "296/296 [==============================] - 0s 455us/step\n",
            "Train on 2664 samples, validate on 296 samples\n",
            "Epoch 1/10\n",
            " - 2s - loss: 0.1133 - acc: 0.8671 - val_loss: 0.0976 - val_acc: 0.8716\n",
            "Epoch 2/10\n",
            " - 1s - loss: 0.0911 - acc: 0.8724 - val_loss: 0.0842 - val_acc: 0.8750\n",
            "Epoch 3/10\n",
            " - 1s - loss: 0.0756 - acc: 0.8968 - val_loss: 0.0786 - val_acc: 0.8851\n",
            "Epoch 4/10\n",
            " - 1s - loss: 0.0650 - acc: 0.9099 - val_loss: 0.0778 - val_acc: 0.8784\n",
            "Epoch 5/10\n",
            " - 1s - loss: 0.0539 - acc: 0.9261 - val_loss: 0.0805 - val_acc: 0.8682\n",
            "Epoch 6/10\n",
            " - 1s - loss: 0.0436 - acc: 0.9388 - val_loss: 0.0863 - val_acc: 0.8615\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 7/10\n",
            " - 1s - loss: 0.0313 - acc: 0.9610 - val_loss: 0.0864 - val_acc: 0.8818\n",
            "Epoch 8/10\n",
            " - 1s - loss: 0.0274 - acc: 0.9655 - val_loss: 0.0901 - val_acc: 0.8885\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 9/10\n",
            " - 1s - loss: 0.0244 - acc: 0.9711 - val_loss: 0.0903 - val_acc: 0.8885\n",
            "Epoch 10/10\n",
            " - 1s - loss: 0.0240 - acc: 0.9707 - val_loss: 0.0908 - val_acc: 0.8818\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "296/296 [==============================] - 0s 521us/step\n",
            "Train on 2664 samples, validate on 296 samples\n",
            "Epoch 1/10\n",
            " - 2s - loss: 0.1086 - acc: 0.8697 - val_loss: 0.1019 - val_acc: 0.8716\n",
            "Epoch 2/10\n",
            " - 1s - loss: 0.0884 - acc: 0.8705 - val_loss: 0.0922 - val_acc: 0.8716\n",
            "Epoch 3/10\n",
            " - 1s - loss: 0.0718 - acc: 0.8983 - val_loss: 0.0897 - val_acc: 0.8851\n",
            "Epoch 4/10\n",
            " - 1s - loss: 0.0605 - acc: 0.9189 - val_loss: 0.0890 - val_acc: 0.8818\n",
            "Epoch 5/10\n",
            " - 1s - loss: 0.0453 - acc: 0.9347 - val_loss: 0.1192 - val_acc: 0.8784\n",
            "Epoch 6/10\n",
            " - 1s - loss: 0.0357 - acc: 0.9459 - val_loss: 0.1121 - val_acc: 0.8885\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 7/10\n",
            " - 1s - loss: 0.0222 - acc: 0.9748 - val_loss: 0.1220 - val_acc: 0.8919\n",
            "Epoch 8/10\n",
            " - 1s - loss: 0.0188 - acc: 0.9801 - val_loss: 0.1323 - val_acc: 0.8919\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 9/10\n",
            " - 1s - loss: 0.0164 - acc: 0.9839 - val_loss: 0.1302 - val_acc: 0.8953\n",
            "Epoch 10/10\n",
            " - 1s - loss: 0.0162 - acc: 0.9854 - val_loss: 0.1312 - val_acc: 0.8953\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "296/296 [==============================] - 0s 466us/step\n",
            "Train on 2664 samples, validate on 296 samples\n",
            "Epoch 1/10\n",
            " - 2s - loss: 0.1120 - acc: 0.8682 - val_loss: 0.1034 - val_acc: 0.8716\n",
            "Epoch 2/10\n",
            " - 1s - loss: 0.0959 - acc: 0.8701 - val_loss: 0.0872 - val_acc: 0.8716\n",
            "Epoch 3/10\n",
            " - 1s - loss: 0.0795 - acc: 0.8769 - val_loss: 0.0758 - val_acc: 0.8953\n",
            "Epoch 4/10\n",
            " - 1s - loss: 0.0641 - acc: 0.9073 - val_loss: 0.0775 - val_acc: 0.8986\n",
            "Epoch 5/10\n",
            " - 1s - loss: 0.0540 - acc: 0.9272 - val_loss: 0.0775 - val_acc: 0.8919\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 6/10\n",
            " - 1s - loss: 0.0415 - acc: 0.9418 - val_loss: 0.0841 - val_acc: 0.9088\n",
            "Epoch 7/10\n",
            " - 1s - loss: 0.0367 - acc: 0.9505 - val_loss: 0.0886 - val_acc: 0.9088\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 8/10\n",
            " - 1s - loss: 0.0335 - acc: 0.9550 - val_loss: 0.0881 - val_acc: 0.9054\n",
            "Epoch 9/10\n",
            " - 1s - loss: 0.0326 - acc: 0.9572 - val_loss: 0.0882 - val_acc: 0.9054\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "Epoch 10/10\n",
            " - 1s - loss: 0.0325 - acc: 0.9576 - val_loss: 0.0883 - val_acc: 0.9054\n",
            "296/296 [==============================] - 0s 505us/step\n",
            "Train on 2664 samples, validate on 296 samples\n",
            "Epoch 1/10\n",
            " - 2s - loss: 0.1110 - acc: 0.8697 - val_loss: 0.0978 - val_acc: 0.8716\n",
            "Epoch 2/10\n",
            " - 1s - loss: 0.0923 - acc: 0.8709 - val_loss: 0.0877 - val_acc: 0.8818\n",
            "Epoch 3/10\n",
            " - 1s - loss: 0.0741 - acc: 0.8998 - val_loss: 0.0837 - val_acc: 0.8818\n",
            "Epoch 4/10\n",
            " - 1s - loss: 0.0615 - acc: 0.9114 - val_loss: 0.0893 - val_acc: 0.9088\n",
            "Epoch 5/10\n",
            " - 1s - loss: 0.0489 - acc: 0.9332 - val_loss: 0.1077 - val_acc: 0.8885\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 6/10\n",
            " - 1s - loss: 0.0342 - acc: 0.9535 - val_loss: 0.1036 - val_acc: 0.8885\n",
            "Epoch 7/10\n",
            " - 1s - loss: 0.0306 - acc: 0.9598 - val_loss: 0.0987 - val_acc: 0.8885\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 8/10\n",
            " - 1s - loss: 0.0278 - acc: 0.9647 - val_loss: 0.1035 - val_acc: 0.8885\n",
            "Epoch 9/10\n",
            " - 1s - loss: 0.0267 - acc: 0.9651 - val_loss: 0.1071 - val_acc: 0.8851\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "Epoch 10/10\n",
            " - 1s - loss: 0.0265 - acc: 0.9655 - val_loss: 0.1070 - val_acc: 0.8851\n",
            "296/296 [==============================] - 0s 528us/step\n",
            "Train on 2664 samples, validate on 296 samples\n",
            "Epoch 1/10\n",
            " - 2s - loss: 0.1155 - acc: 0.8566 - val_loss: 0.1013 - val_acc: 0.8716\n",
            "Epoch 2/10\n",
            " - 1s - loss: 0.0936 - acc: 0.8701 - val_loss: 0.0878 - val_acc: 0.8716\n",
            "Epoch 3/10\n",
            " - 1s - loss: 0.0771 - acc: 0.8956 - val_loss: 0.0853 - val_acc: 0.8953\n",
            "Epoch 4/10\n",
            " - 1s - loss: 0.0684 - acc: 0.9024 - val_loss: 0.0772 - val_acc: 0.9122\n",
            "Epoch 5/10\n",
            " - 1s - loss: 0.0555 - acc: 0.9185 - val_loss: 0.0915 - val_acc: 0.8716\n",
            "Epoch 6/10\n",
            " - 1s - loss: 0.0503 - acc: 0.9321 - val_loss: 0.0802 - val_acc: 0.8986\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 7/10\n",
            " - 1s - loss: 0.0360 - acc: 0.9535 - val_loss: 0.0822 - val_acc: 0.9189\n",
            "Epoch 8/10\n",
            " - 1s - loss: 0.0307 - acc: 0.9587 - val_loss: 0.0880 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 9/10\n",
            " - 1s - loss: 0.0278 - acc: 0.9625 - val_loss: 0.0892 - val_acc: 0.9122\n",
            "Epoch 10/10\n",
            " - 1s - loss: 0.0273 - acc: 0.9632 - val_loss: 0.0890 - val_acc: 0.9122\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "296/296 [==============================] - 0s 574us/step\n",
            "Train on 2664 samples, validate on 296 samples\n",
            "Epoch 1/10\n",
            " - 2s - loss: 0.1076 - acc: 0.8690 - val_loss: 0.1001 - val_acc: 0.8682\n",
            "Epoch 2/10\n",
            " - 1s - loss: 0.0856 - acc: 0.8780 - val_loss: 0.0848 - val_acc: 0.8885\n",
            "Epoch 3/10\n",
            " - 1s - loss: 0.0705 - acc: 0.9020 - val_loss: 0.0866 - val_acc: 0.8919\n",
            "Epoch 4/10\n",
            " - 1s - loss: 0.0618 - acc: 0.9118 - val_loss: 0.0752 - val_acc: 0.9088\n",
            "Epoch 5/10\n",
            " - 1s - loss: 0.0470 - acc: 0.9332 - val_loss: 0.1050 - val_acc: 0.9020\n",
            "Epoch 6/10\n",
            " - 1s - loss: 0.0435 - acc: 0.9377 - val_loss: 0.0871 - val_acc: 0.9155\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 7/10\n",
            " - 1s - loss: 0.0265 - acc: 0.9685 - val_loss: 0.0935 - val_acc: 0.9155\n",
            "Epoch 8/10\n",
            " - 1s - loss: 0.0229 - acc: 0.9745 - val_loss: 0.0950 - val_acc: 0.9088\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 9/10\n",
            " - 1s - loss: 0.0208 - acc: 0.9779 - val_loss: 0.0950 - val_acc: 0.9088\n",
            "Epoch 10/10\n",
            " - 1s - loss: 0.0202 - acc: 0.9775 - val_loss: 0.0951 - val_acc: 0.9088\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "296/296 [==============================] - 0s 529us/step\n",
            "Train on 2664 samples, validate on 296 samples\n",
            "Epoch 1/10\n",
            " - 2s - loss: 0.1112 - acc: 0.8705 - val_loss: 0.1013 - val_acc: 0.8682\n",
            "Epoch 2/10\n",
            " - 1s - loss: 0.0897 - acc: 0.8705 - val_loss: 0.0855 - val_acc: 0.8682\n",
            "Epoch 3/10\n",
            " - 1s - loss: 0.0732 - acc: 0.8908 - val_loss: 0.0816 - val_acc: 0.9020\n",
            "Epoch 4/10\n",
            " - 1s - loss: 0.0590 - acc: 0.9110 - val_loss: 0.0834 - val_acc: 0.9054\n",
            "Epoch 5/10\n",
            " - 1s - loss: 0.0479 - acc: 0.9324 - val_loss: 0.0877 - val_acc: 0.8953\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 6/10\n",
            " - 1s - loss: 0.0326 - acc: 0.9557 - val_loss: 0.1013 - val_acc: 0.9054\n",
            "Epoch 7/10\n",
            " - 1s - loss: 0.0286 - acc: 0.9606 - val_loss: 0.1070 - val_acc: 0.9054\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 8/10\n",
            " - 1s - loss: 0.0253 - acc: 0.9692 - val_loss: 0.1088 - val_acc: 0.9020\n",
            "Epoch 9/10\n",
            " - 1s - loss: 0.0247 - acc: 0.9711 - val_loss: 0.1117 - val_acc: 0.9054\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "Epoch 10/10\n",
            " - 1s - loss: 0.0239 - acc: 0.9715 - val_loss: 0.1097 - val_acc: 0.9020\n",
            "296/296 [==============================] - 0s 463us/step\n",
            "Train on 2664 samples, validate on 296 samples\n",
            "Epoch 1/10\n",
            " - 2s - loss: 0.1108 - acc: 0.8581 - val_loss: 0.0984 - val_acc: 0.8682\n",
            "Epoch 2/10\n",
            " - 1s - loss: 0.0910 - acc: 0.8705 - val_loss: 0.0874 - val_acc: 0.8716\n",
            "Epoch 3/10\n",
            " - 1s - loss: 0.0719 - acc: 0.9020 - val_loss: 0.0918 - val_acc: 0.8784\n",
            "Epoch 4/10\n",
            " - 1s - loss: 0.0591 - acc: 0.9163 - val_loss: 0.0888 - val_acc: 0.8885\n",
            "\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 5/10\n",
            " - 1s - loss: 0.0455 - acc: 0.9351 - val_loss: 0.0935 - val_acc: 0.8919\n",
            "Epoch 6/10\n",
            " - 1s - loss: 0.0402 - acc: 0.9478 - val_loss: 0.1019 - val_acc: 0.8851\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 7/10\n",
            " - 1s - loss: 0.0363 - acc: 0.9497 - val_loss: 0.0991 - val_acc: 0.8919\n",
            "Epoch 8/10\n",
            " - 1s - loss: 0.0353 - acc: 0.9497 - val_loss: 0.0991 - val_acc: 0.8919\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "Epoch 9/10\n",
            " - 1s - loss: 0.0348 - acc: 0.9531 - val_loss: 0.0999 - val_acc: 0.8919\n",
            "Epoch 10/10\n",
            " - 1s - loss: 0.0347 - acc: 0.9546 - val_loss: 0.1009 - val_acc: 0.8885\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
            "296/296 [==============================] - 0s 457us/step\n",
            "Train on 2664 samples, validate on 296 samples\n",
            "Epoch 1/10\n",
            " - 2s - loss: 0.1100 - acc: 0.8630 - val_loss: 0.1056 - val_acc: 0.8682\n",
            "Epoch 2/10\n",
            " - 1s - loss: 0.0933 - acc: 0.8705 - val_loss: 0.0935 - val_acc: 0.8682\n",
            "Epoch 3/10\n",
            " - 1s - loss: 0.0788 - acc: 0.8765 - val_loss: 0.0767 - val_acc: 0.9155\n",
            "Epoch 4/10\n",
            " - 1s - loss: 0.0662 - acc: 0.9028 - val_loss: 0.0707 - val_acc: 0.9020\n",
            "Epoch 5/10\n",
            " - 1s - loss: 0.0545 - acc: 0.9215 - val_loss: 0.0771 - val_acc: 0.9155\n",
            "Epoch 6/10\n",
            " - 1s - loss: 0.0419 - acc: 0.9411 - val_loss: 0.0766 - val_acc: 0.8986\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 7/10\n",
            " - 1s - loss: 0.0321 - acc: 0.9565 - val_loss: 0.0862 - val_acc: 0.9122\n",
            "Epoch 8/10\n",
            " - 1s - loss: 0.0275 - acc: 0.9651 - val_loss: 0.0925 - val_acc: 0.9122\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 9/10\n",
            " - 1s - loss: 0.0243 - acc: 0.9715 - val_loss: 0.0907 - val_acc: 0.9122\n",
            "Epoch 10/10\n",
            " - 1s - loss: 0.0238 - acc: 0.9741 - val_loss: 0.0954 - val_acc: 0.9122\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "296/296 [==============================] - 0s 625us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKgIrCHXJ_Gc",
        "colab_type": "code",
        "outputId": "63be4460-075d-47fa-9d2b-934cf0684a0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.array(cvscores).mean()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7225816050347762"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwZrmmcPMfKm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sepj7fJ_REvZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}