{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "biGRU.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/talhaanwarch/OffenseEval2020/blob/master/Arabic/biGRU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_tja7FDUpcC",
        "colab_type": "text"
      },
      "source": [
        "# Arabic Language"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8yyBcABHgE8",
        "colab_type": "code",
        "outputId": "11dfc879-b1f1-4aa5-9637-0e2234a82896",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0Yzi-0oHqTD",
        "colab_type": "code",
        "outputId": "7b0960fe-caf0-41f8-eb96-730d903c47cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/My Drive/dataset/OffenseEval2020/data/Arabic/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/dataset/OffenseEval2020/data/Arabic\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fN7zvpdTOdo",
        "colab_type": "code",
        "outputId": "b03d63ac-ae59-4e46-96dd-c3d1eb7aec20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "offenseval-ar-dev-v1.tsv  offenseval-ar-training-v1.tsv  readme-data-ar.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04n7RsXqIBlz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "train=pd.read_csv( 'offenseval-ar-training-v1.tsv',sep=\"\\t\")\n",
        "train=train.sample(frac=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqmIsFmsIFPY",
        "colab_type": "code",
        "outputId": "f24ab1d4-94a4-46e9-8bd5-472abb38f91e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>subtask_a</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2484</th>\n",
              "      <td>2491</td>\n",
              "      <td>@USER كفو يا بن زنان يا صليب الراس يالعالمي يا...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4030</th>\n",
              "      <td>4102</td>\n",
              "      <td>يا فهد باص يا فهد باص يا فهد باص يا فهد باص يا...</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2455</th>\n",
              "      <td>2462</td>\n",
              "      <td>يا نفس يا ولهانه &lt;LF&gt;لي ما درى بك حد &lt;LF&gt;اتحمل...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2987</th>\n",
              "      <td>3059</td>\n",
              "      <td>- بكام الشيميز ده لو سمحت ؟&lt;LF&gt;= 420 جنية يا ف...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3112</th>\n",
              "      <td>3184</td>\n",
              "      <td>يالله اللحين يا فقراري يا ظريف يا ملك التلاعب ...</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id                                              tweet subtask_a\n",
              "2484  2491  @USER كفو يا بن زنان يا صليب الراس يالعالمي يا...       NOT\n",
              "4030  4102  يا فهد باص يا فهد باص يا فهد باص يا فهد باص يا...       OFF\n",
              "2455  2462  يا نفس يا ولهانه <LF>لي ما درى بك حد <LF>اتحمل...       NOT\n",
              "2987  3059  - بكام الشيميز ده لو سمحت ؟<LF>= 420 جنية يا ف...       NOT\n",
              "3112  3184  يالله اللحين يا فقراري يا ظريف يا ملك التلاعب ...       OFF"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ptkGujpIwMH",
        "colab_type": "code",
        "outputId": "3be346ee-f664-4c04-d2e4-8c66af15df0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "train.tail()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>subtask_a</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3826</th>\n",
              "      <td>3898</td>\n",
              "      <td>RT @USER: يا وهّاب يا باسط.. &lt;LF&gt;يُغالبني القل...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5984</th>\n",
              "      <td>6082</td>\n",
              "      <td>والله يا نوجا يا حبيبت قلبي كنت زي القمر جنب ا...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2118</th>\n",
              "      <td>2119</td>\n",
              "      <td>@USER يا بكاااايه يا بكاااايه اسكت ازعجتنا ابك...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6043</th>\n",
              "      <td>6141</td>\n",
              "      <td>@USER كل سنه وانت طيب يا باور يا عالمى وعقبال ...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4246</th>\n",
              "      <td>4318</td>\n",
              "      <td>#السيسى_رئيسى_وأفتخر&lt;LF&gt;#السيسى_زعيمى_وأفتخر &lt;...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id                                              tweet subtask_a\n",
              "3826  3898  RT @USER: يا وهّاب يا باسط.. <LF>يُغالبني القل...       NOT\n",
              "5984  6082  والله يا نوجا يا حبيبت قلبي كنت زي القمر جنب ا...       NOT\n",
              "2118  2119  @USER يا بكاااايه يا بكاااايه اسكت ازعجتنا ابك...       NOT\n",
              "6043  6141  @USER كل سنه وانت طيب يا باور يا عالمى وعقبال ...       NOT\n",
              "4246  4318  #السيسى_رئيسى_وأفتخر<LF>#السيسى_زعيمى_وأفتخر <...       NOT"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0O4bhzBG15lI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val=pd.read_csv( 'offenseval-ar-dev-v1.tsv',sep=\"\\t\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TYe8X52IGha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels=train['subtask_a']\n",
        "X_train=train['tweet']\n",
        "y_train=pd.factorize(train_labels)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVmlJvlfIP9k",
        "colab_type": "code",
        "outputId": "9189d182-e555-4815-ac62-14d3be1af366",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import collections\n",
        "collections.Counter(train_labels)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'NOT': 5468, 'OFF': 1371})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGVt19qI2Oo_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_labels=val['subtask_a']\n",
        "X_val=val['tweet']\n",
        "y_val=pd.factorize(val_labels)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tdsMtXX2Vcf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRZItSB-IogR",
        "colab_type": "code",
        "outputId": "48b4bea3-33b9-4342-e409-e0092691bca2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "max_words = 10000 #frequency of words to be kept\n",
        "max_len = 200\n",
        "\n",
        "tokenize = Tokenizer(num_words=max_words)\n",
        "tokenize.fit_on_texts(X_train)\n",
        "sequences = tokenize.texts_to_sequences(X_train)\n",
        "word_index = tokenize.word_index\n",
        "X_train_sequences = sequence.pad_sequences(sequences,maxlen=max_len)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsBKuk1UOu4W",
        "colab_type": "code",
        "outputId": "a2be0232-fdb0-44d0-9263-e585c68d5b21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(X_train_sequences),len(train_labels)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6839, 6839)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3Jlj1633X51",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "val_sequences = tokenize.texts_to_sequences(X_val)\n",
        "X_val_sequences = sequence.pad_sequences(val_sequences,maxlen=max_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_CbYz9jJ1Bc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding,CuDNNGRU,GRU,Dense,Dropout,Bidirectional,GlobalMaxPool1D,GlobalAveragePooling1D, SpatialDropout1D\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.initializers import Constant\n",
        "from sklearn.utils import class_weight\n",
        "import tensorflow as tf\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQC6dlJWLv3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "def f1(y_true, y_pred):\n",
        "    '''\n",
        "    metric from here \n",
        "    https://stackoverflow.com/questions/43547402/how-to-calculate-f1-macro-in-keras\n",
        "    '''\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "\n",
        "        Only computes a batch-wise average of precision.\n",
        "\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTLZ31tIJ4Js",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=max_words,output_dim=300,input_length=max_len))\n",
        "model.add(Bidirectional(CuDNNGRU(150, return_sequences = True)))\n",
        "#model.add(Bidirectional(CuDNNGRU(50, return_sequences = True)))\n",
        "model.add(GlobalMaxPool1D())\n",
        "model.add(Dense(50, activation=\"relu\"))\n",
        "model.add(Dense(20, activation=\"relu\"))\n",
        "\n",
        "model.add(Dropout(0.05))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[f1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKgIrCHXJ_Gc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "class_weights = class_weight.compute_class_weight('balanced',np.unique(y_train),y_train)\n",
        "class_weights=dict(enumerate(class_weights))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHE3OFWz3DTk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ReduceLROnPlateau\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
        "                              patience=2, min_lr=0.000001, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3uZunneJ67w",
        "colab_type": "code",
        "outputId": "2f632967-8a6f-4d90-ddfc-c2b66f3e05f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "source": [
        "\n",
        "model.fit(X_train_sequences,y_train,batch_size=256,epochs=10,verbose=2,class_weight=class_weights,validation_data=(X_val_sequences,y_val),callbacks=[reduce_lr])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 6839 samples, validate on 1000 samples\n",
            "Epoch 1/10\n",
            " - 6s - loss: 0.6577 - f1: 0.4374 - val_loss: 0.5546 - val_f1: 0.5666\n",
            "Epoch 2/10\n",
            " - 2s - loss: 0.4447 - f1: 0.6909 - val_loss: 0.3759 - val_f1: 0.6604\n",
            "Epoch 3/10\n",
            " - 2s - loss: 0.1621 - f1: 0.8744 - val_loss: 0.3160 - val_f1: 0.6785\n",
            "Epoch 4/10\n",
            " - 2s - loss: 0.0658 - f1: 0.9562 - val_loss: 0.4039 - val_f1: 0.6555\n",
            "Epoch 5/10\n",
            " - 2s - loss: 0.0300 - f1: 0.9805 - val_loss: 0.4295 - val_f1: 0.6469\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 6/10\n",
            " - 2s - loss: 0.0150 - f1: 0.9926 - val_loss: 0.4399 - val_f1: 0.6416\n",
            "Epoch 7/10\n",
            " - 2s - loss: 0.0116 - f1: 0.9933 - val_loss: 0.4632 - val_f1: 0.6446\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 8/10\n",
            " - 2s - loss: 0.0103 - f1: 0.9932 - val_loss: 0.4671 - val_f1: 0.6446\n",
            "Epoch 9/10\n",
            " - 2s - loss: 0.0103 - f1: 0.9938 - val_loss: 0.4692 - val_f1: 0.6500\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "Epoch 10/10\n",
            " - 2s - loss: 0.0095 - f1: 0.9946 - val_loss: 0.4701 - val_f1: 0.6483\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4f0d58d550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcXmC1MHKNPL",
        "colab_type": "code",
        "outputId": "a38a0c5d-f724-41d0-a585-5b360fd1c3ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred = model.predict(X_val_sequences, batch_size=32, verbose=1)\n",
        "y_pred_bool = np.argmax(y_pred, axis=1)\n",
        "y_pred = (y_pred > 0.5)\n",
        "\n",
        "print(classification_report(y_val, y_pred))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 0s 499us/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.92      0.92       821\n",
            "           1       0.65      0.65      0.65       179\n",
            "\n",
            "    accuracy                           0.88      1000\n",
            "   macro avg       0.79      0.79      0.79      1000\n",
            "weighted avg       0.88      0.88      0.88      1000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwZrmmcPMfKm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "keras.backend.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sepj7fJ_REvZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}